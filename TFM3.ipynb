{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import keras\n",
    "import six\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,AveragePooling1D,Flatten,concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/roberto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/roberto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/roberto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/roberto/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abro el archivo en el que se encuentra el dataset de los problemas\n",
    "with open('singleop.json', 'r') as f:\n",
    "    datastore = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo que contiene un listado de nombres\n",
    "nombres = pd.read_csv('nombres-2015.csv')\n",
    "names = pd.read_csv('yob2019.txt', header=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('problemas_adicionales2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas = []\n",
    "respuestas = []\n",
    "ecuaciones = []\n",
    "alineacion = []\n",
    "\n",
    "for item in datastore:\n",
    "    preguntas.append(item['sQuestion'])\n",
    "    respuestas.append(item['lSolutions'])\n",
    "    ecuaciones.append(item['lEquations'])\n",
    "    alineacion.append(item['lAlignments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tengo  159  sumas  162  restas,  117  multiplicaciones,  124  divisiones y otras operaciones  0\n"
     ]
    }
   ],
   "source": [
    "# Necesito convertir el dataset en un problema de clasificacion para que la red neuronal pueda identificar\n",
    "# si estoy tratando de resolver un problema de sumas, restas, multiplicaciones o divisiones.\n",
    "# Esto va a crear una lista con el tipo de operacion y que va a ser el resultado a inferir.\n",
    "operaciones = []\n",
    "sumas =0\n",
    "restas =0\n",
    "multiplicaciones =0\n",
    "divisiones = 0\n",
    "otras = 0\n",
    "#Clasifico las operaciones en 0 para sumas, 1 para restas, 2 para multiplicaciones, 3 para divisiones y 4 sino lo encuentro.\n",
    "for operacion in ecuaciones:\n",
    "    if (operacion[0].find('+')>=0):\n",
    "        operaciones.append(0)\n",
    "        sumas = sumas + 1\n",
    "    elif (operacion[0].find('-') >= 0 ):\n",
    "        operaciones.append(1)\n",
    "        restas = restas + 1\n",
    "    elif(operacion[0].find('*') >=0):\n",
    "        operaciones.append(2)\n",
    "        multiplicaciones = multiplicaciones + 1\n",
    "    elif(operacion[0].find('/')):\n",
    "        operaciones.append(3)\n",
    "        divisiones = divisiones + 1\n",
    "    else:\n",
    "        operaciones.append(4)\n",
    "        otras = otras + 1\n",
    "\n",
    "print('Tengo ', sumas, ' sumas ', restas, ' restas, ', multiplicaciones, ' multiplicaciones, ', divisiones, ' divisiones y otras operaciones ', otras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas2 = dataset2['Preguntas'].tolist()\n",
    "respuestas2 = dataset2['respuestas'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas3 = preguntas + preguntas2\n",
    "respuestas3 = operaciones + respuestas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El listado de nombres lo voy a truncar a los 15K primeros, dado que el resto son nombres muy residuales.\n",
    "nombres_ = nombres['nombre'][:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_= names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_ = nombres_.append(names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_words = list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom = nombres['nombre'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomb =  nom + st_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fuimos'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomb[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El vector preguntas_sin, consiste en las preguntas a las que voy a eliminar todos los nombres propios que no\n",
    "# anaden ningun valor al conjunto de preguntas. No quiero que esos nombres se procesen y por tanto los elimino.\n",
    "def eliminar_palabras(dataset, stopw):\n",
    "    preguntas_sin = []\n",
    "    for palabras in dataset:\n",
    "        frases = [word for word in palabras.split(' ') if word not in stopw]\n",
    "        frases = \" \".join(frases)\n",
    "        preguntas_sin.append(frases)\n",
    "    return preguntas_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_sin = eliminar_palabras(preguntas3, nomb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "preguntas3, respuestas3 = shuffle(preguntas_sin,respuestas3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_w = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for i,pregunta in enumerate(preguntas_sin):\n",
    "    palabras = tokenizer.tokenize(pregunta)\n",
    "    for palabra in palabras:\n",
    "        preguntas_w.append(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_unicas = set(preguntas_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_unicas = list(palabras_unicas)\n",
    "\n",
    "vocabulario = {p:i for i, p in enumerate(p_unicas)}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = gensim.models.KeyedVectors.load_word2vec_format('SBW-vectors-300-min5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for key in vocabulario.keys():\n",
    "    if key not in glove:\n",
    "        zeros = np.zeros(300)\n",
    "        if key.isdigit():\n",
    "            for i in range(0,300):\n",
    "                zeros[i] = int(key)*0.000001\n",
    "        embeddings.append({key: zeros})\n",
    "    else:\n",
    "        embeddings.append({key : glove[key][:300]})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_embeddings = []\n",
    "\n",
    "for i, preguntas in enumerate(preguntas_sin):\n",
    "    palabras = tokenizer.tokenize(preguntas)\n",
    "    words = []\n",
    "    for j,palabra in enumerate(palabras):\n",
    "        for h, word in enumerate(embeddings):\n",
    "            for key in embeddings[h]:\n",
    "                if(key == palabra):\n",
    "                    words.append(embeddings[h][palabra][:300])\n",
    "    if (j < 31):\n",
    "        for j in range (j, 30):\n",
    "            words.append(p)\n",
    "    preguntas_embeddings.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el tamano del vocabulario\n",
    "vocabulario = []\n",
    "\n",
    "for pregunta in preguntas_w:\n",
    "    for palabra in pregunta:\n",
    "        vocabulario.append(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = set(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El tamano del vocabulario es necesario para poder crear la matriz de embeddings, con el numero de palabras\n",
    "# totales que tengo\n",
    "embedding_dim = 16\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_X = np.asarray(preguntas_embeddings[:800])\n",
    "test_X = np.asarray(preguntas_embeddings[800:])\n",
    "training_y = np.asarray(respuestas3[:800])\n",
    "test_y = np.asarray(respuestas3[800:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un modelo donde el primer argumento de la capa embedding son las palabras totales que voy a procesar\n",
    "# vectorizadas en un indice.\n",
    "# El segundo argumento, es el tamano del vector embedding, que he fijado en 16.\n",
    "# El tercer argumento, es el tamano o longitud maxima, que he definido para las preguntas. Numero total de palabras\n",
    "# por pregunta.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(36, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \"\"\"\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2352\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 1.3702 - accuracy: 0.3300 - val_loss: 1.3284 - val_accuracy: 0.3851\n",
      "Epoch 2/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.3282 - accuracy: 0.3713 - val_loss: 1.3227 - val_accuracy: 0.3851\n",
      "Epoch 3/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.2983 - accuracy: 0.3738 - val_loss: 1.3287 - val_accuracy: 0.3851\n",
      "Epoch 4/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.2757 - accuracy: 0.3762 - val_loss: 1.3310 - val_accuracy: 0.3851\n",
      "Epoch 5/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.2294 - accuracy: 0.4013 - val_loss: 1.3420 - val_accuracy: 0.3851\n",
      "Epoch 6/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1773 - accuracy: 0.4387 - val_loss: 1.3460 - val_accuracy: 0.3678\n",
      "Epoch 7/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.1115 - accuracy: 0.5050 - val_loss: 1.3598 - val_accuracy: 0.3563\n",
      "Epoch 8/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0370 - accuracy: 0.5888 - val_loss: 1.3826 - val_accuracy: 0.3563\n",
      "Epoch 9/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9565 - accuracy: 0.6600 - val_loss: 1.4126 - val_accuracy: 0.3391\n",
      "Epoch 10/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8484 - accuracy: 0.7275 - val_loss: 1.4500 - val_accuracy: 0.3218\n",
      "Epoch 11/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7705 - accuracy: 0.7625 - val_loss: 1.5031 - val_accuracy: 0.3103\n",
      "Epoch 12/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6654 - accuracy: 0.8025 - val_loss: 1.5767 - val_accuracy: 0.2759\n",
      "Epoch 13/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6073 - accuracy: 0.8075 - val_loss: 1.6849 - val_accuracy: 0.3046\n",
      "Epoch 14/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5247 - accuracy: 0.8612 - val_loss: 1.7096 - val_accuracy: 0.2529\n",
      "Epoch 15/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4538 - accuracy: 0.8838 - val_loss: 1.8549 - val_accuracy: 0.2759\n",
      "Epoch 16/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4155 - accuracy: 0.8737 - val_loss: 1.8402 - val_accuracy: 0.2356\n",
      "Epoch 17/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3669 - accuracy: 0.9100 - val_loss: 1.9229 - val_accuracy: 0.2874\n",
      "Epoch 18/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3297 - accuracy: 0.9062 - val_loss: 1.9944 - val_accuracy: 0.2701\n",
      "Epoch 19/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3065 - accuracy: 0.9025 - val_loss: 2.1058 - val_accuracy: 0.2931\n",
      "Epoch 20/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2673 - accuracy: 0.9300 - val_loss: 2.2067 - val_accuracy: 0.2701\n",
      "Epoch 21/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2378 - accuracy: 0.9325 - val_loss: 2.2701 - val_accuracy: 0.2816\n",
      "Epoch 22/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2532 - accuracy: 0.9312 - val_loss: 2.2867 - val_accuracy: 0.2759\n",
      "Epoch 23/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2453 - accuracy: 0.9250 - val_loss: 2.3384 - val_accuracy: 0.2586\n",
      "Epoch 24/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2020 - accuracy: 0.9475 - val_loss: 2.3876 - val_accuracy: 0.2989\n",
      "Epoch 25/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1842 - accuracy: 0.9550 - val_loss: 2.4661 - val_accuracy: 0.2471\n",
      "Epoch 26/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1796 - accuracy: 0.9362 - val_loss: 2.5447 - val_accuracy: 0.2644\n",
      "Epoch 27/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1747 - accuracy: 0.9400 - val_loss: 2.5942 - val_accuracy: 0.2874\n",
      "Epoch 28/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1570 - accuracy: 0.9525 - val_loss: 2.6306 - val_accuracy: 0.2644\n",
      "Epoch 29/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1559 - accuracy: 0.9550 - val_loss: 2.6589 - val_accuracy: 0.2701\n",
      "Epoch 30/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1446 - accuracy: 0.9625 - val_loss: 2.6767 - val_accuracy: 0.2644\n",
      "Epoch 31/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1366 - accuracy: 0.9538 - val_loss: 2.7890 - val_accuracy: 0.2644\n",
      "Epoch 32/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1362 - accuracy: 0.9563 - val_loss: 2.7724 - val_accuracy: 0.2701\n",
      "Epoch 33/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1289 - accuracy: 0.9550 - val_loss: 2.8275 - val_accuracy: 0.2701\n",
      "Epoch 34/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1124 - accuracy: 0.9625 - val_loss: 2.8532 - val_accuracy: 0.2586\n",
      "Epoch 35/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1231 - accuracy: 0.9600 - val_loss: 2.8405 - val_accuracy: 0.2759\n",
      "Epoch 36/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1304 - accuracy: 0.9525 - val_loss: 2.9061 - val_accuracy: 0.2701\n",
      "Epoch 37/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1199 - accuracy: 0.9513 - val_loss: 2.9607 - val_accuracy: 0.2701\n",
      "Epoch 38/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1150 - accuracy: 0.9638 - val_loss: 3.0136 - val_accuracy: 0.2759\n",
      "Epoch 39/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1315 - accuracy: 0.9588 - val_loss: 3.0093 - val_accuracy: 0.2701\n",
      "Epoch 40/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1132 - accuracy: 0.9663 - val_loss: 3.0099 - val_accuracy: 0.2931\n",
      "Epoch 41/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1144 - accuracy: 0.9600 - val_loss: 2.9697 - val_accuracy: 0.2931\n",
      "Epoch 42/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1198 - accuracy: 0.9525 - val_loss: 2.9975 - val_accuracy: 0.2759\n",
      "Epoch 43/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1100 - accuracy: 0.9638 - val_loss: 2.9954 - val_accuracy: 0.2586\n",
      "Epoch 44/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1058 - accuracy: 0.9575 - val_loss: 3.0364 - val_accuracy: 0.2529\n",
      "Epoch 45/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1168 - accuracy: 0.9563 - val_loss: 3.1465 - val_accuracy: 0.2816\n",
      "Epoch 46/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1059 - accuracy: 0.9563 - val_loss: 3.1290 - val_accuracy: 0.2701\n",
      "Epoch 47/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1035 - accuracy: 0.9663 - val_loss: 3.1234 - val_accuracy: 0.2816\n",
      "Epoch 48/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0999 - accuracy: 0.9563 - val_loss: 3.1851 - val_accuracy: 0.2701\n",
      "Epoch 49/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0999 - accuracy: 0.9638 - val_loss: 3.2823 - val_accuracy: 0.2644\n",
      "Epoch 50/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1018 - accuracy: 0.9663 - val_loss: 3.2847 - val_accuracy: 0.2644\n",
      "Epoch 51/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1029 - accuracy: 0.9625 - val_loss: 3.2544 - val_accuracy: 0.2759\n",
      "Epoch 52/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0990 - accuracy: 0.9638 - val_loss: 3.2350 - val_accuracy: 0.2644\n",
      "Epoch 53/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 0.9613 - val_loss: 3.2385 - val_accuracy: 0.2644\n",
      "Epoch 54/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0921 - accuracy: 0.9600 - val_loss: 3.2467 - val_accuracy: 0.2816\n",
      "Epoch 55/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1003 - accuracy: 0.9575 - val_loss: 3.3112 - val_accuracy: 0.2701\n",
      "Epoch 56/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0912 - accuracy: 0.9663 - val_loss: 3.3630 - val_accuracy: 0.2471\n",
      "Epoch 57/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9650 - val_loss: 3.4080 - val_accuracy: 0.2414\n",
      "Epoch 58/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0804 - accuracy: 0.9663 - val_loss: 3.4566 - val_accuracy: 0.2529\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0747 - accuracy: 0.9675 - val_loss: 3.5409 - val_accuracy: 0.2529\n",
      "Epoch 60/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 0.9638 - val_loss: 3.5684 - val_accuracy: 0.2586\n",
      "Epoch 61/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0846 - accuracy: 0.9625 - val_loss: 3.6241 - val_accuracy: 0.2644\n",
      "Epoch 62/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0725 - accuracy: 0.9725 - val_loss: 3.6897 - val_accuracy: 0.2816\n",
      "Epoch 63/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0777 - accuracy: 0.9650 - val_loss: 3.6534 - val_accuracy: 0.2529\n",
      "Epoch 64/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0876 - accuracy: 0.9625 - val_loss: 3.6252 - val_accuracy: 0.2471\n",
      "Epoch 65/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0738 - accuracy: 0.9688 - val_loss: 3.6752 - val_accuracy: 0.2586\n",
      "Epoch 66/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0878 - accuracy: 0.9600 - val_loss: 3.6800 - val_accuracy: 0.2586\n",
      "Epoch 67/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0898 - accuracy: 0.9563 - val_loss: 3.6218 - val_accuracy: 0.2586\n",
      "Epoch 68/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0734 - accuracy: 0.9650 - val_loss: 3.5650 - val_accuracy: 0.2644\n",
      "Epoch 69/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0756 - accuracy: 0.9625 - val_loss: 3.5840 - val_accuracy: 0.2529\n",
      "Epoch 70/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0741 - accuracy: 0.9675 - val_loss: 3.6428 - val_accuracy: 0.2414\n",
      "Epoch 71/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0762 - accuracy: 0.9638 - val_loss: 3.6309 - val_accuracy: 0.2701\n",
      "Epoch 72/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0765 - accuracy: 0.9663 - val_loss: 3.6199 - val_accuracy: 0.2874\n",
      "Epoch 73/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0692 - accuracy: 0.9613 - val_loss: 3.6370 - val_accuracy: 0.2701\n",
      "Epoch 74/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0759 - accuracy: 0.9650 - val_loss: 3.7257 - val_accuracy: 0.2644\n",
      "Epoch 75/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0731 - accuracy: 0.9613 - val_loss: 3.7504 - val_accuracy: 0.2586\n",
      "Epoch 76/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0695 - accuracy: 0.9737 - val_loss: 3.7741 - val_accuracy: 0.2874\n",
      "Epoch 77/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0705 - accuracy: 0.9600 - val_loss: 3.7998 - val_accuracy: 0.2931\n",
      "Epoch 78/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0706 - accuracy: 0.9663 - val_loss: 3.8288 - val_accuracy: 0.2644\n",
      "Epoch 79/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0757 - accuracy: 0.9638 - val_loss: 3.8463 - val_accuracy: 0.2414\n",
      "Epoch 80/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0658 - accuracy: 0.9625 - val_loss: 3.8313 - val_accuracy: 0.2586\n",
      "Epoch 81/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0722 - accuracy: 0.9613 - val_loss: 3.8495 - val_accuracy: 0.2816\n",
      "Epoch 82/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0773 - accuracy: 0.9650 - val_loss: 3.8490 - val_accuracy: 0.2701\n",
      "Epoch 83/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0792 - accuracy: 0.9625 - val_loss: 3.8055 - val_accuracy: 0.2874\n",
      "Epoch 84/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0703 - accuracy: 0.9663 - val_loss: 3.8299 - val_accuracy: 0.2816\n",
      "Epoch 85/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0764 - accuracy: 0.9575 - val_loss: 3.8288 - val_accuracy: 0.2586\n",
      "Epoch 86/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0778 - accuracy: 0.9650 - val_loss: 3.9040 - val_accuracy: 0.2644\n",
      "Epoch 87/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0718 - accuracy: 0.9588 - val_loss: 3.9618 - val_accuracy: 0.2586\n",
      "Epoch 88/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0691 - accuracy: 0.9663 - val_loss: 4.0157 - val_accuracy: 0.2644\n",
      "Epoch 89/300\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0727 - accuracy: 0.9650 - val_loss: 4.0143 - val_accuracy: 0.2586\n",
      "Epoch 90/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0615 - accuracy: 0.9737 - val_loss: 3.9960 - val_accuracy: 0.2586\n",
      "Epoch 91/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0695 - accuracy: 0.9688 - val_loss: 4.0130 - val_accuracy: 0.2586\n",
      "Epoch 92/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0591 - accuracy: 0.9737 - val_loss: 4.0594 - val_accuracy: 0.2701\n",
      "Epoch 93/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0652 - accuracy: 0.9700 - val_loss: 4.0373 - val_accuracy: 0.2701\n",
      "Epoch 94/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0679 - accuracy: 0.9675 - val_loss: 3.9882 - val_accuracy: 0.2701\n",
      "Epoch 95/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0706 - accuracy: 0.9575 - val_loss: 4.0098 - val_accuracy: 0.2644\n",
      "Epoch 96/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0644 - accuracy: 0.9600 - val_loss: 4.0472 - val_accuracy: 0.2759\n",
      "Epoch 97/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0677 - accuracy: 0.9675 - val_loss: 4.0196 - val_accuracy: 0.2586\n",
      "Epoch 98/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0685 - accuracy: 0.9688 - val_loss: 4.0442 - val_accuracy: 0.2701\n",
      "Epoch 99/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0606 - accuracy: 0.9650 - val_loss: 4.0708 - val_accuracy: 0.2586\n",
      "Epoch 100/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0617 - accuracy: 0.9700 - val_loss: 4.1107 - val_accuracy: 0.2759\n",
      "Epoch 101/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0741 - accuracy: 0.9650 - val_loss: 4.1187 - val_accuracy: 0.2701\n",
      "Epoch 102/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0719 - accuracy: 0.9625 - val_loss: 4.0960 - val_accuracy: 0.2471\n",
      "Epoch 103/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0589 - accuracy: 0.9712 - val_loss: 4.0612 - val_accuracy: 0.2586\n",
      "Epoch 104/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0669 - accuracy: 0.9638 - val_loss: 4.0618 - val_accuracy: 0.2701\n",
      "Epoch 105/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0756 - accuracy: 0.9588 - val_loss: 4.0564 - val_accuracy: 0.2931\n",
      "Epoch 106/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0712 - accuracy: 0.9625 - val_loss: 4.0455 - val_accuracy: 0.2816\n",
      "Epoch 107/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0687 - accuracy: 0.9700 - val_loss: 4.0787 - val_accuracy: 0.2529\n",
      "Epoch 108/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0672 - accuracy: 0.9663 - val_loss: 4.1459 - val_accuracy: 0.2586\n",
      "Epoch 109/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0729 - accuracy: 0.9700 - val_loss: 4.1191 - val_accuracy: 0.2701\n",
      "Epoch 110/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9675 - val_loss: 4.1633 - val_accuracy: 0.2989\n",
      "Epoch 111/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0625 - accuracy: 0.9700 - val_loss: 4.1663 - val_accuracy: 0.2874\n",
      "Epoch 112/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0730 - accuracy: 0.9575 - val_loss: 4.1216 - val_accuracy: 0.2759\n",
      "Epoch 113/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0736 - accuracy: 0.9613 - val_loss: 4.0972 - val_accuracy: 0.2356\n",
      "Epoch 114/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0661 - accuracy: 0.9613 - val_loss: 4.1291 - val_accuracy: 0.2356\n",
      "Epoch 115/300\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0658 - accuracy: 0.9675 - val_loss: 4.1463 - val_accuracy: 0.2586\n",
      "Epoch 116/300\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0624 - accuracy: 0.9663 - val_loss: 4.1832 - val_accuracy: 0.2759\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0611 - accuracy: 0.9638 - val_loss: 4.2190 - val_accuracy: 0.2759\n",
      "Epoch 118/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0614 - accuracy: 0.9675 - val_loss: 4.2161 - val_accuracy: 0.2816\n",
      "Epoch 119/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0611 - accuracy: 0.9700 - val_loss: 4.2119 - val_accuracy: 0.2816\n",
      "Epoch 120/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0643 - accuracy: 0.9650 - val_loss: 4.2355 - val_accuracy: 0.2759\n",
      "Epoch 121/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0673 - accuracy: 0.9613 - val_loss: 4.2495 - val_accuracy: 0.2759\n",
      "Epoch 122/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0594 - accuracy: 0.9688 - val_loss: 4.2325 - val_accuracy: 0.2644\n",
      "Epoch 123/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0572 - accuracy: 0.9712 - val_loss: 4.2590 - val_accuracy: 0.2874\n",
      "Epoch 124/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0637 - accuracy: 0.9688 - val_loss: 4.2825 - val_accuracy: 0.2874\n",
      "Epoch 125/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0735 - accuracy: 0.9575 - val_loss: 4.2944 - val_accuracy: 0.2701\n",
      "Epoch 126/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0732 - accuracy: 0.9625 - val_loss: 4.2780 - val_accuracy: 0.2816\n",
      "Epoch 127/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0657 - accuracy: 0.9663 - val_loss: 4.2795 - val_accuracy: 0.2701\n",
      "Epoch 128/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0694 - accuracy: 0.9650 - val_loss: 4.2811 - val_accuracy: 0.2701\n",
      "Epoch 129/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0638 - accuracy: 0.9688 - val_loss: 4.3269 - val_accuracy: 0.3046\n",
      "Epoch 130/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0665 - accuracy: 0.9688 - val_loss: 4.3561 - val_accuracy: 0.2816\n",
      "Epoch 131/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.9638 - val_loss: 4.3744 - val_accuracy: 0.2816\n",
      "Epoch 132/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0618 - accuracy: 0.9650 - val_loss: 4.3223 - val_accuracy: 0.2874\n",
      "Epoch 133/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0592 - accuracy: 0.9688 - val_loss: 4.1910 - val_accuracy: 0.2759\n",
      "Epoch 134/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0600 - accuracy: 0.9663 - val_loss: 4.2242 - val_accuracy: 0.2759\n",
      "Epoch 135/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0647 - accuracy: 0.9663 - val_loss: 4.2617 - val_accuracy: 0.2816\n",
      "Epoch 136/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0665 - accuracy: 0.9675 - val_loss: 4.2805 - val_accuracy: 0.2816\n",
      "Epoch 137/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0593 - accuracy: 0.9663 - val_loss: 4.3291 - val_accuracy: 0.2874\n",
      "Epoch 138/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0635 - accuracy: 0.9625 - val_loss: 4.3968 - val_accuracy: 0.2816\n",
      "Epoch 139/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0585 - accuracy: 0.9663 - val_loss: 4.5167 - val_accuracy: 0.2759\n",
      "Epoch 140/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0627 - accuracy: 0.9663 - val_loss: 4.5691 - val_accuracy: 0.2701\n",
      "Epoch 141/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0626 - accuracy: 0.9663 - val_loss: 4.5292 - val_accuracy: 0.2644\n",
      "Epoch 142/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0599 - accuracy: 0.9675 - val_loss: 4.5094 - val_accuracy: 0.2586\n",
      "Epoch 143/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0643 - accuracy: 0.9625 - val_loss: 4.5134 - val_accuracy: 0.2759\n",
      "Epoch 144/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0590 - accuracy: 0.9663 - val_loss: 4.4833 - val_accuracy: 0.2701\n",
      "Epoch 145/300\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0580 - accuracy: 0.9688 - val_loss: 4.4924 - val_accuracy: 0.2644\n",
      "Epoch 146/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0659 - accuracy: 0.9588 - val_loss: 4.4612 - val_accuracy: 0.2644\n",
      "Epoch 147/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0632 - accuracy: 0.9588 - val_loss: 4.4535 - val_accuracy: 0.2701\n",
      "Epoch 148/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0552 - accuracy: 0.9700 - val_loss: 4.5285 - val_accuracy: 0.2701\n",
      "Epoch 149/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0599 - accuracy: 0.9650 - val_loss: 4.5926 - val_accuracy: 0.2644\n",
      "Epoch 150/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0544 - accuracy: 0.9700 - val_loss: 4.6251 - val_accuracy: 0.2644\n",
      "Epoch 151/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0521 - accuracy: 0.9700 - val_loss: 4.6489 - val_accuracy: 0.2644\n",
      "Epoch 152/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0567 - accuracy: 0.9688 - val_loss: 4.6573 - val_accuracy: 0.2586\n",
      "Epoch 153/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0623 - accuracy: 0.9688 - val_loss: 4.6942 - val_accuracy: 0.2701\n",
      "Epoch 154/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0607 - accuracy: 0.9688 - val_loss: 4.7075 - val_accuracy: 0.2644\n",
      "Epoch 155/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0635 - accuracy: 0.9675 - val_loss: 4.6472 - val_accuracy: 0.2529\n",
      "Epoch 156/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0572 - accuracy: 0.9663 - val_loss: 4.6199 - val_accuracy: 0.2529\n",
      "Epoch 157/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0637 - accuracy: 0.9688 - val_loss: 4.6360 - val_accuracy: 0.2529\n",
      "Epoch 158/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0560 - accuracy: 0.9700 - val_loss: 4.6621 - val_accuracy: 0.2644\n",
      "Epoch 159/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0681 - accuracy: 0.9575 - val_loss: 4.6179 - val_accuracy: 0.2759\n",
      "Epoch 160/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0571 - accuracy: 0.9600 - val_loss: 4.6166 - val_accuracy: 0.2816\n",
      "Epoch 161/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0553 - accuracy: 0.9675 - val_loss: 4.6624 - val_accuracy: 0.2529\n",
      "Epoch 162/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0547 - accuracy: 0.9688 - val_loss: 4.7493 - val_accuracy: 0.2644\n",
      "Epoch 163/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0677 - accuracy: 0.9563 - val_loss: 4.7251 - val_accuracy: 0.2586\n",
      "Epoch 164/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0592 - accuracy: 0.9650 - val_loss: 4.6588 - val_accuracy: 0.2931\n",
      "Epoch 165/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0536 - accuracy: 0.9700 - val_loss: 4.6566 - val_accuracy: 0.2931\n",
      "Epoch 166/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0607 - accuracy: 0.9688 - val_loss: 4.6974 - val_accuracy: 0.2874\n",
      "Epoch 167/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9700 - val_loss: 4.6880 - val_accuracy: 0.2701\n",
      "Epoch 168/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0589 - accuracy: 0.9700 - val_loss: 4.6497 - val_accuracy: 0.2644\n",
      "Epoch 169/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0603 - accuracy: 0.9663 - val_loss: 4.6683 - val_accuracy: 0.2701\n",
      "Epoch 170/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.9688 - val_loss: 4.6826 - val_accuracy: 0.2701\n",
      "Epoch 171/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0599 - accuracy: 0.9638 - val_loss: 4.6777 - val_accuracy: 0.2586\n",
      "Epoch 172/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0608 - accuracy: 0.9575 - val_loss: 4.6652 - val_accuracy: 0.2586\n",
      "Epoch 173/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0592 - accuracy: 0.9638 - val_loss: 4.6438 - val_accuracy: 0.2586\n",
      "Epoch 174/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0628 - accuracy: 0.9663 - val_loss: 4.6474 - val_accuracy: 0.2701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0624 - accuracy: 0.9675 - val_loss: 4.6221 - val_accuracy: 0.2701\n",
      "Epoch 176/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0594 - accuracy: 0.9638 - val_loss: 4.6196 - val_accuracy: 0.2586\n",
      "Epoch 177/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0631 - accuracy: 0.9588 - val_loss: 4.6593 - val_accuracy: 0.2644\n",
      "Epoch 178/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0603 - accuracy: 0.9650 - val_loss: 4.6979 - val_accuracy: 0.2759\n",
      "Epoch 179/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0612 - accuracy: 0.9688 - val_loss: 4.7203 - val_accuracy: 0.2644\n",
      "Epoch 180/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0573 - accuracy: 0.9725 - val_loss: 4.7841 - val_accuracy: 0.2701\n",
      "Epoch 181/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0625 - accuracy: 0.9625 - val_loss: 4.8268 - val_accuracy: 0.2529\n",
      "Epoch 182/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0549 - accuracy: 0.9650 - val_loss: 4.8635 - val_accuracy: 0.2644\n",
      "Epoch 183/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0620 - accuracy: 0.9663 - val_loss: 4.8786 - val_accuracy: 0.2644\n",
      "Epoch 184/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0633 - accuracy: 0.9650 - val_loss: 4.8558 - val_accuracy: 0.2701\n",
      "Epoch 185/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0557 - accuracy: 0.9675 - val_loss: 4.8024 - val_accuracy: 0.2586\n",
      "Epoch 186/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0611 - accuracy: 0.9663 - val_loss: 4.7581 - val_accuracy: 0.2586\n",
      "Epoch 187/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0543 - accuracy: 0.9688 - val_loss: 4.7338 - val_accuracy: 0.2644\n",
      "Epoch 188/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0645 - accuracy: 0.9663 - val_loss: 4.7596 - val_accuracy: 0.2816\n",
      "Epoch 189/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0544 - accuracy: 0.9700 - val_loss: 4.7245 - val_accuracy: 0.2586\n",
      "Epoch 190/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0538 - accuracy: 0.9688 - val_loss: 4.6944 - val_accuracy: 0.2759\n",
      "Epoch 191/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0617 - accuracy: 0.9663 - val_loss: 4.7352 - val_accuracy: 0.2931\n",
      "Epoch 192/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0624 - accuracy: 0.9613 - val_loss: 4.7043 - val_accuracy: 0.2759\n",
      "Epoch 193/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0559 - accuracy: 0.9650 - val_loss: 4.7031 - val_accuracy: 0.2586\n",
      "Epoch 194/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0651 - accuracy: 0.9638 - val_loss: 4.6948 - val_accuracy: 0.2471\n",
      "Epoch 195/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0569 - accuracy: 0.9688 - val_loss: 4.7277 - val_accuracy: 0.2816\n",
      "Epoch 196/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0610 - accuracy: 0.9650 - val_loss: 4.7287 - val_accuracy: 0.2989\n",
      "Epoch 197/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0641 - accuracy: 0.9712 - val_loss: 4.7931 - val_accuracy: 0.2816\n",
      "Epoch 198/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0607 - accuracy: 0.9663 - val_loss: 4.7578 - val_accuracy: 0.2874\n",
      "Epoch 199/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0573 - accuracy: 0.9688 - val_loss: 4.7817 - val_accuracy: 0.2874\n",
      "Epoch 200/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0574 - accuracy: 0.9675 - val_loss: 4.8317 - val_accuracy: 0.2874\n",
      "Epoch 201/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0589 - accuracy: 0.9613 - val_loss: 4.8511 - val_accuracy: 0.2816\n",
      "Epoch 202/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0612 - accuracy: 0.9613 - val_loss: 4.8461 - val_accuracy: 0.2874\n",
      "Epoch 203/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0604 - accuracy: 0.9625 - val_loss: 4.8610 - val_accuracy: 0.2644\n",
      "Epoch 204/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0533 - accuracy: 0.9625 - val_loss: 4.9109 - val_accuracy: 0.2644\n",
      "Epoch 205/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0594 - accuracy: 0.9688 - val_loss: 4.9871 - val_accuracy: 0.2529\n",
      "Epoch 206/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0649 - accuracy: 0.9675 - val_loss: 5.0057 - val_accuracy: 0.2471\n",
      "Epoch 207/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0586 - accuracy: 0.9663 - val_loss: 5.0420 - val_accuracy: 0.2701\n",
      "Epoch 208/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0553 - accuracy: 0.9688 - val_loss: 5.0050 - val_accuracy: 0.2874\n",
      "Epoch 209/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0589 - accuracy: 0.9675 - val_loss: 5.0001 - val_accuracy: 0.2874\n",
      "Epoch 210/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0637 - accuracy: 0.9575 - val_loss: 4.9502 - val_accuracy: 0.2874\n",
      "Epoch 211/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0535 - accuracy: 0.9700 - val_loss: 4.9075 - val_accuracy: 0.2586\n",
      "Epoch 212/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0578 - accuracy: 0.9638 - val_loss: 4.9043 - val_accuracy: 0.2471\n",
      "Epoch 213/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0607 - accuracy: 0.9625 - val_loss: 4.9231 - val_accuracy: 0.2701\n",
      "Epoch 214/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0588 - accuracy: 0.9625 - val_loss: 4.9786 - val_accuracy: 0.2759\n",
      "Epoch 215/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0666 - accuracy: 0.9600 - val_loss: 5.0129 - val_accuracy: 0.2701\n",
      "Epoch 216/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0550 - accuracy: 0.9688 - val_loss: 4.9604 - val_accuracy: 0.2701\n",
      "Epoch 217/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0541 - accuracy: 0.9663 - val_loss: 4.9459 - val_accuracy: 0.2816\n",
      "Epoch 218/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0596 - accuracy: 0.9663 - val_loss: 4.9614 - val_accuracy: 0.2816\n",
      "Epoch 219/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0618 - accuracy: 0.9625 - val_loss: 4.9215 - val_accuracy: 0.2816\n",
      "Epoch 220/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0593 - accuracy: 0.9613 - val_loss: 4.9598 - val_accuracy: 0.2701\n",
      "Epoch 221/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0575 - accuracy: 0.9675 - val_loss: 4.9899 - val_accuracy: 0.2816\n",
      "Epoch 222/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0562 - accuracy: 0.9675 - val_loss: 5.0228 - val_accuracy: 0.2874\n",
      "Epoch 223/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0569 - accuracy: 0.9663 - val_loss: 5.0512 - val_accuracy: 0.2874\n",
      "Epoch 224/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0498 - accuracy: 0.9700 - val_loss: 5.0767 - val_accuracy: 0.2816\n",
      "Epoch 225/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0573 - accuracy: 0.9737 - val_loss: 5.1146 - val_accuracy: 0.2816\n",
      "Epoch 226/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0609 - accuracy: 0.9638 - val_loss: 5.1084 - val_accuracy: 0.2759\n",
      "Epoch 227/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0599 - accuracy: 0.9625 - val_loss: 5.0922 - val_accuracy: 0.2586\n",
      "Epoch 228/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0548 - accuracy: 0.9650 - val_loss: 5.0866 - val_accuracy: 0.2701\n",
      "Epoch 229/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 0.9725 - val_loss: 5.1213 - val_accuracy: 0.2644\n",
      "Epoch 230/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0567 - accuracy: 0.9675 - val_loss: 5.1748 - val_accuracy: 0.2701\n",
      "Epoch 231/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0579 - accuracy: 0.9650 - val_loss: 5.1417 - val_accuracy: 0.2586\n",
      "Epoch 232/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0563 - accuracy: 0.9700 - val_loss: 5.1343 - val_accuracy: 0.2586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0525 - accuracy: 0.9725 - val_loss: 5.1577 - val_accuracy: 0.2816\n",
      "Epoch 234/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0563 - accuracy: 0.9663 - val_loss: 5.1697 - val_accuracy: 0.2874\n",
      "Epoch 235/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0605 - accuracy: 0.9625 - val_loss: 5.1421 - val_accuracy: 0.2644\n",
      "Epoch 236/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0520 - accuracy: 0.9663 - val_loss: 5.1361 - val_accuracy: 0.2586\n",
      "Epoch 237/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0574 - accuracy: 0.9650 - val_loss: 5.1495 - val_accuracy: 0.2529\n",
      "Epoch 238/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0581 - accuracy: 0.9650 - val_loss: 5.1979 - val_accuracy: 0.2299\n",
      "Epoch 239/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0545 - accuracy: 0.9663 - val_loss: 5.2387 - val_accuracy: 0.2586\n",
      "Epoch 240/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0527 - accuracy: 0.9650 - val_loss: 5.3879 - val_accuracy: 0.2586\n",
      "Epoch 241/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0590 - accuracy: 0.9663 - val_loss: 5.3704 - val_accuracy: 0.2586\n",
      "Epoch 242/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0533 - accuracy: 0.9663 - val_loss: 5.2420 - val_accuracy: 0.2529\n",
      "Epoch 243/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0516 - accuracy: 0.9688 - val_loss: 5.1860 - val_accuracy: 0.2586\n",
      "Epoch 244/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0493 - accuracy: 0.9712 - val_loss: 5.2259 - val_accuracy: 0.2529\n",
      "Epoch 245/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0561 - accuracy: 0.9675 - val_loss: 5.2698 - val_accuracy: 0.2471\n",
      "Epoch 246/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0555 - accuracy: 0.9700 - val_loss: 5.3152 - val_accuracy: 0.2529\n",
      "Epoch 247/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0529 - accuracy: 0.9725 - val_loss: 5.2521 - val_accuracy: 0.2471\n",
      "Epoch 248/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0556 - accuracy: 0.9613 - val_loss: 5.2055 - val_accuracy: 0.2644\n",
      "Epoch 249/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0575 - accuracy: 0.9613 - val_loss: 5.1620 - val_accuracy: 0.2701\n",
      "Epoch 250/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0543 - accuracy: 0.9663 - val_loss: 5.1375 - val_accuracy: 0.2759\n",
      "Epoch 251/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0529 - accuracy: 0.9688 - val_loss: 5.1920 - val_accuracy: 0.2931\n",
      "Epoch 252/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0591 - accuracy: 0.9638 - val_loss: 5.2193 - val_accuracy: 0.2931\n",
      "Epoch 253/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 0.9625 - val_loss: 5.2172 - val_accuracy: 0.2759\n",
      "Epoch 254/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 0.9675 - val_loss: 5.2170 - val_accuracy: 0.2874\n",
      "Epoch 255/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9663 - val_loss: 5.2079 - val_accuracy: 0.2989\n",
      "Epoch 256/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0511 - accuracy: 0.9725 - val_loss: 5.1925 - val_accuracy: 0.2874\n",
      "Epoch 257/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0516 - accuracy: 0.9725 - val_loss: 5.2242 - val_accuracy: 0.2874\n",
      "Epoch 258/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0547 - accuracy: 0.9700 - val_loss: 5.2325 - val_accuracy: 0.2759\n",
      "Epoch 259/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0552 - accuracy: 0.9675 - val_loss: 5.2596 - val_accuracy: 0.2644\n",
      "Epoch 260/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0546 - accuracy: 0.9700 - val_loss: 5.2986 - val_accuracy: 0.2644\n",
      "Epoch 261/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0586 - accuracy: 0.9625 - val_loss: 5.3266 - val_accuracy: 0.2874\n",
      "Epoch 262/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0532 - accuracy: 0.9650 - val_loss: 5.2879 - val_accuracy: 0.3046\n",
      "Epoch 263/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0543 - accuracy: 0.9650 - val_loss: 5.2565 - val_accuracy: 0.3046\n",
      "Epoch 264/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0550 - accuracy: 0.9688 - val_loss: 5.2672 - val_accuracy: 0.2874\n",
      "Epoch 265/300\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0506 - accuracy: 0.9737 - val_loss: 5.2944 - val_accuracy: 0.2816\n",
      "Epoch 266/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0509 - accuracy: 0.9688 - val_loss: 5.3249 - val_accuracy: 0.2874\n",
      "Epoch 267/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0549 - accuracy: 0.9663 - val_loss: 5.3325 - val_accuracy: 0.2816\n",
      "Epoch 268/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0574 - accuracy: 0.9638 - val_loss: 5.3166 - val_accuracy: 0.3046\n",
      "Epoch 269/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0568 - accuracy: 0.9625 - val_loss: 5.2989 - val_accuracy: 0.3046\n",
      "Epoch 270/300\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0555 - accuracy: 0.9650 - val_loss: 5.2963 - val_accuracy: 0.2989\n",
      "Epoch 271/300\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0572 - accuracy: 0.9638 - val_loss: 5.2737 - val_accuracy: 0.2874\n",
      "Epoch 272/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0564 - accuracy: 0.9625 - val_loss: 5.3051 - val_accuracy: 0.2759\n",
      "Epoch 273/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0544 - accuracy: 0.9675 - val_loss: 5.3769 - val_accuracy: 0.2644\n",
      "Epoch 274/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0496 - accuracy: 0.9762 - val_loss: 5.4381 - val_accuracy: 0.2701\n",
      "Epoch 275/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0722 - accuracy: 0.9663 - val_loss: 5.3615 - val_accuracy: 0.2874\n",
      "Epoch 276/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0524 - accuracy: 0.9750 - val_loss: 5.4638 - val_accuracy: 0.2759\n",
      "Epoch 277/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0681 - accuracy: 0.9563 - val_loss: 5.2517 - val_accuracy: 0.2874\n",
      "Epoch 278/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0596 - accuracy: 0.9638 - val_loss: 5.0965 - val_accuracy: 0.2759\n",
      "Epoch 279/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0629 - accuracy: 0.9650 - val_loss: 4.9589 - val_accuracy: 0.2701\n",
      "Epoch 280/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0558 - accuracy: 0.9638 - val_loss: 5.0376 - val_accuracy: 0.2816\n",
      "Epoch 281/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0534 - accuracy: 0.9663 - val_loss: 5.1260 - val_accuracy: 0.2989\n",
      "Epoch 282/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0571 - accuracy: 0.9663 - val_loss: 5.2126 - val_accuracy: 0.2989\n",
      "Epoch 283/300\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0509 - accuracy: 0.9712 - val_loss: 5.2777 - val_accuracy: 0.2931\n",
      "Epoch 284/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0497 - accuracy: 0.9650 - val_loss: 5.3982 - val_accuracy: 0.2989\n",
      "Epoch 285/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0548 - accuracy: 0.9638 - val_loss: 5.4534 - val_accuracy: 0.2989\n",
      "Epoch 286/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0564 - accuracy: 0.9688 - val_loss: 5.4651 - val_accuracy: 0.2989\n",
      "Epoch 287/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0536 - accuracy: 0.9725 - val_loss: 5.4897 - val_accuracy: 0.2989\n",
      "Epoch 288/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0520 - accuracy: 0.9725 - val_loss: 5.4988 - val_accuracy: 0.2989\n",
      "Epoch 289/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0496 - accuracy: 0.9688 - val_loss: 5.5056 - val_accuracy: 0.2874\n",
      "Epoch 290/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0486 - accuracy: 0.9712 - val_loss: 5.5353 - val_accuracy: 0.2874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0493 - accuracy: 0.9638 - val_loss: 5.6073 - val_accuracy: 0.2931\n",
      "Epoch 292/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0559 - accuracy: 0.9675 - val_loss: 5.6641 - val_accuracy: 0.2816\n",
      "Epoch 293/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0584 - accuracy: 0.9600 - val_loss: 5.6760 - val_accuracy: 0.2931\n",
      "Epoch 294/300\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0570 - accuracy: 0.9638 - val_loss: 5.7144 - val_accuracy: 0.2989\n",
      "Epoch 295/300\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0509 - accuracy: 0.9700 - val_loss: 5.7184 - val_accuracy: 0.3046\n",
      "Epoch 296/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0554 - accuracy: 0.9675 - val_loss: 5.6691 - val_accuracy: 0.3046\n",
      "Epoch 297/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0518 - accuracy: 0.9712 - val_loss: 5.6276 - val_accuracy: 0.2989\n",
      "Epoch 298/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0559 - accuracy: 0.9675 - val_loss: 5.5635 - val_accuracy: 0.2931\n",
      "Epoch 299/300\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0575 - accuracy: 0.9550 - val_loss: 5.5025 - val_accuracy: 0.2759\n",
      "Epoch 300/300\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0593 - accuracy: 0.9725 - val_loss: 5.4989 - val_accuracy: 0.2931\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_X, training_y, epochs = 300, validation_data=(test_X, test_y), batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences= True, input_shape=training_X.shape)),\n",
    "    keras.layers.LSTM (64, return_sequences = True),\n",
    "    keras.layers.LSTM (128,  return_sequences = True),\n",
    "    keras.layers.LSTM (256, return_sequences = True),\n",
    "    keras.layers.LSTM (64),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "opt = keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-07,\n",
    "    centered=False,\n",
    ")\n",
    "\n",
    "#opt = keras.optimizers.SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#opt = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model2.compile(loss='sparse_categorical_crossentropy',optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f028897e5df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model2 = keras.Sequential([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-378732ef5219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \"\"\"\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2352\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6344 - accuracy: 0.3325 - val_loss: 1.5614 - val_accuracy: 0.3851\n",
      "Epoch 2/240\n",
      "7/7 [==============================] - 5s 730ms/step - loss: 1.4206 - accuracy: 0.3700 - val_loss: 1.3421 - val_accuracy: 0.3851\n",
      "Epoch 3/240\n",
      "7/7 [==============================] - 5s 724ms/step - loss: 1.3759 - accuracy: 0.3700 - val_loss: 1.3420 - val_accuracy: 0.2874\n",
      "Epoch 4/240\n",
      "7/7 [==============================] - 5s 763ms/step - loss: 1.3566 - accuracy: 0.3587 - val_loss: 1.4241 - val_accuracy: 0.3563\n",
      "Epoch 5/240\n",
      "7/7 [==============================] - 5s 740ms/step - loss: 1.3667 - accuracy: 0.3675 - val_loss: 1.4362 - val_accuracy: 0.3851\n",
      "Epoch 6/240\n",
      "7/7 [==============================] - 5s 736ms/step - loss: 1.3783 - accuracy: 0.3700 - val_loss: 1.3640 - val_accuracy: 0.3851\n",
      "Epoch 7/240\n",
      "7/7 [==============================] - 5s 725ms/step - loss: 1.3595 - accuracy: 0.3700 - val_loss: 1.3488 - val_accuracy: 0.3851\n",
      "Epoch 8/240\n",
      "7/7 [==============================] - 6s 786ms/step - loss: 1.3635 - accuracy: 0.3700 - val_loss: 1.3960 - val_accuracy: 0.1494\n",
      "Epoch 9/240\n",
      "7/7 [==============================] - 5s 744ms/step - loss: 1.3807 - accuracy: 0.3262 - val_loss: 1.3636 - val_accuracy: 0.3851\n",
      "Epoch 10/240\n",
      "7/7 [==============================] - 5s 740ms/step - loss: 1.3562 - accuracy: 0.3700 - val_loss: 1.3407 - val_accuracy: 0.3851\n",
      "Epoch 11/240\n",
      "7/7 [==============================] - 5s 734ms/step - loss: 1.3641 - accuracy: 0.3700 - val_loss: 1.3229 - val_accuracy: 0.3851\n",
      "Epoch 12/240\n",
      "7/7 [==============================] - 5s 730ms/step - loss: 1.3551 - accuracy: 0.3700 - val_loss: 1.3420 - val_accuracy: 0.3851\n",
      "Epoch 13/240\n",
      "7/7 [==============================] - 5s 723ms/step - loss: 1.3626 - accuracy: 0.3700 - val_loss: 1.3524 - val_accuracy: 0.3851\n",
      "Epoch 14/240\n",
      "7/7 [==============================] - 5s 754ms/step - loss: 1.3581 - accuracy: 0.3400 - val_loss: 1.3126 - val_accuracy: 0.3851\n",
      "Epoch 15/240\n",
      "7/7 [==============================] - 6s 803ms/step - loss: 1.3514 - accuracy: 0.3700 - val_loss: 1.3354 - val_accuracy: 0.3851\n",
      "Epoch 16/240\n",
      "7/7 [==============================] - 5s 743ms/step - loss: 1.3590 - accuracy: 0.3650 - val_loss: 1.3199 - val_accuracy: 0.3851\n",
      "Epoch 17/240\n",
      "7/7 [==============================] - 5s 762ms/step - loss: 1.3528 - accuracy: 0.3700 - val_loss: 1.3276 - val_accuracy: 0.3851\n",
      "Epoch 18/240\n",
      "7/7 [==============================] - 5s 779ms/step - loss: 1.3435 - accuracy: 0.3713 - val_loss: 1.3440 - val_accuracy: 0.3851\n",
      "Epoch 19/240\n",
      "7/7 [==============================] - 5s 744ms/step - loss: 1.3392 - accuracy: 0.3725 - val_loss: 1.3829 - val_accuracy: 0.3851\n",
      "Epoch 20/240\n",
      "7/7 [==============================] - 6s 828ms/step - loss: 1.3681 - accuracy: 0.3525 - val_loss: 1.3757 - val_accuracy: 0.1897\n",
      "Epoch 21/240\n",
      "7/7 [==============================] - 7s 967ms/step - loss: 1.3452 - accuracy: 0.3338 - val_loss: 1.3495 - val_accuracy: 0.3678\n",
      "Epoch 22/240\n",
      "7/7 [==============================] - 6s 848ms/step - loss: 1.3261 - accuracy: 0.3787 - val_loss: 1.3649 - val_accuracy: 0.3908\n",
      "Epoch 23/240\n",
      "7/7 [==============================] - 5s 749ms/step - loss: 1.4138 - accuracy: 0.3450 - val_loss: 1.3504 - val_accuracy: 0.3736\n",
      "Epoch 24/240\n",
      "7/7 [==============================] - 5s 727ms/step - loss: 1.3140 - accuracy: 0.3975 - val_loss: 1.3680 - val_accuracy: 0.3678\n",
      "Epoch 25/240\n",
      "7/7 [==============================] - 5s 757ms/step - loss: 1.3147 - accuracy: 0.4025 - val_loss: 1.3661 - val_accuracy: 0.3851\n",
      "Epoch 26/240\n",
      "7/7 [==============================] - 5s 755ms/step - loss: 1.3146 - accuracy: 0.3913 - val_loss: 1.3776 - val_accuracy: 0.2816\n",
      "Epoch 27/240\n",
      "7/7 [==============================] - 6s 788ms/step - loss: 1.3095 - accuracy: 0.3862 - val_loss: 1.4074 - val_accuracy: 0.2586\n",
      "Epoch 28/240\n",
      "7/7 [==============================] - 5s 775ms/step - loss: 1.3110 - accuracy: 0.4013 - val_loss: 1.4042 - val_accuracy: 0.3793\n",
      "Epoch 29/240\n",
      "7/7 [==============================] - 5s 733ms/step - loss: 1.3191 - accuracy: 0.3887 - val_loss: 1.3703 - val_accuracy: 0.3793\n",
      "Epoch 30/240\n",
      "7/7 [==============================] - 5s 743ms/step - loss: 1.3192 - accuracy: 0.3800 - val_loss: 1.4590 - val_accuracy: 0.1782\n",
      "Epoch 31/240\n",
      "7/7 [==============================] - 5s 752ms/step - loss: 1.3225 - accuracy: 0.3713 - val_loss: 1.3928 - val_accuracy: 0.3736\n",
      "Epoch 32/240\n",
      "7/7 [==============================] - 5s 749ms/step - loss: 1.2958 - accuracy: 0.4013 - val_loss: 1.3778 - val_accuracy: 0.3678\n",
      "Epoch 33/240\n",
      "7/7 [==============================] - 5s 754ms/step - loss: 1.3163 - accuracy: 0.3875 - val_loss: 1.4260 - val_accuracy: 0.2989\n",
      "Epoch 34/240\n",
      "7/7 [==============================] - 5s 736ms/step - loss: 1.2979 - accuracy: 0.4025 - val_loss: 1.3833 - val_accuracy: 0.3851\n",
      "Epoch 35/240\n",
      "7/7 [==============================] - 6s 795ms/step - loss: 1.3228 - accuracy: 0.3762 - val_loss: 1.4881 - val_accuracy: 0.3851\n",
      "Epoch 36/240\n",
      "7/7 [==============================] - 6s 791ms/step - loss: 1.3412 - accuracy: 0.4050 - val_loss: 1.4267 - val_accuracy: 0.2644\n",
      "Epoch 37/240\n",
      "7/7 [==============================] - 6s 807ms/step - loss: 1.3170 - accuracy: 0.3875 - val_loss: 1.3622 - val_accuracy: 0.3736\n",
      "Epoch 38/240\n",
      "7/7 [==============================] - 5s 727ms/step - loss: 1.2864 - accuracy: 0.4025 - val_loss: 1.3819 - val_accuracy: 0.3621\n",
      "Epoch 39/240\n",
      "7/7 [==============================] - 5s 749ms/step - loss: 1.2925 - accuracy: 0.4100 - val_loss: 1.3775 - val_accuracy: 0.3736\n",
      "Epoch 40/240\n",
      "7/7 [==============================] - 5s 749ms/step - loss: 1.2600 - accuracy: 0.4112 - val_loss: 1.6116 - val_accuracy: 0.1379\n",
      "Epoch 41/240\n",
      "7/7 [==============================] - 5s 750ms/step - loss: 1.3406 - accuracy: 0.3487 - val_loss: 1.4178 - val_accuracy: 0.3908\n",
      "Epoch 42/240\n",
      "7/7 [==============================] - 6s 789ms/step - loss: 1.2836 - accuracy: 0.3925 - val_loss: 1.3873 - val_accuracy: 0.3563\n",
      "Epoch 43/240\n",
      "7/7 [==============================] - 5s 726ms/step - loss: 1.2617 - accuracy: 0.4250 - val_loss: 1.4412 - val_accuracy: 0.3103\n",
      "Epoch 44/240\n",
      "7/7 [==============================] - 5s 745ms/step - loss: 1.2433 - accuracy: 0.4200 - val_loss: 1.4942 - val_accuracy: 0.1897\n",
      "Epoch 45/240\n",
      "7/7 [==============================] - 5s 751ms/step - loss: 1.3026 - accuracy: 0.3887 - val_loss: 1.3902 - val_accuracy: 0.3563\n",
      "Epoch 46/240\n",
      "7/7 [==============================] - 5s 778ms/step - loss: 1.2770 - accuracy: 0.4225 - val_loss: 1.4532 - val_accuracy: 0.2989\n",
      "Epoch 47/240\n",
      "7/7 [==============================] - 5s 783ms/step - loss: 1.2584 - accuracy: 0.4137 - val_loss: 1.4224 - val_accuracy: 0.3046\n",
      "Epoch 48/240\n",
      "7/7 [==============================] - 5s 737ms/step - loss: 1.2740 - accuracy: 0.3950 - val_loss: 1.4234 - val_accuracy: 0.3103\n",
      "Epoch 49/240\n",
      "7/7 [==============================] - 5s 781ms/step - loss: 1.1916 - accuracy: 0.4688 - val_loss: 1.4560 - val_accuracy: 0.3218\n",
      "Epoch 50/240\n",
      "7/7 [==============================] - 6s 815ms/step - loss: 1.2702 - accuracy: 0.4238 - val_loss: 1.4250 - val_accuracy: 0.2816\n",
      "Epoch 51/240\n",
      "7/7 [==============================] - 5s 738ms/step - loss: 1.2177 - accuracy: 0.4275 - val_loss: 1.5479 - val_accuracy: 0.2644\n",
      "Epoch 52/240\n",
      "7/7 [==============================] - 6s 819ms/step - loss: 1.2159 - accuracy: 0.4613 - val_loss: 1.5092 - val_accuracy: 0.2126\n",
      "Epoch 53/240\n",
      "7/7 [==============================] - 6s 795ms/step - loss: 1.2144 - accuracy: 0.4412 - val_loss: 1.4961 - val_accuracy: 0.3448\n",
      "Epoch 54/240\n",
      "7/7 [==============================] - 5s 750ms/step - loss: 1.2602 - accuracy: 0.4200 - val_loss: 1.4217 - val_accuracy: 0.3678\n",
      "Epoch 55/240\n",
      "7/7 [==============================] - 5s 781ms/step - loss: 1.1959 - accuracy: 0.4725 - val_loss: 1.4957 - val_accuracy: 0.3391\n",
      "Epoch 56/240\n",
      "7/7 [==============================] - 5s 778ms/step - loss: 1.2190 - accuracy: 0.4700 - val_loss: 1.5778 - val_accuracy: 0.2184\n",
      "Epoch 57/240\n",
      "7/7 [==============================] - 6s 798ms/step - loss: 1.2340 - accuracy: 0.4588 - val_loss: 1.4967 - val_accuracy: 0.2759\n",
      "Epoch 58/240\n",
      "7/7 [==============================] - 5s 735ms/step - loss: 1.1204 - accuracy: 0.5213 - val_loss: 1.6109 - val_accuracy: 0.2184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/240\n",
      "7/7 [==============================] - 5s 750ms/step - loss: 1.1982 - accuracy: 0.4663 - val_loss: 1.5065 - val_accuracy: 0.3333\n",
      "Epoch 60/240\n",
      "7/7 [==============================] - 5s 763ms/step - loss: 1.1676 - accuracy: 0.4963 - val_loss: 1.5660 - val_accuracy: 0.1839\n",
      "Epoch 61/240\n",
      "7/7 [==============================] - 5s 785ms/step - loss: 1.1634 - accuracy: 0.5025 - val_loss: 1.6632 - val_accuracy: 0.1954\n",
      "Epoch 62/240\n",
      "7/7 [==============================] - 5s 736ms/step - loss: 1.2002 - accuracy: 0.4750 - val_loss: 1.6618 - val_accuracy: 0.2069\n",
      "Epoch 63/240\n",
      "7/7 [==============================] - 5s 769ms/step - loss: 1.0902 - accuracy: 0.5437 - val_loss: 1.5894 - val_accuracy: 0.2126\n",
      "Epoch 64/240\n",
      "7/7 [==============================] - 5s 757ms/step - loss: 1.1080 - accuracy: 0.5163 - val_loss: 1.5990 - val_accuracy: 0.2644\n",
      "Epoch 65/240\n",
      "7/7 [==============================] - 5s 775ms/step - loss: 1.1466 - accuracy: 0.5075 - val_loss: 1.5285 - val_accuracy: 0.2989\n",
      "Epoch 66/240\n",
      "7/7 [==============================] - 5s 776ms/step - loss: 1.1563 - accuracy: 0.4988 - val_loss: 1.6302 - val_accuracy: 0.3103\n",
      "Epoch 67/240\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 1.1261 - accuracy: 0.5263 - val_loss: 1.6253 - val_accuracy: 0.2069\n",
      "Epoch 68/240\n",
      "7/7 [==============================] - 6s 811ms/step - loss: 1.1226 - accuracy: 0.5100 - val_loss: 1.5468 - val_accuracy: 0.2816\n",
      "Epoch 69/240\n",
      "7/7 [==============================] - 6s 837ms/step - loss: 1.0265 - accuracy: 0.5625 - val_loss: 1.7610 - val_accuracy: 0.2011\n",
      "Epoch 70/240\n",
      "7/7 [==============================] - 6s 795ms/step - loss: 1.0994 - accuracy: 0.5362 - val_loss: 1.5458 - val_accuracy: 0.2414\n",
      "Epoch 71/240\n",
      "7/7 [==============================] - 5s 746ms/step - loss: 1.0858 - accuracy: 0.5475 - val_loss: 1.6422 - val_accuracy: 0.2874\n",
      "Epoch 72/240\n",
      "7/7 [==============================] - 5s 749ms/step - loss: 1.0720 - accuracy: 0.5375 - val_loss: 1.6232 - val_accuracy: 0.2759\n",
      "Epoch 73/240\n",
      "7/7 [==============================] - 5s 766ms/step - loss: 1.0933 - accuracy: 0.5412 - val_loss: 1.6638 - val_accuracy: 0.2299\n",
      "Epoch 74/240\n",
      "7/7 [==============================] - 6s 790ms/step - loss: 1.0484 - accuracy: 0.5663 - val_loss: 1.6428 - val_accuracy: 0.2586\n",
      "Epoch 75/240\n",
      "7/7 [==============================] - 5s 740ms/step - loss: 0.9930 - accuracy: 0.5938 - val_loss: 1.8321 - val_accuracy: 0.2011\n",
      "Epoch 76/240\n",
      "7/7 [==============================] - 6s 798ms/step - loss: 1.1059 - accuracy: 0.5025 - val_loss: 1.7284 - val_accuracy: 0.2011\n",
      "Epoch 77/240\n",
      "7/7 [==============================] - 6s 794ms/step - loss: 1.0921 - accuracy: 0.5263 - val_loss: 1.6921 - val_accuracy: 0.2586\n",
      "Epoch 78/240\n",
      "7/7 [==============================] - 5s 777ms/step - loss: 1.0030 - accuracy: 0.5838 - val_loss: 1.6988 - val_accuracy: 0.1667\n",
      "Epoch 79/240\n",
      "7/7 [==============================] - 5s 773ms/step - loss: 1.0186 - accuracy: 0.5638 - val_loss: 1.9165 - val_accuracy: 0.1839\n",
      "Epoch 80/240\n",
      "7/7 [==============================] - 5s 779ms/step - loss: 1.0305 - accuracy: 0.5713 - val_loss: 1.8073 - val_accuracy: 0.2241\n",
      "Epoch 81/240\n",
      "7/7 [==============================] - 6s 793ms/step - loss: 0.9089 - accuracy: 0.6425 - val_loss: 1.8225 - val_accuracy: 0.2184\n",
      "Epoch 82/240\n",
      "7/7 [==============================] - 5s 768ms/step - loss: 1.0189 - accuracy: 0.5713 - val_loss: 1.8392 - val_accuracy: 0.1782\n",
      "Epoch 83/240\n",
      "7/7 [==============================] - 5s 784ms/step - loss: 1.0365 - accuracy: 0.5625 - val_loss: 1.7053 - val_accuracy: 0.3103\n",
      "Epoch 84/240\n",
      "7/7 [==============================] - 6s 823ms/step - loss: 0.9415 - accuracy: 0.6150 - val_loss: 1.9588 - val_accuracy: 0.1897\n",
      "Epoch 85/240\n",
      "7/7 [==============================] - 6s 795ms/step - loss: 1.0358 - accuracy: 0.5625 - val_loss: 1.8041 - val_accuracy: 0.1897\n",
      "Epoch 86/240\n",
      "7/7 [==============================] - 5s 781ms/step - loss: 0.8653 - accuracy: 0.6812 - val_loss: 1.7405 - val_accuracy: 0.3103\n",
      "Epoch 87/240\n",
      "7/7 [==============================] - 6s 850ms/step - loss: 0.9688 - accuracy: 0.6087 - val_loss: 1.8629 - val_accuracy: 0.2759\n",
      "Epoch 88/240\n",
      "7/7 [==============================] - 5s 754ms/step - loss: 0.9935 - accuracy: 0.5900 - val_loss: 1.9802 - val_accuracy: 0.2011\n",
      "Epoch 89/240\n",
      "7/7 [==============================] - 6s 832ms/step - loss: 0.9615 - accuracy: 0.6150 - val_loss: 1.9162 - val_accuracy: 0.2069\n",
      "Epoch 90/240\n",
      "7/7 [==============================] - 6s 807ms/step - loss: 0.9663 - accuracy: 0.6162 - val_loss: 1.9341 - val_accuracy: 0.1782\n",
      "Epoch 91/240\n",
      "7/7 [==============================] - 5s 763ms/step - loss: 1.0160 - accuracy: 0.5850 - val_loss: 1.8238 - val_accuracy: 0.2644\n",
      "Epoch 92/240\n",
      "7/7 [==============================] - 6s 909ms/step - loss: 0.9078 - accuracy: 0.6375 - val_loss: 1.7944 - val_accuracy: 0.3161\n",
      "Epoch 93/240\n",
      "7/7 [==============================] - 7s 948ms/step - loss: 0.8624 - accuracy: 0.6612 - val_loss: 1.8411 - val_accuracy: 0.2529\n",
      "Epoch 94/240\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.8371 - accuracy: 0.6725 - val_loss: 2.0084 - val_accuracy: 0.2759\n",
      "Epoch 95/240\n",
      "7/7 [==============================] - 5s 767ms/step - loss: 0.9427 - accuracy: 0.6125 - val_loss: 1.7942 - val_accuracy: 0.2931\n",
      "Epoch 96/240\n",
      "7/7 [==============================] - 6s 808ms/step - loss: 0.8110 - accuracy: 0.6825 - val_loss: 2.0257 - val_accuracy: 0.2644\n",
      "Epoch 97/240\n",
      "7/7 [==============================] - 5s 785ms/step - loss: 0.8299 - accuracy: 0.6837 - val_loss: 1.9278 - val_accuracy: 0.2759\n",
      "Epoch 98/240\n",
      "7/7 [==============================] - 5s 777ms/step - loss: 1.0188 - accuracy: 0.6025 - val_loss: 2.0754 - val_accuracy: 0.2126\n",
      "Epoch 99/240\n",
      "7/7 [==============================] - 6s 802ms/step - loss: 0.9149 - accuracy: 0.6488 - val_loss: 1.8616 - val_accuracy: 0.3103\n",
      "Epoch 100/240\n",
      "7/7 [==============================] - 5s 753ms/step - loss: 0.7980 - accuracy: 0.7075 - val_loss: 2.0992 - val_accuracy: 0.2356\n",
      "Epoch 101/240\n",
      "7/7 [==============================] - 5s 768ms/step - loss: 0.8610 - accuracy: 0.6712 - val_loss: 2.0255 - val_accuracy: 0.2816\n",
      "Epoch 102/240\n",
      "7/7 [==============================] - 6s 884ms/step - loss: 0.8619 - accuracy: 0.6637 - val_loss: 1.9553 - val_accuracy: 0.2586\n",
      "Epoch 103/240\n",
      "7/7 [==============================] - 5s 774ms/step - loss: 0.7435 - accuracy: 0.7350 - val_loss: 2.0642 - val_accuracy: 0.2011\n",
      "Epoch 104/240\n",
      "7/7 [==============================] - 5s 761ms/step - loss: 0.9363 - accuracy: 0.6250 - val_loss: 1.8623 - val_accuracy: 0.2759\n",
      "Epoch 105/240\n",
      "7/7 [==============================] - 5s 773ms/step - loss: 0.7640 - accuracy: 0.7100 - val_loss: 2.0512 - val_accuracy: 0.2874\n",
      "Epoch 106/240\n",
      "7/7 [==============================] - 5s 724ms/step - loss: 0.8860 - accuracy: 0.6500 - val_loss: 2.1013 - val_accuracy: 0.2529\n",
      "Epoch 107/240\n",
      "7/7 [==============================] - 6s 849ms/step - loss: 0.7285 - accuracy: 0.7287 - val_loss: 2.1472 - val_accuracy: 0.2414\n",
      "Epoch 108/240\n",
      "7/7 [==============================] - 6s 793ms/step - loss: 0.8226 - accuracy: 0.6775 - val_loss: 2.0588 - val_accuracy: 0.2069\n",
      "Epoch 109/240\n",
      "7/7 [==============================] - 5s 739ms/step - loss: 0.8038 - accuracy: 0.6913 - val_loss: 1.9994 - val_accuracy: 0.3391\n",
      "Epoch 110/240\n",
      "7/7 [==============================] - 6s 811ms/step - loss: 0.7550 - accuracy: 0.7150 - val_loss: 2.2348 - val_accuracy: 0.2184\n",
      "Epoch 111/240\n",
      "7/7 [==============================] - 6s 789ms/step - loss: 0.8592 - accuracy: 0.6550 - val_loss: 2.1212 - val_accuracy: 0.2644\n",
      "Epoch 112/240\n",
      "7/7 [==============================] - 5s 748ms/step - loss: 0.7473 - accuracy: 0.7312 - val_loss: 2.2548 - val_accuracy: 0.2184\n",
      "Epoch 113/240\n",
      "7/7 [==============================] - 6s 815ms/step - loss: 0.7483 - accuracy: 0.7250 - val_loss: 2.2746 - val_accuracy: 0.2644\n",
      "Epoch 114/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.7283 - accuracy: 0.7300 - val_loss: 2.2038 - val_accuracy: 0.2356\n",
      "Epoch 115/240\n",
      "7/7 [==============================] - 7s 978ms/step - loss: 0.7020 - accuracy: 0.7387 - val_loss: 2.1818 - val_accuracy: 0.2414\n",
      "Epoch 116/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 797ms/step - loss: 0.7112 - accuracy: 0.7412 - val_loss: 2.2391 - val_accuracy: 0.2816\n",
      "Epoch 117/240\n",
      "7/7 [==============================] - 6s 795ms/step - loss: 0.7743 - accuracy: 0.6913 - val_loss: 1.9540 - val_accuracy: 0.2816\n",
      "Epoch 118/240\n",
      "7/7 [==============================] - 5s 723ms/step - loss: 0.7407 - accuracy: 0.7125 - val_loss: 2.1045 - val_accuracy: 0.2356\n",
      "Epoch 119/240\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 0.6677 - accuracy: 0.7362 - val_loss: 2.1611 - val_accuracy: 0.2874\n",
      "Epoch 120/240\n",
      "7/7 [==============================] - 5s 774ms/step - loss: 0.6845 - accuracy: 0.7525 - val_loss: 2.2713 - val_accuracy: 0.2471\n",
      "Epoch 121/240\n",
      "7/7 [==============================] - 6s 809ms/step - loss: 0.8031 - accuracy: 0.6812 - val_loss: 2.2671 - val_accuracy: 0.2759\n",
      "Epoch 122/240\n",
      "7/7 [==============================] - 6s 912ms/step - loss: 0.6718 - accuracy: 0.7437 - val_loss: 2.2528 - val_accuracy: 0.2644\n",
      "Epoch 123/240\n",
      "7/7 [==============================] - 5s 764ms/step - loss: 0.7317 - accuracy: 0.7275 - val_loss: 2.1797 - val_accuracy: 0.3391\n",
      "Epoch 124/240\n",
      "7/7 [==============================] - 5s 753ms/step - loss: 0.7528 - accuracy: 0.7188 - val_loss: 2.3538 - val_accuracy: 0.2356\n",
      "Epoch 125/240\n",
      "7/7 [==============================] - 5s 765ms/step - loss: 0.5814 - accuracy: 0.7862 - val_loss: 2.5250 - val_accuracy: 0.1897\n",
      "Epoch 126/240\n",
      "7/7 [==============================] - 6s 827ms/step - loss: 0.7085 - accuracy: 0.7225 - val_loss: 2.2295 - val_accuracy: 0.2701\n",
      "Epoch 127/240\n",
      "7/7 [==============================] - 5s 778ms/step - loss: 0.6069 - accuracy: 0.7688 - val_loss: 2.3569 - val_accuracy: 0.2356\n",
      "Epoch 128/240\n",
      "7/7 [==============================] - 6s 805ms/step - loss: 0.5677 - accuracy: 0.7900 - val_loss: 2.3696 - val_accuracy: 0.2356\n",
      "Epoch 129/240\n",
      "7/7 [==============================] - 6s 789ms/step - loss: 0.7413 - accuracy: 0.7038 - val_loss: 2.3441 - val_accuracy: 0.2241\n",
      "Epoch 130/240\n",
      "7/7 [==============================] - 5s 745ms/step - loss: 0.6372 - accuracy: 0.7525 - val_loss: 2.6379 - val_accuracy: 0.2356\n",
      "Epoch 131/240\n",
      "7/7 [==============================] - 5s 778ms/step - loss: 0.7906 - accuracy: 0.6975 - val_loss: 2.3388 - val_accuracy: 0.2414\n",
      "Epoch 132/240\n",
      "7/7 [==============================] - 5s 759ms/step - loss: 0.5425 - accuracy: 0.7962 - val_loss: 2.3772 - val_accuracy: 0.2586\n",
      "Epoch 133/240\n",
      "7/7 [==============================] - 5s 745ms/step - loss: 0.6372 - accuracy: 0.7638 - val_loss: 2.6085 - val_accuracy: 0.2529\n",
      "Epoch 134/240\n",
      "7/7 [==============================] - 6s 809ms/step - loss: 0.7465 - accuracy: 0.6975 - val_loss: 2.3085 - val_accuracy: 0.2299\n",
      "Epoch 135/240\n",
      "7/7 [==============================] - 5s 762ms/step - loss: 0.4931 - accuracy: 0.8112 - val_loss: 2.5760 - val_accuracy: 0.2471\n",
      "Epoch 136/240\n",
      "7/7 [==============================] - 5s 764ms/step - loss: 0.7247 - accuracy: 0.7375 - val_loss: 2.4096 - val_accuracy: 0.2069\n",
      "Epoch 137/240\n",
      "7/7 [==============================] - 5s 776ms/step - loss: 0.5888 - accuracy: 0.7613 - val_loss: 2.5244 - val_accuracy: 0.2356\n",
      "Epoch 138/240\n",
      "7/7 [==============================] - 5s 722ms/step - loss: 0.4371 - accuracy: 0.8363 - val_loss: 2.6221 - val_accuracy: 0.2586\n",
      "Epoch 139/240\n",
      "7/7 [==============================] - 6s 792ms/step - loss: 0.5278 - accuracy: 0.8100 - val_loss: 2.7408 - val_accuracy: 0.2069\n",
      "Epoch 140/240\n",
      "7/7 [==============================] - 6s 821ms/step - loss: 0.6294 - accuracy: 0.7550 - val_loss: 2.4514 - val_accuracy: 0.2759\n",
      "Epoch 141/240\n",
      "7/7 [==============================] - 5s 779ms/step - loss: 0.6367 - accuracy: 0.7600 - val_loss: 2.5778 - val_accuracy: 0.2414\n",
      "Epoch 142/240\n",
      "7/7 [==============================] - 6s 801ms/step - loss: 0.5326 - accuracy: 0.7750 - val_loss: 2.6551 - val_accuracy: 0.2184\n",
      "Epoch 143/240\n",
      "7/7 [==============================] - 6s 889ms/step - loss: 0.5366 - accuracy: 0.7862 - val_loss: 2.3753 - val_accuracy: 0.2874\n",
      "Epoch 144/240\n",
      "7/7 [==============================] - 6s 906ms/step - loss: 0.6274 - accuracy: 0.7500 - val_loss: 2.5357 - val_accuracy: 0.2644\n",
      "Epoch 145/240\n",
      "7/7 [==============================] - 6s 887ms/step - loss: 0.6676 - accuracy: 0.7575 - val_loss: 2.6251 - val_accuracy: 0.2586\n",
      "Epoch 146/240\n",
      "7/7 [==============================] - 6s 854ms/step - loss: 0.4233 - accuracy: 0.8300 - val_loss: 2.4969 - val_accuracy: 0.3046\n",
      "Epoch 147/240\n",
      "7/7 [==============================] - 5s 761ms/step - loss: 0.4049 - accuracy: 0.8525 - val_loss: 2.7298 - val_accuracy: 0.2529\n",
      "Epoch 148/240\n",
      "7/7 [==============================] - 5s 762ms/step - loss: 0.5363 - accuracy: 0.7975 - val_loss: 2.7590 - val_accuracy: 0.1954\n",
      "Epoch 149/240\n",
      "7/7 [==============================] - 5s 758ms/step - loss: 0.6744 - accuracy: 0.7350 - val_loss: 2.5087 - val_accuracy: 0.3046\n",
      "Epoch 150/240\n",
      "7/7 [==============================] - 5s 743ms/step - loss: 0.4000 - accuracy: 0.8363 - val_loss: 2.8982 - val_accuracy: 0.2816\n",
      "Epoch 151/240\n",
      "7/7 [==============================] - 5s 779ms/step - loss: 0.6263 - accuracy: 0.7412 - val_loss: 2.7200 - val_accuracy: 0.2184\n",
      "Epoch 152/240\n",
      "7/7 [==============================] - 5s 771ms/step - loss: 0.4796 - accuracy: 0.8225 - val_loss: 3.0600 - val_accuracy: 0.2644\n",
      "Epoch 153/240\n",
      "7/7 [==============================] - 5s 782ms/step - loss: 0.5207 - accuracy: 0.8037 - val_loss: 2.8926 - val_accuracy: 0.2529\n",
      "Epoch 154/240\n",
      "7/7 [==============================] - 6s 841ms/step - loss: 0.4062 - accuracy: 0.8375 - val_loss: 3.0083 - val_accuracy: 0.2356\n",
      "Epoch 155/240\n",
      "7/7 [==============================] - 5s 765ms/step - loss: 0.4663 - accuracy: 0.8238 - val_loss: 2.7720 - val_accuracy: 0.2529\n",
      "Epoch 156/240\n",
      "7/7 [==============================] - 6s 804ms/step - loss: 0.4611 - accuracy: 0.8225 - val_loss: 3.1808 - val_accuracy: 0.2471\n",
      "Epoch 157/240\n",
      "7/7 [==============================] - 6s 823ms/step - loss: 0.6071 - accuracy: 0.7738 - val_loss: 2.8888 - val_accuracy: 0.2701\n",
      "Epoch 158/240\n",
      "7/7 [==============================] - 5s 776ms/step - loss: 0.3763 - accuracy: 0.8637 - val_loss: 2.7785 - val_accuracy: 0.3046\n",
      "Epoch 159/240\n",
      "7/7 [==============================] - 6s 806ms/step - loss: 0.6944 - accuracy: 0.7300 - val_loss: 2.5288 - val_accuracy: 0.2701\n",
      "Epoch 160/240\n",
      "7/7 [==============================] - 6s 804ms/step - loss: 0.3622 - accuracy: 0.8700 - val_loss: 2.7283 - val_accuracy: 0.2759\n",
      "Epoch 161/240\n",
      "7/7 [==============================] - 5s 743ms/step - loss: 0.3297 - accuracy: 0.8813 - val_loss: 2.9189 - val_accuracy: 0.2989\n",
      "Epoch 162/240\n",
      "7/7 [==============================] - 6s 903ms/step - loss: 0.5505 - accuracy: 0.7900 - val_loss: 2.6427 - val_accuracy: 0.2931\n",
      "Epoch 163/240\n",
      "7/7 [==============================] - 5s 776ms/step - loss: 0.5799 - accuracy: 0.7788 - val_loss: 2.8801 - val_accuracy: 0.2529\n",
      "Epoch 164/240\n",
      "7/7 [==============================] - 5s 756ms/step - loss: 0.3492 - accuracy: 0.8525 - val_loss: 3.1370 - val_accuracy: 0.2184\n",
      "Epoch 165/240\n",
      "7/7 [==============================] - 6s 801ms/step - loss: 0.3331 - accuracy: 0.8712 - val_loss: 3.0388 - val_accuracy: 0.2356\n",
      "Epoch 166/240\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.4010 - accuracy: 0.8475 - val_loss: 3.0599 - val_accuracy: 0.2586\n",
      "Epoch 167/240\n",
      "7/7 [==============================] - 5s 779ms/step - loss: 0.5469 - accuracy: 0.7987 - val_loss: 3.0661 - val_accuracy: 0.2529\n",
      "Epoch 168/240\n",
      "7/7 [==============================] - 5s 777ms/step - loss: 0.2936 - accuracy: 0.8750 - val_loss: 2.8286 - val_accuracy: 0.2701\n",
      "Epoch 169/240\n",
      "7/7 [==============================] - 5s 762ms/step - loss: 0.6334 - accuracy: 0.7688 - val_loss: 2.7966 - val_accuracy: 0.2069\n",
      "Epoch 170/240\n",
      "7/7 [==============================] - 7s 937ms/step - loss: 0.3700 - accuracy: 0.8687 - val_loss: 3.0287 - val_accuracy: 0.2529\n",
      "Epoch 171/240\n",
      "7/7 [==============================] - 6s 848ms/step - loss: 0.3790 - accuracy: 0.8475 - val_loss: 2.9999 - val_accuracy: 0.2874\n",
      "Epoch 172/240\n",
      "7/7 [==============================] - 5s 780ms/step - loss: 0.3185 - accuracy: 0.8750 - val_loss: 3.2554 - val_accuracy: 0.2586\n",
      "Epoch 173/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 833ms/step - loss: 0.3281 - accuracy: 0.8800 - val_loss: 3.1701 - val_accuracy: 0.2816\n",
      "Epoch 174/240\n",
      "7/7 [==============================] - 5s 743ms/step - loss: 0.5928 - accuracy: 0.8037 - val_loss: 2.6822 - val_accuracy: 0.2644\n",
      "Epoch 175/240\n",
      "7/7 [==============================] - 6s 788ms/step - loss: 0.3649 - accuracy: 0.8575 - val_loss: 3.1208 - val_accuracy: 0.2586\n",
      "Epoch 176/240\n",
      "7/7 [==============================] - 6s 855ms/step - loss: 0.2850 - accuracy: 0.8900 - val_loss: 3.0008 - val_accuracy: 0.3103\n",
      "Epoch 177/240\n",
      "7/7 [==============================] - 5s 785ms/step - loss: 0.3724 - accuracy: 0.8612 - val_loss: 3.1367 - val_accuracy: 0.2874\n",
      "Epoch 178/240\n",
      "7/7 [==============================] - 5s 782ms/step - loss: 0.3193 - accuracy: 0.8800 - val_loss: 3.4754 - val_accuracy: 0.1724\n",
      "Epoch 179/240\n",
      "7/7 [==============================] - 5s 783ms/step - loss: 0.5733 - accuracy: 0.8037 - val_loss: 3.1535 - val_accuracy: 0.2644\n",
      "Epoch 180/240\n",
      "7/7 [==============================] - 5s 731ms/step - loss: 0.2416 - accuracy: 0.9013 - val_loss: 3.0762 - val_accuracy: 0.2874\n",
      "Epoch 181/240\n",
      "7/7 [==============================] - 6s 791ms/step - loss: 0.4332 - accuracy: 0.8587 - val_loss: 3.1073 - val_accuracy: 0.2874\n",
      "Epoch 182/240\n",
      "7/7 [==============================] - 5s 762ms/step - loss: 0.2149 - accuracy: 0.9200 - val_loss: 3.4341 - val_accuracy: 0.2586\n",
      "Epoch 183/240\n",
      "7/7 [==============================] - 6s 788ms/step - loss: 0.2101 - accuracy: 0.9175 - val_loss: 3.1883 - val_accuracy: 0.2989\n",
      "Epoch 184/240\n",
      "7/7 [==============================] - 6s 807ms/step - loss: 0.4465 - accuracy: 0.8500 - val_loss: 3.1187 - val_accuracy: 0.1839\n",
      "Epoch 185/240\n",
      "7/7 [==============================] - 6s 791ms/step - loss: 0.4290 - accuracy: 0.8438 - val_loss: 3.2910 - val_accuracy: 0.2414\n",
      "Epoch 186/240\n",
      "7/7 [==============================] - 6s 787ms/step - loss: 0.2170 - accuracy: 0.9112 - val_loss: 3.3293 - val_accuracy: 0.3103\n",
      "Epoch 187/240\n",
      "7/7 [==============================] - 6s 813ms/step - loss: 0.2055 - accuracy: 0.9212 - val_loss: 3.5856 - val_accuracy: 0.2529\n",
      "Epoch 188/240\n",
      "7/7 [==============================] - 5s 737ms/step - loss: 0.5247 - accuracy: 0.8025 - val_loss: 2.7406 - val_accuracy: 0.2759\n",
      "Epoch 189/240\n",
      "7/7 [==============================] - 6s 807ms/step - loss: 0.3492 - accuracy: 0.8875 - val_loss: 3.3682 - val_accuracy: 0.2759\n",
      "Epoch 190/240\n",
      "7/7 [==============================] - 6s 828ms/step - loss: 0.2025 - accuracy: 0.9212 - val_loss: 3.4183 - val_accuracy: 0.2816\n",
      "Epoch 191/240\n",
      "7/7 [==============================] - 6s 827ms/step - loss: 0.3687 - accuracy: 0.8612 - val_loss: 3.1904 - val_accuracy: 0.2299\n",
      "Epoch 192/240\n",
      "7/7 [==============================] - 5s 755ms/step - loss: 0.3933 - accuracy: 0.8450 - val_loss: 3.1992 - val_accuracy: 0.2931\n",
      "Epoch 193/240\n",
      "7/7 [==============================] - 5s 738ms/step - loss: 0.2080 - accuracy: 0.9200 - val_loss: 3.4023 - val_accuracy: 0.2759\n",
      "Epoch 194/240\n",
      "7/7 [==============================] - 6s 807ms/step - loss: 0.1967 - accuracy: 0.9225 - val_loss: 3.8087 - val_accuracy: 0.2184\n",
      "Epoch 195/240\n",
      "7/7 [==============================] - 6s 822ms/step - loss: 0.3244 - accuracy: 0.8737 - val_loss: 3.4170 - val_accuracy: 0.2931\n",
      "Epoch 196/240\n",
      "7/7 [==============================] - 5s 782ms/step - loss: 0.5010 - accuracy: 0.8325 - val_loss: 2.8453 - val_accuracy: 0.2701\n",
      "Epoch 197/240\n",
      "7/7 [==============================] - 6s 826ms/step - loss: 0.3153 - accuracy: 0.8700 - val_loss: 3.2799 - val_accuracy: 0.3161\n",
      "Epoch 198/240\n",
      "7/7 [==============================] - 6s 853ms/step - loss: 0.2353 - accuracy: 0.9100 - val_loss: 3.5104 - val_accuracy: 0.2529\n",
      "Epoch 199/240\n",
      "7/7 [==============================] - 7s 955ms/step - loss: 0.1896 - accuracy: 0.9312 - val_loss: 3.1038 - val_accuracy: 0.2931\n",
      "Epoch 200/240\n",
      "7/7 [==============================] - 7s 947ms/step - loss: 0.3589 - accuracy: 0.8662 - val_loss: 3.3366 - val_accuracy: 0.2874\n",
      "Epoch 201/240\n",
      "7/7 [==============================] - 7s 949ms/step - loss: 0.2086 - accuracy: 0.9087 - val_loss: 3.5425 - val_accuracy: 0.2759\n",
      "Epoch 202/240\n",
      "7/7 [==============================] - 7s 968ms/step - loss: 0.3674 - accuracy: 0.8637 - val_loss: 3.0948 - val_accuracy: 0.3103\n",
      "Epoch 203/240\n",
      "7/7 [==============================] - 6s 830ms/step - loss: 0.3276 - accuracy: 0.8712 - val_loss: 3.3490 - val_accuracy: 0.2816\n",
      "Epoch 204/240\n",
      "7/7 [==============================] - 6s 893ms/step - loss: 0.1412 - accuracy: 0.9450 - val_loss: 3.5617 - val_accuracy: 0.2701\n",
      "Epoch 205/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.1651 - accuracy: 0.9375 - val_loss: 3.8024 - val_accuracy: 0.2471\n",
      "Epoch 206/240\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1886 - accuracy: 0.9287 - val_loss: 3.6635 - val_accuracy: 0.2874\n",
      "Epoch 207/240\n",
      "7/7 [==============================] - 7s 963ms/step - loss: 0.3773 - accuracy: 0.8525 - val_loss: 3.2643 - val_accuracy: 0.2356\n",
      "Epoch 208/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.4093 - accuracy: 0.8550 - val_loss: 3.2307 - val_accuracy: 0.3046\n",
      "Epoch 209/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.3043 - accuracy: 0.8813 - val_loss: 3.5917 - val_accuracy: 0.2701\n",
      "Epoch 210/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.1432 - accuracy: 0.9438 - val_loss: 3.7292 - val_accuracy: 0.2701\n",
      "Epoch 211/240\n",
      "7/7 [==============================] - 7s 958ms/step - loss: 0.1395 - accuracy: 0.9463 - val_loss: 3.7438 - val_accuracy: 0.2816\n",
      "Epoch 212/240\n",
      "7/7 [==============================] - 6s 844ms/step - loss: 0.1507 - accuracy: 0.9413 - val_loss: 3.4440 - val_accuracy: 0.3448\n",
      "Epoch 213/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.9293 - accuracy: 0.7063 - val_loss: 2.9284 - val_accuracy: 0.2586\n",
      "Epoch 214/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2657 - accuracy: 0.9038 - val_loss: 3.3803 - val_accuracy: 0.2816\n",
      "Epoch 215/240\n",
      "7/7 [==============================] - 7s 968ms/step - loss: 0.1475 - accuracy: 0.9425 - val_loss: 3.4974 - val_accuracy: 0.2816\n",
      "Epoch 216/240\n",
      "7/7 [==============================] - 6s 829ms/step - loss: 0.1593 - accuracy: 0.9388 - val_loss: 3.7389 - val_accuracy: 0.3046\n",
      "Epoch 217/240\n",
      "7/7 [==============================] - 6s 880ms/step - loss: 0.2260 - accuracy: 0.9112 - val_loss: 3.6621 - val_accuracy: 0.2414\n",
      "Epoch 218/240\n",
      "7/7 [==============================] - 6s 815ms/step - loss: 0.2433 - accuracy: 0.9038 - val_loss: 3.7746 - val_accuracy: 0.2644\n",
      "Epoch 219/240\n",
      "7/7 [==============================] - 6s 835ms/step - loss: 0.2626 - accuracy: 0.9025 - val_loss: 3.6806 - val_accuracy: 0.2644\n",
      "Epoch 220/240\n",
      "7/7 [==============================] - 6s 829ms/step - loss: 0.1688 - accuracy: 0.9362 - val_loss: 3.7917 - val_accuracy: 0.2701\n",
      "Epoch 221/240\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 0.5754 - accuracy: 0.8112 - val_loss: 2.6525 - val_accuracy: 0.3276\n",
      "Epoch 222/240\n",
      "7/7 [==============================] - 6s 895ms/step - loss: 0.2271 - accuracy: 0.9225 - val_loss: 3.3893 - val_accuracy: 0.3103\n",
      "Epoch 223/240\n",
      "7/7 [==============================] - 6s 833ms/step - loss: 0.1441 - accuracy: 0.9413 - val_loss: 3.6669 - val_accuracy: 0.2874\n",
      "Epoch 224/240\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 0.1898 - accuracy: 0.9300 - val_loss: 3.2384 - val_accuracy: 0.2299\n",
      "Epoch 225/240\n",
      "7/7 [==============================] - 6s 880ms/step - loss: 0.3971 - accuracy: 0.8650 - val_loss: 3.5193 - val_accuracy: 0.2759\n",
      "Epoch 226/240\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 0.1839 - accuracy: 0.9300 - val_loss: 3.6789 - val_accuracy: 0.2816\n",
      "Epoch 227/240\n",
      "7/7 [==============================] - 6s 824ms/step - loss: 0.2128 - accuracy: 0.9187 - val_loss: 3.5353 - val_accuracy: 0.2759\n",
      "Epoch 228/240\n",
      "7/7 [==============================] - 6s 869ms/step - loss: 0.2007 - accuracy: 0.9237 - val_loss: 3.8396 - val_accuracy: 0.2586\n",
      "Epoch 229/240\n",
      "7/7 [==============================] - 6s 838ms/step - loss: 0.1775 - accuracy: 0.9362 - val_loss: 3.7809 - val_accuracy: 0.3276\n",
      "Epoch 230/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 821ms/step - loss: 0.3315 - accuracy: 0.8838 - val_loss: 3.7289 - val_accuracy: 0.2701\n",
      "Epoch 231/240\n",
      "7/7 [==============================] - 6s 793ms/step - loss: 0.1373 - accuracy: 0.9350 - val_loss: 3.8879 - val_accuracy: 0.2644\n",
      "Epoch 232/240\n",
      "7/7 [==============================] - 6s 899ms/step - loss: 0.1883 - accuracy: 0.9187 - val_loss: 3.9005 - val_accuracy: 0.2586\n",
      "Epoch 233/240\n",
      "7/7 [==============================] - 6s 835ms/step - loss: 0.7068 - accuracy: 0.7800 - val_loss: 3.2241 - val_accuracy: 0.2701\n",
      "Epoch 234/240\n",
      "7/7 [==============================] - 7s 933ms/step - loss: 0.2465 - accuracy: 0.8900 - val_loss: 3.4799 - val_accuracy: 0.2701\n",
      "Epoch 235/240\n",
      "7/7 [==============================] - 7s 929ms/step - loss: 0.1461 - accuracy: 0.9375 - val_loss: 3.5630 - val_accuracy: 0.2759\n",
      "Epoch 236/240\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.1276 - accuracy: 0.9438 - val_loss: 3.8149 - val_accuracy: 0.2874\n",
      "Epoch 237/240\n",
      "7/7 [==============================] - 6s 791ms/step - loss: 0.2132 - accuracy: 0.9175 - val_loss: 3.6506 - val_accuracy: 0.2471\n",
      "Epoch 238/240\n",
      "7/7 [==============================] - 6s 786ms/step - loss: 0.1987 - accuracy: 0.9187 - val_loss: 3.8471 - val_accuracy: 0.2299\n",
      "Epoch 239/240\n",
      "7/7 [==============================] - 6s 824ms/step - loss: 0.2442 - accuracy: 0.9075 - val_loss: 3.6948 - val_accuracy: 0.2931\n",
      "Epoch 240/240\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.1534 - accuracy: 0.9262 - val_loss: 4.0588 - val_accuracy: 0.2356\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(training_X, training_y, epochs = 240, batch_size= 128, validation_data=(test_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
