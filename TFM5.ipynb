{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import keras\n",
    "import six\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,AveragePooling1D,Flatten,concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/roberto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/roberto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/roberto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/roberto/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abro el archivo en el que se encuentra el dataset de los problemas\n",
    "with open('singleop.json', 'r') as f:\n",
    "    datastore = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo que contiene un listado de nombres\n",
    "nombres = pd.read_csv('nombres-2015.csv')\n",
    "names = pd.read_csv('yob2019.txt', header=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('problemas_adicionales2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas = []\n",
    "respuestas = []\n",
    "ecuaciones = []\n",
    "alineacion = []\n",
    "\n",
    "for item in datastore:\n",
    "    preguntas.append(item['sQuestion'])\n",
    "    respuestas.append(item['lSolutions'])\n",
    "    ecuaciones.append(item['lEquations'])\n",
    "    alineacion.append(item['lAlignments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tengo  159  sumas  162  restas,  117  multiplicaciones,  124  divisiones y otras operaciones  0\n"
     ]
    }
   ],
   "source": [
    "# Necesito convertir el dataset en un problema de clasificacion para que la red neuronal pueda identificar\n",
    "# si estoy tratando de resolver un problema de sumas, restas, multiplicaciones o divisiones.\n",
    "# Esto va a crear una lista con el tipo de operacion y que va a ser el resultado a inferir.\n",
    "operaciones = []\n",
    "sumas =0\n",
    "restas =0\n",
    "multiplicaciones =0\n",
    "divisiones = 0\n",
    "otras = 0\n",
    "#Clasifico las operaciones en 0 para sumas, 1 para restas, 2 para multiplicaciones, 3 para divisiones y 4 sino lo encuentro.\n",
    "for operacion in ecuaciones:\n",
    "    if (operacion[0].find('+')>=0):\n",
    "        operaciones.append(0)\n",
    "        sumas = sumas + 1\n",
    "    elif (operacion[0].find('-') >= 0 ):\n",
    "        operaciones.append(1)\n",
    "        restas = restas + 1\n",
    "    elif(operacion[0].find('*') >=0):\n",
    "        operaciones.append(2)\n",
    "        multiplicaciones = multiplicaciones + 1\n",
    "    elif(operacion[0].find('/')):\n",
    "        operaciones.append(3)\n",
    "        divisiones = divisiones + 1\n",
    "    else:\n",
    "        operaciones.append(4)\n",
    "        otras = otras + 1\n",
    "\n",
    "print('Tengo ', sumas, ' sumas ', restas, ' restas, ', multiplicaciones, ' multiplicaciones, ', divisiones, ' divisiones y otras operaciones ', otras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas2 = dataset2['Preguntas'].tolist()\n",
    "respuestas2 = dataset2['respuestas'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas3 = preguntas + preguntas2\n",
    "respuestas3 = operaciones + respuestas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El listado de nombres lo voy a truncar a los 15K primeros, dado que el resto son nombres muy residuales.\n",
    "nombres_ = nombres['nombre'][:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_= names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_ = nombres_.append(names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_words = list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom = nombres['nombre'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomb =  nom + st_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sea'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomb[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El vector preguntas_sin, consiste en las preguntas a las que voy a eliminar todos los nombres propios que no\n",
    "# anaden ningun valor al conjunto de preguntas. No quiero que esos nombres se procesen y por tanto los elimino.\n",
    "def eliminar_palabras(dataset, stopw):\n",
    "    preguntas_sin = []\n",
    "    for palabras in dataset:\n",
    "        frases = [word for word in palabras.split(' ') if word not in stopw]\n",
    "        frases = \" \".join(frases)\n",
    "        preguntas_sin.append(frases)\n",
    "    return preguntas_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_sin = eliminar_palabras(preguntas3, nomb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "preguntas3, respuestas3 = shuffle(preguntas_sin,respuestas3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for i,pregunta in enumerate(preguntas_sin):\n",
    "    palabras = tokenizer.tokenize(pregunta)\n",
    "    preguntas_w = []\n",
    "    for palabra in palabras:\n",
    "        preguntas_w.append(palabra)\n",
    "    frases.append(preguntas_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_unicas = set(preguntas_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2305"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palabras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_unicas = list(palabras_unicas)\n",
    "\n",
    "#Voy a convertir los indices a escala logaritmica para evitar que puedan reventar los pesos en la red neuronal\n",
    "vocabulario = {p:i*0.0001 for i, p in enumerate(p_unicas)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamano max es  31  y la media de la longitud de las frases es de 12.803901437371664\n"
     ]
    }
   ],
   "source": [
    "tamanoMedio = 0\n",
    "tamanoTotal = 0\n",
    "\n",
    "for pregunta in frases:\n",
    "    if(len(pregunta) > tamanoTotal):\n",
    "        tamanoTotal = len(pregunta)\n",
    "    tamanoMedio = tamanoMedio + len(pregunta)\n",
    "\n",
    "print(\"El tamano max es \", tamanoTotal, \" y la media de la longitud de las frases es de\", tamanoMedio/len(frases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a meter en este vector todas mis preguntas y todas las palabras.\n",
    "# Para esta prueba, vamos a poner en la posición de la frase, el número de la palabra que estamos procesando.\n",
    "# El objetivo es procesar las palabras teniendo en cuenta el orden secuencial de la frase.\n",
    "bag = np.zeros([len(frases), tamanoTotal, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pregunta in enumerate(frases):\n",
    "    for j, palabras in enumerate(pregunta):\n",
    "        bag[i, tamanoTotal - len(pregunta) + j, 0] = vocabulario[palabras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [0.1292],\n",
       "       [0.0123],\n",
       "       [0.2296],\n",
       "       [0.0049],\n",
       "       [0.1921],\n",
       "       [0.0834],\n",
       "       [0.0123],\n",
       "       [0.2296],\n",
       "       [0.2054],\n",
       "       [0.1958],\n",
       "       [0.2296],\n",
       "       [0.1921]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_X = np.asarray(bag[:800])\n",
    "test_X = np.asarray(bag[800:])\n",
    "training_y = np.asarray(respuestas3[:800])\n",
    "test_y = np.asarray(respuestas3[800:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un modelo donde el primer argumento de la capa embedding son las palabras totales que voy a procesar\n",
    "# vectorizadas en un indice.\n",
    "# El segundo argumento, es el tamano del vector embedding, que he fijado en 16.\n",
    "# El tercer argumento, es el tamano o longitud maxima, que he definido para las preguntas. Numero total de palabras\n",
    "# por pregunta.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(36, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 0, 0, 1, 1, 1, 3, 2, 2, 2, 0, 1, 2, 1, 2, 3, 2, 0, 3, 0,\n",
       "       0, 1, 2, 2, 3, 1, 1, 1, 2, 1, 3, 0, 2, 0, 2, 1, 2, 1, 3, 1, 3, 3,\n",
       "       0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 1, 1, 2, 1, 2, 1, 3, 1, 0, 0, 1,\n",
       "       1, 3, 2, 3, 2, 1, 3, 0, 2, 3, 1, 0, 0, 3, 3, 0, 1, 3, 1, 1, 2, 1,\n",
       "       2, 2, 1, 3, 0, 0, 1, 1, 0, 1, 2, 3, 0, 1, 0, 1, 3, 2, 1, 1, 0, 0,\n",
       "       1, 3, 2, 1, 2, 3, 2, 0, 0, 3, 1, 1, 2, 1, 2, 2, 0, 3, 0, 1, 3, 0,\n",
       "       2, 3, 1, 3, 1, 1, 2, 2, 1, 0, 3, 2, 1, 1, 1, 3, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 3, 2, 3, 0, 1, 1, 1, 3, 3, 2, 2, 3, 1, 3, 0, 3,\n",
       "       1, 1, 0, 2, 3, 0, 3, 2, 2, 0, 3, 2, 1, 0, 0, 3, 1, 1, 1, 3, 3, 1,\n",
       "       0, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 0, 3, 2, 1, 1, 2, 1, 1, 1, 0, 1,\n",
       "       0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 3, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2,\n",
       "       1, 0, 3, 1, 2, 3, 2, 1, 1, 0, 0, 1, 2, 0, 1, 1, 2, 0, 1, 0, 3, 1,\n",
       "       0, 0, 1, 2, 1, 2, 3, 2, 1, 1, 1, 3, 1, 0, 0, 2, 1, 1, 2, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 2, 3, 3, 1, 2, 1, 0, 1, 2, 1, 3, 1, 0, 0, 2,\n",
       "       0, 0, 1, 3, 2, 0, 0, 2, 2, 1, 3, 0, 2, 0, 0, 1, 1, 1, 2, 3, 1, 2,\n",
       "       1, 1, 1, 0, 0, 2, 3, 1, 1, 3, 1, 1, 3, 3, 1, 2, 0, 3, 3, 2, 3, 2,\n",
       "       0, 1, 2, 0, 1, 0, 3, 2, 1, 1, 2, 1, 1, 3, 1, 0, 3, 0, 2, 1, 1, 1,\n",
       "       0, 1, 3, 1, 0, 1, 0, 3, 0, 2, 3, 0, 2, 1, 2, 2, 3, 0, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 3, 1, 3, 0, 0, 2, 1, 1, 1, 1, 0, 0, 1, 0, 3, 1, 2, 1,\n",
       "       0, 3, 1, 1, 0, 1, 3, 3, 0, 1, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 3, 3, 3, 1, 1, 0, 3, 1, 3, 1, 1, 1, 1, 2, 1,\n",
       "       1, 2, 0, 1, 1, 0, 2, 2, 2, 2, 1, 0, 2, 1, 3, 3, 1, 0, 1, 2, 1, 1,\n",
       "       0, 1, 1, 1, 1, 3, 2, 3, 2, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1,\n",
       "       0, 0, 2, 1, 2, 3, 1, 3, 1, 1, 3, 1, 1, 0, 1, 3, 1, 0, 2, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 3, 3, 3, 3, 1, 1, 3, 0, 2, 0, 3, 2, 0, 1, 2, 3,\n",
       "       3, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 1, 3, 1, 1, 1, 2, 1, 3,\n",
       "       3, 2, 1, 2, 1, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 3, 0, 3,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 2, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 3,\n",
       "       0, 1, 1, 0, 2, 0, 2, 3, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 2, 1,\n",
       "       1, 3, 1, 0, 1, 0, 1, 2, 1, 3, 2, 1, 1, 2, 0, 3, 3, 0, 2, 2, 3, 0,\n",
       "       3, 0, 0, 0, 2, 1, 3, 1, 2, 1, 0, 3, 0, 2, 1, 0, 1, 0, 2, 1, 2, 3,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 2, 2, 1, 1, 0, 3, 0, 0, 0, 2, 0, 2, 1, 2,\n",
       "       1, 0, 3, 1, 0, 3, 2, 3, 3, 0, 1, 0, 1, 1, 2, 0, 2, 1, 1, 1, 1, 1,\n",
       "       3, 1, 2, 1, 0, 2, 1, 0, 0, 1, 3, 0, 1, 1, 1, 1, 0, 2, 3, 1, 0, 3,\n",
       "       0, 1, 1, 1, 0, 0, 3, 1, 1, 3, 2, 0, 0, 3, 0, 1, 3, 2, 1, 1, 1, 2,\n",
       "       2, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 3, 1, 0, 0, 3, 2, 1, 1,\n",
       "       0, 0, 2, 1, 1, 3, 3, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.3834 - accuracy: 0.2825 - val_loss: 1.3788 - val_accuracy: 0.2529\n",
      "Epoch 2/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3645 - accuracy: 0.3500 - val_loss: 1.3711 - val_accuracy: 0.3448\n",
      "Epoch 3/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3514 - accuracy: 0.3812 - val_loss: 1.3672 - val_accuracy: 0.3448\n",
      "Epoch 4/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3383 - accuracy: 0.3787 - val_loss: 1.3682 - val_accuracy: 0.3448\n",
      "Epoch 5/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3341 - accuracy: 0.3787 - val_loss: 1.3745 - val_accuracy: 0.3448\n",
      "Epoch 6/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3343 - accuracy: 0.3787 - val_loss: 1.3808 - val_accuracy: 0.3448\n",
      "Epoch 7/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3329 - accuracy: 0.3787 - val_loss: 1.3807 - val_accuracy: 0.3448\n",
      "Epoch 8/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3316 - accuracy: 0.3787 - val_loss: 1.3763 - val_accuracy: 0.3448\n",
      "Epoch 9/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3286 - accuracy: 0.3787 - val_loss: 1.3755 - val_accuracy: 0.3448\n",
      "Epoch 10/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3282 - accuracy: 0.3787 - val_loss: 1.3746 - val_accuracy: 0.3448\n",
      "Epoch 11/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3309 - accuracy: 0.3787 - val_loss: 1.3739 - val_accuracy: 0.3448\n",
      "Epoch 12/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3296 - accuracy: 0.3787 - val_loss: 1.3751 - val_accuracy: 0.3448\n",
      "Epoch 13/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3283 - accuracy: 0.3787 - val_loss: 1.3770 - val_accuracy: 0.3448\n",
      "Epoch 14/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3272 - accuracy: 0.3787 - val_loss: 1.3788 - val_accuracy: 0.3448\n",
      "Epoch 15/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3243 - accuracy: 0.3787 - val_loss: 1.3815 - val_accuracy: 0.3448\n",
      "Epoch 16/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3283 - accuracy: 0.3787 - val_loss: 1.3838 - val_accuracy: 0.3448\n",
      "Epoch 17/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3297 - accuracy: 0.3787 - val_loss: 1.3817 - val_accuracy: 0.3448\n",
      "Epoch 18/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3235 - accuracy: 0.3787 - val_loss: 1.3801 - val_accuracy: 0.3448\n",
      "Epoch 19/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3256 - accuracy: 0.3787 - val_loss: 1.3798 - val_accuracy: 0.3448\n",
      "Epoch 20/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3204 - accuracy: 0.3787 - val_loss: 1.3803 - val_accuracy: 0.3448\n",
      "Epoch 21/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3261 - accuracy: 0.3787 - val_loss: 1.3815 - val_accuracy: 0.3448\n",
      "Epoch 22/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3245 - accuracy: 0.3787 - val_loss: 1.3841 - val_accuracy: 0.3448\n",
      "Epoch 23/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3250 - accuracy: 0.3787 - val_loss: 1.3841 - val_accuracy: 0.3448\n",
      "Epoch 24/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3215 - accuracy: 0.3787 - val_loss: 1.3863 - val_accuracy: 0.3448\n",
      "Epoch 25/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3166 - accuracy: 0.3787 - val_loss: 1.3880 - val_accuracy: 0.3448\n",
      "Epoch 26/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3219 - accuracy: 0.3787 - val_loss: 1.3883 - val_accuracy: 0.3448\n",
      "Epoch 27/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3189 - accuracy: 0.3787 - val_loss: 1.3863 - val_accuracy: 0.3448\n",
      "Epoch 28/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3180 - accuracy: 0.3800 - val_loss: 1.3856 - val_accuracy: 0.3448\n",
      "Epoch 29/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3162 - accuracy: 0.3775 - val_loss: 1.3857 - val_accuracy: 0.3448\n",
      "Epoch 30/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3190 - accuracy: 0.3800 - val_loss: 1.3879 - val_accuracy: 0.3448\n",
      "Epoch 31/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3135 - accuracy: 0.3775 - val_loss: 1.3886 - val_accuracy: 0.3448\n",
      "Epoch 32/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3110 - accuracy: 0.3800 - val_loss: 1.3935 - val_accuracy: 0.3448\n",
      "Epoch 33/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3141 - accuracy: 0.3837 - val_loss: 1.3960 - val_accuracy: 0.3448\n",
      "Epoch 34/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3053 - accuracy: 0.3862 - val_loss: 1.3969 - val_accuracy: 0.3448\n",
      "Epoch 35/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3123 - accuracy: 0.3812 - val_loss: 1.3940 - val_accuracy: 0.3448\n",
      "Epoch 36/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3100 - accuracy: 0.3862 - val_loss: 1.3926 - val_accuracy: 0.3448\n",
      "Epoch 37/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3101 - accuracy: 0.3812 - val_loss: 1.3974 - val_accuracy: 0.3391\n",
      "Epoch 38/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3057 - accuracy: 0.3887 - val_loss: 1.3999 - val_accuracy: 0.3391\n",
      "Epoch 39/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3044 - accuracy: 0.3825 - val_loss: 1.4038 - val_accuracy: 0.3448\n",
      "Epoch 40/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3056 - accuracy: 0.3862 - val_loss: 1.4036 - val_accuracy: 0.3448\n",
      "Epoch 41/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3069 - accuracy: 0.3800 - val_loss: 1.4051 - val_accuracy: 0.3333\n",
      "Epoch 42/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3021 - accuracy: 0.3900 - val_loss: 1.4036 - val_accuracy: 0.3276\n",
      "Epoch 43/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3010 - accuracy: 0.3938 - val_loss: 1.4035 - val_accuracy: 0.3276\n",
      "Epoch 44/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3035 - accuracy: 0.3963 - val_loss: 1.4101 - val_accuracy: 0.3276\n",
      "Epoch 45/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3014 - accuracy: 0.3875 - val_loss: 1.4088 - val_accuracy: 0.3276\n",
      "Epoch 46/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2986 - accuracy: 0.3913 - val_loss: 1.4076 - val_accuracy: 0.3276\n",
      "Epoch 47/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2948 - accuracy: 0.3950 - val_loss: 1.4121 - val_accuracy: 0.3333\n",
      "Epoch 48/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2964 - accuracy: 0.3887 - val_loss: 1.4102 - val_accuracy: 0.3333\n",
      "Epoch 49/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2961 - accuracy: 0.3837 - val_loss: 1.4109 - val_accuracy: 0.3448\n",
      "Epoch 50/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2961 - accuracy: 0.3925 - val_loss: 1.4131 - val_accuracy: 0.3276\n",
      "Epoch 51/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2885 - accuracy: 0.4062 - val_loss: 1.4174 - val_accuracy: 0.3218\n",
      "Epoch 52/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2939 - accuracy: 0.3900 - val_loss: 1.4223 - val_accuracy: 0.3103\n",
      "Epoch 53/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2948 - accuracy: 0.3975 - val_loss: 1.4221 - val_accuracy: 0.3333\n",
      "Epoch 54/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2894 - accuracy: 0.3913 - val_loss: 1.4152 - val_accuracy: 0.3276\n",
      "Epoch 55/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2929 - accuracy: 0.3975 - val_loss: 1.4125 - val_accuracy: 0.3333\n",
      "Epoch 56/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2910 - accuracy: 0.4150 - val_loss: 1.4172 - val_accuracy: 0.3218\n",
      "Epoch 57/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2892 - accuracy: 0.4075 - val_loss: 1.4259 - val_accuracy: 0.3276\n",
      "Epoch 58/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2855 - accuracy: 0.3988 - val_loss: 1.4295 - val_accuracy: 0.3333\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2836 - accuracy: 0.4038 - val_loss: 1.4282 - val_accuracy: 0.3276\n",
      "Epoch 60/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2805 - accuracy: 0.4075 - val_loss: 1.4263 - val_accuracy: 0.3276\n",
      "Epoch 61/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2808 - accuracy: 0.4087 - val_loss: 1.4294 - val_accuracy: 0.3161\n",
      "Epoch 62/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2792 - accuracy: 0.4038 - val_loss: 1.4339 - val_accuracy: 0.3103\n",
      "Epoch 63/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2762 - accuracy: 0.4125 - val_loss: 1.4339 - val_accuracy: 0.3161\n",
      "Epoch 64/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2847 - accuracy: 0.4087 - val_loss: 1.4365 - val_accuracy: 0.2989\n",
      "Epoch 65/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2738 - accuracy: 0.4137 - val_loss: 1.4314 - val_accuracy: 0.3161\n",
      "Epoch 66/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2803 - accuracy: 0.4000 - val_loss: 1.4381 - val_accuracy: 0.3391\n",
      "Epoch 67/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2706 - accuracy: 0.4112 - val_loss: 1.4404 - val_accuracy: 0.3333\n",
      "Epoch 68/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2731 - accuracy: 0.4137 - val_loss: 1.4353 - val_accuracy: 0.3161\n",
      "Epoch 69/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2728 - accuracy: 0.4112 - val_loss: 1.4401 - val_accuracy: 0.3333\n",
      "Epoch 70/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2734 - accuracy: 0.4013 - val_loss: 1.4490 - val_accuracy: 0.3276\n",
      "Epoch 71/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2678 - accuracy: 0.4000 - val_loss: 1.4494 - val_accuracy: 0.3333\n",
      "Epoch 72/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2686 - accuracy: 0.4050 - val_loss: 1.4465 - val_accuracy: 0.2989\n",
      "Epoch 73/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2577 - accuracy: 0.4250 - val_loss: 1.4459 - val_accuracy: 0.2816\n",
      "Epoch 74/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2664 - accuracy: 0.4038 - val_loss: 1.4505 - val_accuracy: 0.2816\n",
      "Epoch 75/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2688 - accuracy: 0.4087 - val_loss: 1.4496 - val_accuracy: 0.2874\n",
      "Epoch 76/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2693 - accuracy: 0.4125 - val_loss: 1.4504 - val_accuracy: 0.3103\n",
      "Epoch 77/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2545 - accuracy: 0.4150 - val_loss: 1.4480 - val_accuracy: 0.2874\n",
      "Epoch 78/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2719 - accuracy: 0.4275 - val_loss: 1.4508 - val_accuracy: 0.2931\n",
      "Epoch 79/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2591 - accuracy: 0.4200 - val_loss: 1.4677 - val_accuracy: 0.3218\n",
      "Epoch 80/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2621 - accuracy: 0.4238 - val_loss: 1.4575 - val_accuracy: 0.2989\n",
      "Epoch 81/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2549 - accuracy: 0.4300 - val_loss: 1.4574 - val_accuracy: 0.3046\n",
      "Epoch 82/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2568 - accuracy: 0.4225 - val_loss: 1.4545 - val_accuracy: 0.2931\n",
      "Epoch 83/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2498 - accuracy: 0.4212 - val_loss: 1.4537 - val_accuracy: 0.3103\n",
      "Epoch 84/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2450 - accuracy: 0.4363 - val_loss: 1.4637 - val_accuracy: 0.3046\n",
      "Epoch 85/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2515 - accuracy: 0.4350 - val_loss: 1.4604 - val_accuracy: 0.2874\n",
      "Epoch 86/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2544 - accuracy: 0.4250 - val_loss: 1.4607 - val_accuracy: 0.2989\n",
      "Epoch 87/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2566 - accuracy: 0.4137 - val_loss: 1.4611 - val_accuracy: 0.3046\n",
      "Epoch 88/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2585 - accuracy: 0.4125 - val_loss: 1.4652 - val_accuracy: 0.3161\n",
      "Epoch 89/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2501 - accuracy: 0.4325 - val_loss: 1.4642 - val_accuracy: 0.3103\n",
      "Epoch 90/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2424 - accuracy: 0.4175 - val_loss: 1.4624 - val_accuracy: 0.2816\n",
      "Epoch 91/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2505 - accuracy: 0.4225 - val_loss: 1.4671 - val_accuracy: 0.2759\n",
      "Epoch 92/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2392 - accuracy: 0.4275 - val_loss: 1.4709 - val_accuracy: 0.3046\n",
      "Epoch 93/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2495 - accuracy: 0.4212 - val_loss: 1.4709 - val_accuracy: 0.3161\n",
      "Epoch 94/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2373 - accuracy: 0.4338 - val_loss: 1.4733 - val_accuracy: 0.2874\n",
      "Epoch 95/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2348 - accuracy: 0.4412 - val_loss: 1.4838 - val_accuracy: 0.3103\n",
      "Epoch 96/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2439 - accuracy: 0.4350 - val_loss: 1.4822 - val_accuracy: 0.3046\n",
      "Epoch 97/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2394 - accuracy: 0.4400 - val_loss: 1.4876 - val_accuracy: 0.2989\n",
      "Epoch 98/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2326 - accuracy: 0.4338 - val_loss: 1.4823 - val_accuracy: 0.2931\n",
      "Epoch 99/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2427 - accuracy: 0.4350 - val_loss: 1.4707 - val_accuracy: 0.2816\n",
      "Epoch 100/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2544 - accuracy: 0.4275 - val_loss: 1.4771 - val_accuracy: 0.3046\n",
      "Epoch 101/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2322 - accuracy: 0.4487 - val_loss: 1.4855 - val_accuracy: 0.2931\n",
      "Epoch 102/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.4487 - val_loss: 1.4870 - val_accuracy: 0.2989\n",
      "Epoch 103/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2354 - accuracy: 0.4200 - val_loss: 1.4842 - val_accuracy: 0.3046\n",
      "Epoch 104/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2386 - accuracy: 0.4288 - val_loss: 1.4870 - val_accuracy: 0.3161\n",
      "Epoch 105/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2343 - accuracy: 0.4525 - val_loss: 1.4854 - val_accuracy: 0.2931\n",
      "Epoch 106/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2321 - accuracy: 0.4525 - val_loss: 1.4884 - val_accuracy: 0.2989\n",
      "Epoch 107/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2366 - accuracy: 0.4450 - val_loss: 1.4919 - val_accuracy: 0.3046\n",
      "Epoch 108/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2350 - accuracy: 0.4450 - val_loss: 1.4992 - val_accuracy: 0.2874\n",
      "Epoch 109/300\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.2544 - accuracy: 0.45 - 0s 4ms/step - loss: 1.2300 - accuracy: 0.4425 - val_loss: 1.4975 - val_accuracy: 0.2931\n",
      "Epoch 110/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2255 - accuracy: 0.4462 - val_loss: 1.4997 - val_accuracy: 0.2989\n",
      "Epoch 111/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2352 - accuracy: 0.4550 - val_loss: 1.4986 - val_accuracy: 0.2759\n",
      "Epoch 112/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2277 - accuracy: 0.4288 - val_loss: 1.4961 - val_accuracy: 0.2816\n",
      "Epoch 113/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2115 - accuracy: 0.4538 - val_loss: 1.4986 - val_accuracy: 0.2931\n",
      "Epoch 114/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2148 - accuracy: 0.4462 - val_loss: 1.5035 - val_accuracy: 0.3046\n",
      "Epoch 115/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2226 - accuracy: 0.4525 - val_loss: 1.5021 - val_accuracy: 0.2874\n",
      "Epoch 116/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2282 - accuracy: 0.4563 - val_loss: 1.4974 - val_accuracy: 0.2644\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2307 - accuracy: 0.4412 - val_loss: 1.5017 - val_accuracy: 0.2931\n",
      "Epoch 118/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2292 - accuracy: 0.4275 - val_loss: 1.5065 - val_accuracy: 0.3046\n",
      "Epoch 119/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.4550 - val_loss: 1.5020 - val_accuracy: 0.2989\n",
      "Epoch 120/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2179 - accuracy: 0.4375 - val_loss: 1.5063 - val_accuracy: 0.2874\n",
      "Epoch 121/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2136 - accuracy: 0.4400 - val_loss: 1.5059 - val_accuracy: 0.2989\n",
      "Epoch 122/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2081 - accuracy: 0.4563 - val_loss: 1.5053 - val_accuracy: 0.2874\n",
      "Epoch 123/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2154 - accuracy: 0.4288 - val_loss: 1.5005 - val_accuracy: 0.2874\n",
      "Epoch 124/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2099 - accuracy: 0.4575 - val_loss: 1.5023 - val_accuracy: 0.2874\n",
      "Epoch 125/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2086 - accuracy: 0.4525 - val_loss: 1.5123 - val_accuracy: 0.2989\n",
      "Epoch 126/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2093 - accuracy: 0.4550 - val_loss: 1.5194 - val_accuracy: 0.3103\n",
      "Epoch 127/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2003 - accuracy: 0.4550 - val_loss: 1.5213 - val_accuracy: 0.2989\n",
      "Epoch 128/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2021 - accuracy: 0.4638 - val_loss: 1.5163 - val_accuracy: 0.2644\n",
      "Epoch 129/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2102 - accuracy: 0.4387 - val_loss: 1.5149 - val_accuracy: 0.2644\n",
      "Epoch 130/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2039 - accuracy: 0.4575 - val_loss: 1.5189 - val_accuracy: 0.2874\n",
      "Epoch 131/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1954 - accuracy: 0.4600 - val_loss: 1.5205 - val_accuracy: 0.2874\n",
      "Epoch 132/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2021 - accuracy: 0.4575 - val_loss: 1.5211 - val_accuracy: 0.2874\n",
      "Epoch 133/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2094 - accuracy: 0.4575 - val_loss: 1.5183 - val_accuracy: 0.2701\n",
      "Epoch 134/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2007 - accuracy: 0.4600 - val_loss: 1.5244 - val_accuracy: 0.2816\n",
      "Epoch 135/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1818 - accuracy: 0.4638 - val_loss: 1.5348 - val_accuracy: 0.2874\n",
      "Epoch 136/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2076 - accuracy: 0.4550 - val_loss: 1.5294 - val_accuracy: 0.2874\n",
      "Epoch 137/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1979 - accuracy: 0.4650 - val_loss: 1.5305 - val_accuracy: 0.2874\n",
      "Epoch 138/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2070 - accuracy: 0.4425 - val_loss: 1.5285 - val_accuracy: 0.2701\n",
      "Epoch 139/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1936 - accuracy: 0.4437 - val_loss: 1.5305 - val_accuracy: 0.2989\n",
      "Epoch 140/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1979 - accuracy: 0.4650 - val_loss: 1.5290 - val_accuracy: 0.2931\n",
      "Epoch 141/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2050 - accuracy: 0.4538 - val_loss: 1.5256 - val_accuracy: 0.2816\n",
      "Epoch 142/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2041 - accuracy: 0.4525 - val_loss: 1.5386 - val_accuracy: 0.3046\n",
      "Epoch 143/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1872 - accuracy: 0.4725 - val_loss: 1.5384 - val_accuracy: 0.2989\n",
      "Epoch 144/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1890 - accuracy: 0.4888 - val_loss: 1.5448 - val_accuracy: 0.3046\n",
      "Epoch 145/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1996 - accuracy: 0.4563 - val_loss: 1.5388 - val_accuracy: 0.2989\n",
      "Epoch 146/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1805 - accuracy: 0.4487 - val_loss: 1.5397 - val_accuracy: 0.2816\n",
      "Epoch 147/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2009 - accuracy: 0.4563 - val_loss: 1.5386 - val_accuracy: 0.2816\n",
      "Epoch 148/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1759 - accuracy: 0.4775 - val_loss: 1.5457 - val_accuracy: 0.2759\n",
      "Epoch 149/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1984 - accuracy: 0.4512 - val_loss: 1.5436 - val_accuracy: 0.2874\n",
      "Epoch 150/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1904 - accuracy: 0.4638 - val_loss: 1.5381 - val_accuracy: 0.2529\n",
      "Epoch 151/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1791 - accuracy: 0.4650 - val_loss: 1.5538 - val_accuracy: 0.2874\n",
      "Epoch 152/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1835 - accuracy: 0.4737 - val_loss: 1.5561 - val_accuracy: 0.2874\n",
      "Epoch 153/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1847 - accuracy: 0.4550 - val_loss: 1.5587 - val_accuracy: 0.2931\n",
      "Epoch 154/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1969 - accuracy: 0.4588 - val_loss: 1.5575 - val_accuracy: 0.2759\n",
      "Epoch 155/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1972 - accuracy: 0.4512 - val_loss: 1.5440 - val_accuracy: 0.2701\n",
      "Epoch 156/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1924 - accuracy: 0.4550 - val_loss: 1.5538 - val_accuracy: 0.2816\n",
      "Epoch 157/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1870 - accuracy: 0.4638 - val_loss: 1.5520 - val_accuracy: 0.2644\n",
      "Epoch 158/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1819 - accuracy: 0.4800 - val_loss: 1.5541 - val_accuracy: 0.2701\n",
      "Epoch 159/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1759 - accuracy: 0.4825 - val_loss: 1.5628 - val_accuracy: 0.2931\n",
      "Epoch 160/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1917 - accuracy: 0.4650 - val_loss: 1.5585 - val_accuracy: 0.2989\n",
      "Epoch 161/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1643 - accuracy: 0.4863 - val_loss: 1.5578 - val_accuracy: 0.2759\n",
      "Epoch 162/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1805 - accuracy: 0.4638 - val_loss: 1.5662 - val_accuracy: 0.2816\n",
      "Epoch 163/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1819 - accuracy: 0.4625 - val_loss: 1.5679 - val_accuracy: 0.2874\n",
      "Epoch 164/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1738 - accuracy: 0.4762 - val_loss: 1.5687 - val_accuracy: 0.2931\n",
      "Epoch 165/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1802 - accuracy: 0.4575 - val_loss: 1.5591 - val_accuracy: 0.2816\n",
      "Epoch 166/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1909 - accuracy: 0.4688 - val_loss: 1.5516 - val_accuracy: 0.2644\n",
      "Epoch 167/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1673 - accuracy: 0.4625 - val_loss: 1.5668 - val_accuracy: 0.2931\n",
      "Epoch 168/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1706 - accuracy: 0.4675 - val_loss: 1.5775 - val_accuracy: 0.2989\n",
      "Epoch 169/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1716 - accuracy: 0.4787 - val_loss: 1.5623 - val_accuracy: 0.2759\n",
      "Epoch 170/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1658 - accuracy: 0.4837 - val_loss: 1.5557 - val_accuracy: 0.2644\n",
      "Epoch 171/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1452 - accuracy: 0.4950 - val_loss: 1.5761 - val_accuracy: 0.2989\n",
      "Epoch 172/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1660 - accuracy: 0.4725 - val_loss: 1.5873 - val_accuracy: 0.2874\n",
      "Epoch 173/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1728 - accuracy: 0.4688 - val_loss: 1.5828 - val_accuracy: 0.2931\n",
      "Epoch 174/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1822 - accuracy: 0.4538 - val_loss: 1.5861 - val_accuracy: 0.2931\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1625 - accuracy: 0.4675 - val_loss: 1.5703 - val_accuracy: 0.2816\n",
      "Epoch 176/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1726 - accuracy: 0.4725 - val_loss: 1.5784 - val_accuracy: 0.2874\n",
      "Epoch 177/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1691 - accuracy: 0.4638 - val_loss: 1.5894 - val_accuracy: 0.3046\n",
      "Epoch 178/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1650 - accuracy: 0.4650 - val_loss: 1.5727 - val_accuracy: 0.2816\n",
      "Epoch 179/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1550 - accuracy: 0.4875 - val_loss: 1.5730 - val_accuracy: 0.2816\n",
      "Epoch 180/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1582 - accuracy: 0.4787 - val_loss: 1.5862 - val_accuracy: 0.3046\n",
      "Epoch 181/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1550 - accuracy: 0.4975 - val_loss: 1.5846 - val_accuracy: 0.2816\n",
      "Epoch 182/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1798 - accuracy: 0.4450 - val_loss: 1.5794 - val_accuracy: 0.2586\n",
      "Epoch 183/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1643 - accuracy: 0.4750 - val_loss: 1.5903 - val_accuracy: 0.2874\n",
      "Epoch 184/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1512 - accuracy: 0.4737 - val_loss: 1.5883 - val_accuracy: 0.2931\n",
      "Epoch 185/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1859 - accuracy: 0.4487 - val_loss: 1.5923 - val_accuracy: 0.2931\n",
      "Epoch 186/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1618 - accuracy: 0.4750 - val_loss: 1.5861 - val_accuracy: 0.2816\n",
      "Epoch 187/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1751 - accuracy: 0.4837 - val_loss: 1.5889 - val_accuracy: 0.2874\n",
      "Epoch 188/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1703 - accuracy: 0.4663 - val_loss: 1.5899 - val_accuracy: 0.2816\n",
      "Epoch 189/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1694 - accuracy: 0.4725 - val_loss: 1.5805 - val_accuracy: 0.2701\n",
      "Epoch 190/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1612 - accuracy: 0.4650 - val_loss: 1.5834 - val_accuracy: 0.2701\n",
      "Epoch 191/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1552 - accuracy: 0.4563 - val_loss: 1.5869 - val_accuracy: 0.2759\n",
      "Epoch 192/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1540 - accuracy: 0.4900 - val_loss: 1.5823 - val_accuracy: 0.2816\n",
      "Epoch 193/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1408 - accuracy: 0.4900 - val_loss: 1.5920 - val_accuracy: 0.2701\n",
      "Epoch 194/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1614 - accuracy: 0.4850 - val_loss: 1.6023 - val_accuracy: 0.2816\n",
      "Epoch 195/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1541 - accuracy: 0.4925 - val_loss: 1.5924 - val_accuracy: 0.2874\n",
      "Epoch 196/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1435 - accuracy: 0.4850 - val_loss: 1.5885 - val_accuracy: 0.2701\n",
      "Epoch 197/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1486 - accuracy: 0.5000 - val_loss: 1.5967 - val_accuracy: 0.2644\n",
      "Epoch 198/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1644 - accuracy: 0.4900 - val_loss: 1.5978 - val_accuracy: 0.2644\n",
      "Epoch 199/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1366 - accuracy: 0.4775 - val_loss: 1.5956 - val_accuracy: 0.2759\n",
      "Epoch 200/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1569 - accuracy: 0.5000 - val_loss: 1.5951 - val_accuracy: 0.2759\n",
      "Epoch 201/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1661 - accuracy: 0.4737 - val_loss: 1.6063 - val_accuracy: 0.2759\n",
      "Epoch 202/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1550 - accuracy: 0.4950 - val_loss: 1.6106 - val_accuracy: 0.2931\n",
      "Epoch 203/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1479 - accuracy: 0.4900 - val_loss: 1.6143 - val_accuracy: 0.2701\n",
      "Epoch 204/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1670 - accuracy: 0.4613 - val_loss: 1.6000 - val_accuracy: 0.2816\n",
      "Epoch 205/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1650 - accuracy: 0.4950 - val_loss: 1.5962 - val_accuracy: 0.2816\n",
      "Epoch 206/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1430 - accuracy: 0.4737 - val_loss: 1.5982 - val_accuracy: 0.2759\n",
      "Epoch 207/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1492 - accuracy: 0.4812 - val_loss: 1.6178 - val_accuracy: 0.2931\n",
      "Epoch 208/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1386 - accuracy: 0.4938 - val_loss: 1.6139 - val_accuracy: 0.2701\n",
      "Epoch 209/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1343 - accuracy: 0.4913 - val_loss: 1.6030 - val_accuracy: 0.2759\n",
      "Epoch 210/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1463 - accuracy: 0.5000 - val_loss: 1.6067 - val_accuracy: 0.2874\n",
      "Epoch 211/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1610 - accuracy: 0.4812 - val_loss: 1.6287 - val_accuracy: 0.2874\n",
      "Epoch 212/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1586 - accuracy: 0.4825 - val_loss: 1.6106 - val_accuracy: 0.2989\n",
      "Epoch 213/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1483 - accuracy: 0.4725 - val_loss: 1.6026 - val_accuracy: 0.2931\n",
      "Epoch 214/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1448 - accuracy: 0.4988 - val_loss: 1.6159 - val_accuracy: 0.2816\n",
      "Epoch 215/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1424 - accuracy: 0.4888 - val_loss: 1.6188 - val_accuracy: 0.2759\n",
      "Epoch 216/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1538 - accuracy: 0.4812 - val_loss: 1.6117 - val_accuracy: 0.2701\n",
      "Epoch 217/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1217 - accuracy: 0.5138 - val_loss: 1.6237 - val_accuracy: 0.2701\n",
      "Epoch 218/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1546 - accuracy: 0.4925 - val_loss: 1.6305 - val_accuracy: 0.2816\n",
      "Epoch 219/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1435 - accuracy: 0.5000 - val_loss: 1.6370 - val_accuracy: 0.3046\n",
      "Epoch 220/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1435 - accuracy: 0.4950 - val_loss: 1.6210 - val_accuracy: 0.2989\n",
      "Epoch 221/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1454 - accuracy: 0.4900 - val_loss: 1.6194 - val_accuracy: 0.2874\n",
      "Epoch 222/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1441 - accuracy: 0.5013 - val_loss: 1.6190 - val_accuracy: 0.2989\n",
      "Epoch 223/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1346 - accuracy: 0.5100 - val_loss: 1.6201 - val_accuracy: 0.3046\n",
      "Epoch 224/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1353 - accuracy: 0.5150 - val_loss: 1.6202 - val_accuracy: 0.2931\n",
      "Epoch 225/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1264 - accuracy: 0.5000 - val_loss: 1.6316 - val_accuracy: 0.2816\n",
      "Epoch 226/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1454 - accuracy: 0.4700 - val_loss: 1.6384 - val_accuracy: 0.2874\n",
      "Epoch 227/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1262 - accuracy: 0.4812 - val_loss: 1.6481 - val_accuracy: 0.2931\n",
      "Epoch 228/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1405 - accuracy: 0.4875 - val_loss: 1.6423 - val_accuracy: 0.2874\n",
      "Epoch 229/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1419 - accuracy: 0.4800 - val_loss: 1.6352 - val_accuracy: 0.2874\n",
      "Epoch 230/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1338 - accuracy: 0.4900 - val_loss: 1.6406 - val_accuracy: 0.2759\n",
      "Epoch 231/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1274 - accuracy: 0.5113 - val_loss: 1.6360 - val_accuracy: 0.2759\n",
      "Epoch 232/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1301 - accuracy: 0.4975 - val_loss: 1.6527 - val_accuracy: 0.2816\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1264 - accuracy: 0.4888 - val_loss: 1.6515 - val_accuracy: 0.2874\n",
      "Epoch 234/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1120 - accuracy: 0.5200 - val_loss: 1.6469 - val_accuracy: 0.2816\n",
      "Epoch 235/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1297 - accuracy: 0.5088 - val_loss: 1.6573 - val_accuracy: 0.2816\n",
      "Epoch 236/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1102 - accuracy: 0.5200 - val_loss: 1.6494 - val_accuracy: 0.2874\n",
      "Epoch 237/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1129 - accuracy: 0.5250 - val_loss: 1.6611 - val_accuracy: 0.2816\n",
      "Epoch 238/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1287 - accuracy: 0.4837 - val_loss: 1.6593 - val_accuracy: 0.2989\n",
      "Epoch 239/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1318 - accuracy: 0.4762 - val_loss: 1.6535 - val_accuracy: 0.2931\n",
      "Epoch 240/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1352 - accuracy: 0.4888 - val_loss: 1.6528 - val_accuracy: 0.2874\n",
      "Epoch 241/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1150 - accuracy: 0.5138 - val_loss: 1.6640 - val_accuracy: 0.2816\n",
      "Epoch 242/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1221 - accuracy: 0.5138 - val_loss: 1.6746 - val_accuracy: 0.2759\n",
      "Epoch 243/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1455 - accuracy: 0.4875 - val_loss: 1.6719 - val_accuracy: 0.2874\n",
      "Epoch 244/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1251 - accuracy: 0.4925 - val_loss: 1.6656 - val_accuracy: 0.2816\n",
      "Epoch 245/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1362 - accuracy: 0.4988 - val_loss: 1.6660 - val_accuracy: 0.2931\n",
      "Epoch 246/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1211 - accuracy: 0.5025 - val_loss: 1.6568 - val_accuracy: 0.2931\n",
      "Epoch 247/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1261 - accuracy: 0.4825 - val_loss: 1.6586 - val_accuracy: 0.3103\n",
      "Epoch 248/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1150 - accuracy: 0.5013 - val_loss: 1.6532 - val_accuracy: 0.3046\n",
      "Epoch 249/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1180 - accuracy: 0.4988 - val_loss: 1.6569 - val_accuracy: 0.2931\n",
      "Epoch 250/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1263 - accuracy: 0.4863 - val_loss: 1.6610 - val_accuracy: 0.2931\n",
      "Epoch 251/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1196 - accuracy: 0.5050 - val_loss: 1.6570 - val_accuracy: 0.2989\n",
      "Epoch 252/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1366 - accuracy: 0.4812 - val_loss: 1.6727 - val_accuracy: 0.3046\n",
      "Epoch 253/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.5188 - val_loss: 1.6759 - val_accuracy: 0.3046\n",
      "Epoch 254/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1141 - accuracy: 0.5088 - val_loss: 1.6698 - val_accuracy: 0.2816\n",
      "Epoch 255/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1276 - accuracy: 0.4963 - val_loss: 1.6731 - val_accuracy: 0.2931\n",
      "Epoch 256/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1119 - accuracy: 0.4913 - val_loss: 1.6692 - val_accuracy: 0.2874\n",
      "Epoch 257/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1019 - accuracy: 0.5213 - val_loss: 1.6725 - val_accuracy: 0.2989\n",
      "Epoch 258/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1237 - accuracy: 0.5038 - val_loss: 1.6564 - val_accuracy: 0.2816\n",
      "Epoch 259/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1223 - accuracy: 0.5125 - val_loss: 1.6676 - val_accuracy: 0.2931\n",
      "Epoch 260/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1238 - accuracy: 0.5125 - val_loss: 1.6864 - val_accuracy: 0.3046\n",
      "Epoch 261/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1177 - accuracy: 0.4913 - val_loss: 1.6934 - val_accuracy: 0.3046\n",
      "Epoch 262/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1167 - accuracy: 0.5025 - val_loss: 1.6954 - val_accuracy: 0.2989\n",
      "Epoch 263/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1329 - accuracy: 0.4913 - val_loss: 1.6805 - val_accuracy: 0.2874\n",
      "Epoch 264/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1219 - accuracy: 0.4825 - val_loss: 1.6982 - val_accuracy: 0.2989\n",
      "Epoch 265/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1064 - accuracy: 0.4725 - val_loss: 1.6999 - val_accuracy: 0.2989\n",
      "Epoch 266/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1151 - accuracy: 0.4900 - val_loss: 1.6893 - val_accuracy: 0.2874\n",
      "Epoch 267/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1103 - accuracy: 0.5138 - val_loss: 1.6945 - val_accuracy: 0.2931\n",
      "Epoch 268/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1299 - accuracy: 0.5050 - val_loss: 1.6983 - val_accuracy: 0.2874\n",
      "Epoch 269/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1219 - accuracy: 0.5050 - val_loss: 1.7070 - val_accuracy: 0.2931\n",
      "Epoch 270/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1148 - accuracy: 0.5200 - val_loss: 1.7037 - val_accuracy: 0.2874\n",
      "Epoch 271/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0924 - accuracy: 0.5075 - val_loss: 1.7070 - val_accuracy: 0.2874\n",
      "Epoch 272/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1236 - accuracy: 0.5312 - val_loss: 1.7092 - val_accuracy: 0.2816\n",
      "Epoch 273/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1104 - accuracy: 0.5163 - val_loss: 1.7027 - val_accuracy: 0.2989\n",
      "Epoch 274/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1380 - accuracy: 0.4850 - val_loss: 1.6994 - val_accuracy: 0.2931\n",
      "Epoch 275/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1035 - accuracy: 0.5175 - val_loss: 1.6909 - val_accuracy: 0.2701\n",
      "Epoch 276/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1147 - accuracy: 0.5013 - val_loss: 1.6895 - val_accuracy: 0.3046\n",
      "Epoch 277/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1113 - accuracy: 0.5088 - val_loss: 1.7061 - val_accuracy: 0.2931\n",
      "Epoch 278/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1084 - accuracy: 0.5000 - val_loss: 1.7010 - val_accuracy: 0.2759\n",
      "Epoch 279/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1166 - accuracy: 0.5063 - val_loss: 1.6972 - val_accuracy: 0.2816\n",
      "Epoch 280/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1125 - accuracy: 0.4975 - val_loss: 1.6949 - val_accuracy: 0.2759\n",
      "Epoch 281/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1140 - accuracy: 0.5213 - val_loss: 1.6910 - val_accuracy: 0.2759\n",
      "Epoch 282/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1049 - accuracy: 0.5050 - val_loss: 1.7010 - val_accuracy: 0.2701\n",
      "Epoch 283/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1074 - accuracy: 0.4950 - val_loss: 1.7046 - val_accuracy: 0.2701\n",
      "Epoch 284/300\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1154 - accuracy: 0.5000 - val_loss: 1.7043 - val_accuracy: 0.2759\n",
      "Epoch 285/300\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1172 - accuracy: 0.4963 - val_loss: 1.6916 - val_accuracy: 0.2931\n",
      "Epoch 286/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.0998 - accuracy: 0.5100 - val_loss: 1.6839 - val_accuracy: 0.2989\n",
      "Epoch 287/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.0982 - accuracy: 0.5425 - val_loss: 1.6975 - val_accuracy: 0.2874\n",
      "Epoch 288/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1167 - accuracy: 0.5000 - val_loss: 1.6950 - val_accuracy: 0.3046\n",
      "Epoch 289/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1054 - accuracy: 0.4888 - val_loss: 1.6920 - val_accuracy: 0.2874\n",
      "Epoch 290/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1041 - accuracy: 0.5200 - val_loss: 1.7058 - val_accuracy: 0.2874\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1327 - accuracy: 0.4913 - val_loss: 1.7070 - val_accuracy: 0.2989\n",
      "Epoch 292/300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1220 - accuracy: 0.4938 - val_loss: 1.6889 - val_accuracy: 0.2989\n",
      "Epoch 293/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1147 - accuracy: 0.5213 - val_loss: 1.6890 - val_accuracy: 0.2989\n",
      "Epoch 294/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1003 - accuracy: 0.5125 - val_loss: 1.7201 - val_accuracy: 0.2931\n",
      "Epoch 295/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1067 - accuracy: 0.5038 - val_loss: 1.7115 - val_accuracy: 0.3046\n",
      "Epoch 296/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1023 - accuracy: 0.5250 - val_loss: 1.7077 - val_accuracy: 0.2931\n",
      "Epoch 297/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0954 - accuracy: 0.5150 - val_loss: 1.7105 - val_accuracy: 0.2931\n",
      "Epoch 298/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1015 - accuracy: 0.5000 - val_loss: 1.7051 - val_accuracy: 0.2816\n",
      "Epoch 299/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0915 - accuracy: 0.5350 - val_loss: 1.7161 - val_accuracy: 0.2816\n",
      "Epoch 300/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1029 - accuracy: 0.5138 - val_loss: 1.7109 - val_accuracy: 0.2701\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_X, training_y, epochs = 300, validation_data=(test_X, test_y), batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(128, dropout = 0.2, input_shape=[bag.shape[0], bag.shape[1], 1])),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "opt = keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-07,\n",
    "    centered=False,\n",
    ")\n",
    "\n",
    "#opt = keras.optimizers.SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#opt = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model2.compile(loss='sparse_categorical_crossentropy',optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 31, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-378732ef5219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \"\"\"\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2352\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 1.3709 - accuracy: 0.3438 - val_loss: 1.3646 - val_accuracy: 0.3448\n",
      "Epoch 2/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3428 - accuracy: 0.3787 - val_loss: 1.3655 - val_accuracy: 0.3448\n",
      "Epoch 3/240\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3345 - accuracy: 0.3787 - val_loss: 1.5903 - val_accuracy: 0.3448\n",
      "Epoch 4/240\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3734 - accuracy: 0.3787 - val_loss: 1.3657 - val_accuracy: 0.3448\n",
      "Epoch 5/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3355 - accuracy: 0.3787 - val_loss: 1.3821 - val_accuracy: 0.3448\n",
      "Epoch 6/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3365 - accuracy: 0.3787 - val_loss: 1.3668 - val_accuracy: 0.3448\n",
      "Epoch 7/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3354 - accuracy: 0.3787 - val_loss: 1.3645 - val_accuracy: 0.3448\n",
      "Epoch 8/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3352 - accuracy: 0.3787 - val_loss: 1.3693 - val_accuracy: 0.3448\n",
      "Epoch 9/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3388 - accuracy: 0.3787 - val_loss: 1.3809 - val_accuracy: 0.3448\n",
      "Epoch 10/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3380 - accuracy: 0.3787 - val_loss: 1.3661 - val_accuracy: 0.3448\n",
      "Epoch 11/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3349 - accuracy: 0.3787 - val_loss: 1.4196 - val_accuracy: 0.3448\n",
      "Epoch 12/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3389 - accuracy: 0.3787 - val_loss: 1.3763 - val_accuracy: 0.3448\n",
      "Epoch 13/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3383 - accuracy: 0.3787 - val_loss: 1.4221 - val_accuracy: 0.3448\n",
      "Epoch 14/240\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.3384 - accuracy: 0.3787 - val_loss: 1.3769 - val_accuracy: 0.3448\n",
      "Epoch 15/240\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 1.3375 - accuracy: 0.3787 - val_loss: 1.3717 - val_accuracy: 0.3448\n",
      "Epoch 16/240\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 1.3395 - accuracy: 0.3787 - val_loss: 1.3734 - val_accuracy: 0.3448\n",
      "Epoch 17/240\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 1.3367 - accuracy: 0.3787 - val_loss: 1.3811 - val_accuracy: 0.3448\n",
      "Epoch 18/240\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 1.3360 - accuracy: 0.3787 - val_loss: 1.3682 - val_accuracy: 0.3448\n",
      "Epoch 19/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3359 - accuracy: 0.3787 - val_loss: 1.3740 - val_accuracy: 0.3448\n",
      "Epoch 20/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3366 - accuracy: 0.3787 - val_loss: 1.3662 - val_accuracy: 0.3448\n",
      "Epoch 21/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3351 - accuracy: 0.3787 - val_loss: 1.3690 - val_accuracy: 0.3448\n",
      "Epoch 22/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3393 - accuracy: 0.3787 - val_loss: 1.3661 - val_accuracy: 0.3448\n",
      "Epoch 23/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3349 - accuracy: 0.3787 - val_loss: 1.3681 - val_accuracy: 0.3448\n",
      "Epoch 24/240\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 1.3373 - accuracy: 0.3787 - val_loss: 1.3691 - val_accuracy: 0.3448\n",
      "Epoch 25/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3353 - accuracy: 0.3787 - val_loss: 1.3663 - val_accuracy: 0.3448\n",
      "Epoch 26/240\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 1.3387 - accuracy: 0.3787 - val_loss: 1.3676 - val_accuracy: 0.3448\n",
      "Epoch 27/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3369 - accuracy: 0.3787 - val_loss: 1.3755 - val_accuracy: 0.3448\n",
      "Epoch 28/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3376 - accuracy: 0.3787 - val_loss: 1.3677 - val_accuracy: 0.3448\n",
      "Epoch 29/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3359 - accuracy: 0.3787 - val_loss: 1.3683 - val_accuracy: 0.3448\n",
      "Epoch 30/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3358 - accuracy: 0.3787 - val_loss: 1.3664 - val_accuracy: 0.3448\n",
      "Epoch 31/240\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 1.3374 - accuracy: 0.3787 - val_loss: 1.3678 - val_accuracy: 0.3448\n",
      "Epoch 32/240\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3348 - accuracy: 0.3787 - val_loss: 1.3704 - val_accuracy: 0.3448\n",
      "Epoch 33/240\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.3355 - accuracy: 0.3787 - val_loss: 1.3904 - val_accuracy: 0.3448\n",
      "Epoch 34/240\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3367 - accuracy: 0.3787 - val_loss: 1.3667 - val_accuracy: 0.3448\n",
      "Epoch 35/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3364 - accuracy: 0.3787 - val_loss: 1.3679 - val_accuracy: 0.3448\n",
      "Epoch 36/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3364 - accuracy: 0.3787 - val_loss: 1.3654 - val_accuracy: 0.3448\n",
      "Epoch 37/240\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 1.3344 - accuracy: 0.3787 - val_loss: 1.3676 - val_accuracy: 0.3448\n",
      "Epoch 38/240\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 1.3349 - accuracy: 0.3787 - val_loss: 1.3727 - val_accuracy: 0.3448\n",
      "Epoch 39/240\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.3347 - accuracy: 0.3787 - val_loss: 1.3671 - val_accuracy: 0.3448\n",
      "Epoch 40/240\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.3356 - accuracy: 0.3787 - val_loss: 1.3687 - val_accuracy: 0.3448\n",
      "Epoch 41/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3360 - accuracy: 0.3787 - val_loss: 1.3808 - val_accuracy: 0.3448\n",
      "Epoch 42/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3365 - accuracy: 0.3787 - val_loss: 1.3732 - val_accuracy: 0.3448\n",
      "Epoch 43/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3351 - accuracy: 0.3787 - val_loss: 1.3666 - val_accuracy: 0.3448\n",
      "Epoch 44/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3375 - accuracy: 0.3787 - val_loss: 1.3831 - val_accuracy: 0.3448\n",
      "Epoch 45/240\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3351 - accuracy: 0.3787 - val_loss: 1.3887 - val_accuracy: 0.3448\n",
      "Epoch 46/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3363 - accuracy: 0.3787 - val_loss: 1.3727 - val_accuracy: 0.3448\n",
      "Epoch 47/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3362 - accuracy: 0.3787 - val_loss: 1.3775 - val_accuracy: 0.3448\n",
      "Epoch 48/240\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 1.3361 - accuracy: 0.3787 - val_loss: 1.3851 - val_accuracy: 0.3448\n",
      "Epoch 49/240\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3346 - accuracy: 0.3787 - val_loss: 1.3730 - val_accuracy: 0.3448\n",
      "Epoch 50/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3355 - accuracy: 0.3787 - val_loss: 1.3679 - val_accuracy: 0.3448\n",
      "Epoch 51/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3354 - accuracy: 0.3787 - val_loss: 1.3714 - val_accuracy: 0.3448\n",
      "Epoch 52/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3365 - accuracy: 0.3787 - val_loss: 1.3762 - val_accuracy: 0.3448\n",
      "Epoch 53/240\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3343 - accuracy: 0.3787 - val_loss: 1.3808 - val_accuracy: 0.3448\n",
      "Epoch 54/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3350 - accuracy: 0.3787 - val_loss: 1.3719 - val_accuracy: 0.3448\n",
      "Epoch 55/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3351 - accuracy: 0.3787 - val_loss: 1.3781 - val_accuracy: 0.3448\n",
      "Epoch 56/240\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3352 - accuracy: 0.3787 - val_loss: 1.3673 - val_accuracy: 0.3448\n",
      "Epoch 57/240\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 1.3346 - accuracy: 0.3787 - val_loss: 1.3701 - val_accuracy: 0.3448\n",
      "Epoch 58/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3359 - accuracy: 0.3787 - val_loss: 1.3763 - val_accuracy: 0.3448\n",
      "Epoch 59/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3350 - accuracy: 0.3787 - val_loss: 1.3716 - val_accuracy: 0.3448\n",
      "Epoch 60/240\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 1.3364 - accuracy: 0.3787 - val_loss: 1.3735 - val_accuracy: 0.3448\n",
      "Epoch 61/240\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3344 - accuracy: 0.3787 - val_loss: 1.3691 - val_accuracy: 0.3448\n",
      "Epoch 62/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3347 - accuracy: 0.3787 - val_loss: 1.3828 - val_accuracy: 0.3448\n",
      "Epoch 63/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3359 - accuracy: 0.3787 - val_loss: 1.3752 - val_accuracy: 0.3448\n",
      "Epoch 64/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3355 - accuracy: 0.3787 - val_loss: 1.3705 - val_accuracy: 0.3448\n",
      "Epoch 65/240\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 1.3365 - accuracy: 0.3787 - val_loss: 1.3736 - val_accuracy: 0.3448\n",
      "Epoch 66/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3352 - accuracy: 0.3787 - val_loss: 1.3800 - val_accuracy: 0.3448\n",
      "Epoch 67/240\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 1.3338 - accuracy: 0.3787 - val_loss: 1.3836 - val_accuracy: 0.3448\n",
      "Epoch 68/240\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3340 - accuracy: 0.3787 - val_loss: 1.3678 - val_accuracy: 0.3448\n",
      "Epoch 69/240\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 1.3344 - accuracy: 0.3787 - val_loss: 1.3706 - val_accuracy: 0.3448\n",
      "Epoch 70/240\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3361 - accuracy: 0.3787 - val_loss: 1.3811 - val_accuracy: 0.3448\n",
      "Epoch 71/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3359 - accuracy: 0.3787 - val_loss: 1.3701 - val_accuracy: 0.3448\n",
      "Epoch 72/240\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.3343 - accuracy: 0.3787 - val_loss: 1.3755 - val_accuracy: 0.3448\n",
      "Epoch 73/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3344 - accuracy: 0.3787 - val_loss: 1.3851 - val_accuracy: 0.3448\n",
      "Epoch 74/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3384 - accuracy: 0.3787 - val_loss: 1.3695 - val_accuracy: 0.3448\n",
      "Epoch 75/240\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.3342 - accuracy: 0.3787 - val_loss: 1.3726 - val_accuracy: 0.3448\n",
      "Epoch 76/240\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 1.3342 - accuracy: 0.3787 - val_loss: 1.3720 - val_accuracy: 0.3448\n",
      "Epoch 77/240\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3334 - accuracy: 0.3787 - val_loss: 1.3706 - val_accuracy: 0.3448\n",
      "Epoch 78/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3356 - accuracy: 0.3787 - val_loss: 1.3733 - val_accuracy: 0.3448\n",
      "Epoch 79/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3336 - accuracy: 0.3787 - val_loss: 1.3684 - val_accuracy: 0.3448\n",
      "Epoch 80/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3341 - accuracy: 0.3787 - val_loss: 1.3701 - val_accuracy: 0.3448\n",
      "Epoch 81/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3331 - accuracy: 0.3787 - val_loss: 1.3702 - val_accuracy: 0.3448\n",
      "Epoch 82/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3333 - accuracy: 0.3787 - val_loss: 1.3746 - val_accuracy: 0.3448\n",
      "Epoch 83/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3339 - accuracy: 0.3787 - val_loss: 1.3815 - val_accuracy: 0.3448\n",
      "Epoch 84/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3346 - accuracy: 0.3787 - val_loss: 1.3697 - val_accuracy: 0.3448\n",
      "Epoch 85/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3354 - accuracy: 0.3787 - val_loss: 1.3681 - val_accuracy: 0.3448\n",
      "Epoch 86/240\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.3341 - accuracy: 0.3787 - val_loss: 1.3696 - val_accuracy: 0.3448\n",
      "Epoch 87/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3332 - accuracy: 0.3787 - val_loss: 1.6375 - val_accuracy: 0.3448\n",
      "Epoch 88/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3575 - accuracy: 0.3787 - val_loss: 1.3753 - val_accuracy: 0.3448\n",
      "Epoch 89/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3326 - accuracy: 0.3787 - val_loss: 1.3761 - val_accuracy: 0.3448\n",
      "Epoch 90/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3329 - accuracy: 0.3787 - val_loss: 1.3709 - val_accuracy: 0.3448\n",
      "Epoch 91/240\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3326 - accuracy: 0.3787 - val_loss: 1.3718 - val_accuracy: 0.3448\n",
      "Epoch 92/240\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 1.3322 - accuracy: 0.3787 - val_loss: 1.3729 - val_accuracy: 0.3448\n",
      "Epoch 93/240\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 1.3331 - accuracy: 0.3787 - val_loss: 1.3721 - val_accuracy: 0.3448\n",
      "Epoch 94/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3326 - accuracy: 0.3787 - val_loss: 1.3702 - val_accuracy: 0.3448\n",
      "Epoch 95/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3330 - accuracy: 0.3787 - val_loss: 1.3727 - val_accuracy: 0.3448\n",
      "Epoch 96/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3352 - accuracy: 0.3787 - val_loss: 1.3688 - val_accuracy: 0.3448\n",
      "Epoch 97/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3331 - accuracy: 0.3787 - val_loss: 1.3709 - val_accuracy: 0.3448\n",
      "Epoch 98/240\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.3324 - accuracy: 0.3787 - val_loss: 1.3791 - val_accuracy: 0.3448\n",
      "Epoch 99/240\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.3329 - accuracy: 0.3787 - val_loss: 1.3730 - val_accuracy: 0.3448\n",
      "Epoch 100/240\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3327 - accuracy: 0.3787 - val_loss: 1.3803 - val_accuracy: 0.3448\n",
      "Epoch 101/240\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 1.3325 - accuracy: 0.3787 - val_loss: 1.3703 - val_accuracy: 0.3448\n",
      "Epoch 102/240\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3318 - accuracy: 0.3787 - val_loss: 1.3711 - val_accuracy: 0.3448\n",
      "Epoch 103/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3342 - accuracy: 0.3787 - val_loss: 1.3796 - val_accuracy: 0.3448\n",
      "Epoch 104/240\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.3316 - accuracy: 0.3787 - val_loss: 1.3750 - val_accuracy: 0.3448\n",
      "Epoch 105/240\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3311 - accuracy: 0.3787 - val_loss: 1.3736 - val_accuracy: 0.3448\n",
      "Epoch 106/240\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.3331 - accuracy: 0.3787 - val_loss: 1.3871 - val_accuracy: 0.3448\n",
      "Epoch 107/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3347 - accuracy: 0.3787 - val_loss: 1.3851 - val_accuracy: 0.3448\n",
      "Epoch 108/240\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.3329 - accuracy: 0.3787 - val_loss: 1.3714 - val_accuracy: 0.3448\n",
      "Epoch 109/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3324 - accuracy: 0.3787 - val_loss: 1.3782 - val_accuracy: 0.3448\n",
      "Epoch 110/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3363 - accuracy: 0.3787 - val_loss: 1.3703 - val_accuracy: 0.3448\n",
      "Epoch 111/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3324 - accuracy: 0.3787 - val_loss: 1.3717 - val_accuracy: 0.3448\n",
      "Epoch 112/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3328 - accuracy: 0.3800 - val_loss: 1.3729 - val_accuracy: 0.3448\n",
      "Epoch 113/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3325 - accuracy: 0.3787 - val_loss: 1.3734 - val_accuracy: 0.3448\n",
      "Epoch 114/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3316 - accuracy: 0.3800 - val_loss: 1.3786 - val_accuracy: 0.3448\n",
      "Epoch 115/240\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 1.3307 - accuracy: 0.3762 - val_loss: 1.3734 - val_accuracy: 0.3448\n",
      "Epoch 116/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3323 - accuracy: 0.3787 - val_loss: 1.3683 - val_accuracy: 0.3448\n",
      "Epoch 117/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3406 - accuracy: 0.3787 - val_loss: 1.3701 - val_accuracy: 0.3448\n",
      "Epoch 118/240\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.3318 - accuracy: 0.3787 - val_loss: 1.3740 - val_accuracy: 0.3448\n",
      "Epoch 119/240\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3328 - accuracy: 0.3800 - val_loss: 1.3773 - val_accuracy: 0.3448\n",
      "Epoch 120/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3319 - accuracy: 0.3787 - val_loss: 1.3701 - val_accuracy: 0.3448\n",
      "Epoch 121/240\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.3316 - accuracy: 0.3787 - val_loss: 1.3720 - val_accuracy: 0.3448\n",
      "Epoch 122/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3309 - accuracy: 0.3787 - val_loss: 1.3714 - val_accuracy: 0.3448\n",
      "Epoch 123/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3279 - accuracy: 0.3812 - val_loss: 1.3739 - val_accuracy: 0.3448\n",
      "Epoch 124/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3331 - accuracy: 0.3787 - val_loss: 1.3773 - val_accuracy: 0.3391\n",
      "Epoch 125/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3295 - accuracy: 0.3775 - val_loss: 1.3788 - val_accuracy: 0.3448\n",
      "Epoch 126/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3293 - accuracy: 0.3825 - val_loss: 1.3803 - val_accuracy: 0.3448\n",
      "Epoch 127/240\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 1.3321 - accuracy: 0.3750 - val_loss: 1.3919 - val_accuracy: 0.3448\n",
      "Epoch 128/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3319 - accuracy: 0.3787 - val_loss: 1.3763 - val_accuracy: 0.3391\n",
      "Epoch 129/240\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.3280 - accuracy: 0.3738 - val_loss: 1.3933 - val_accuracy: 0.3448\n",
      "Epoch 130/240\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3380 - accuracy: 0.3787 - val_loss: 1.3851 - val_accuracy: 0.3506\n",
      "Epoch 131/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3303 - accuracy: 0.3750 - val_loss: 1.3759 - val_accuracy: 0.3448\n",
      "Epoch 132/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3306 - accuracy: 0.3750 - val_loss: 1.3798 - val_accuracy: 0.3448\n",
      "Epoch 133/240\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3321 - accuracy: 0.3787 - val_loss: 1.3886 - val_accuracy: 0.3448\n",
      "Epoch 134/240\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.3283 - accuracy: 0.3800 - val_loss: 1.3737 - val_accuracy: 0.3506\n",
      "Epoch 135/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3313 - accuracy: 0.3812 - val_loss: 1.3764 - val_accuracy: 0.3448\n",
      "Epoch 136/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3301 - accuracy: 0.3812 - val_loss: 1.3905 - val_accuracy: 0.3448\n",
      "Epoch 137/240\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3458 - accuracy: 0.3775 - val_loss: 1.3798 - val_accuracy: 0.3506\n",
      "Epoch 138/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3295 - accuracy: 0.3812 - val_loss: 1.3727 - val_accuracy: 0.3448\n",
      "Epoch 139/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3313 - accuracy: 0.3787 - val_loss: 1.3776 - val_accuracy: 0.3448\n",
      "Epoch 140/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3280 - accuracy: 0.3787 - val_loss: 1.3771 - val_accuracy: 0.3448\n",
      "Epoch 141/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3294 - accuracy: 0.3800 - val_loss: 1.3714 - val_accuracy: 0.3448\n",
      "Epoch 142/240\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 1.3305 - accuracy: 0.3800 - val_loss: 1.3803 - val_accuracy: 0.3448\n",
      "Epoch 143/240\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 1.3247 - accuracy: 0.3800 - val_loss: 1.4040 - val_accuracy: 0.3448\n",
      "Epoch 144/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3315 - accuracy: 0.3787 - val_loss: 1.3818 - val_accuracy: 0.3448\n",
      "Epoch 145/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3254 - accuracy: 0.3762 - val_loss: 1.3707 - val_accuracy: 0.3506\n",
      "Epoch 146/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3288 - accuracy: 0.3825 - val_loss: 1.4138 - val_accuracy: 0.3218\n",
      "Epoch 147/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3264 - accuracy: 0.3762 - val_loss: 1.3971 - val_accuracy: 0.3448\n",
      "Epoch 148/240\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 1.3276 - accuracy: 0.3775 - val_loss: 1.4982 - val_accuracy: 0.3448\n",
      "Epoch 149/240\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 1.3384 - accuracy: 0.3750 - val_loss: 1.3747 - val_accuracy: 0.3448\n",
      "Epoch 150/240\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.3282 - accuracy: 0.3812 - val_loss: 1.3774 - val_accuracy: 0.3448\n",
      "Epoch 151/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3294 - accuracy: 0.3812 - val_loss: 1.4002 - val_accuracy: 0.3448\n",
      "Epoch 152/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3249 - accuracy: 0.3800 - val_loss: 1.3868 - val_accuracy: 0.3448\n",
      "Epoch 153/240\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 1.3319 - accuracy: 0.3750 - val_loss: 1.3898 - val_accuracy: 0.3448\n",
      "Epoch 154/240\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 1.3266 - accuracy: 0.3738 - val_loss: 1.3813 - val_accuracy: 0.3391\n",
      "Epoch 155/240\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3254 - accuracy: 0.3738 - val_loss: 1.3841 - val_accuracy: 0.3448\n",
      "Epoch 156/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3297 - accuracy: 0.3762 - val_loss: 1.3861 - val_accuracy: 0.3448\n",
      "Epoch 157/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3289 - accuracy: 0.3775 - val_loss: 1.3788 - val_accuracy: 0.3448\n",
      "Epoch 158/240\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 1.3236 - accuracy: 0.3775 - val_loss: 1.3990 - val_accuracy: 0.3391\n",
      "Epoch 159/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3283 - accuracy: 0.3738 - val_loss: 1.3868 - val_accuracy: 0.3448\n",
      "Epoch 160/240\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3319 - accuracy: 0.3725 - val_loss: 1.3872 - val_accuracy: 0.3448\n",
      "Epoch 161/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3280 - accuracy: 0.3775 - val_loss: 1.3882 - val_accuracy: 0.3448\n",
      "Epoch 162/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3279 - accuracy: 0.3762 - val_loss: 1.3893 - val_accuracy: 0.3448\n",
      "Epoch 163/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3262 - accuracy: 0.3700 - val_loss: 1.4031 - val_accuracy: 0.3448\n",
      "Epoch 164/240\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.3274 - accuracy: 0.3762 - val_loss: 1.4028 - val_accuracy: 0.3448\n",
      "Epoch 165/240\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.3251 - accuracy: 0.3775 - val_loss: 1.3842 - val_accuracy: 0.3391\n",
      "Epoch 166/240\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.3275 - accuracy: 0.3713 - val_loss: 1.3973 - val_accuracy: 0.3391\n",
      "Epoch 167/240\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3252 - accuracy: 0.3750 - val_loss: 1.3821 - val_accuracy: 0.3448\n",
      "Epoch 168/240\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3243 - accuracy: 0.3750 - val_loss: 1.3826 - val_accuracy: 0.3448\n",
      "Epoch 169/240\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 1.3273 - accuracy: 0.3800 - val_loss: 1.3837 - val_accuracy: 0.3448\n",
      "Epoch 170/240\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.3243 - accuracy: 0.3775 - val_loss: 1.3864 - val_accuracy: 0.3448\n",
      "Epoch 171/240\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 1.3231 - accuracy: 0.3762 - val_loss: 1.3897 - val_accuracy: 0.3448\n",
      "Epoch 172/240\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.3284 - accuracy: 0.3825 - val_loss: 1.3850 - val_accuracy: 0.3448\n",
      "Epoch 173/240\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3249 - accuracy: 0.3800 - val_loss: 1.3842 - val_accuracy: 0.3448\n",
      "Epoch 174/240\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.3265 - accuracy: 0.3750 - val_loss: 1.3936 - val_accuracy: 0.3448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/240\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 1.3263 - accuracy: 0.3725 - val_loss: 1.3852 - val_accuracy: 0.3448\n",
      "Epoch 176/240\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 1.3226 - accuracy: 0.3750 - val_loss: 1.4082 - val_accuracy: 0.3391\n",
      "Epoch 177/240\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 1.3492 - accuracy: 0.3762 - val_loss: 1.3858 - val_accuracy: 0.3448\n",
      "Epoch 178/240\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 1.3267 - accuracy: 0.3738 - val_loss: 1.3891 - val_accuracy: 0.3448\n",
      "Epoch 179/240\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 1.3276 - accuracy: 0.3825 - val_loss: 1.3832 - val_accuracy: 0.3448\n",
      "Epoch 180/240\n",
      "7/7 [==============================] - 1s 131ms/step - loss: 1.3220 - accuracy: 0.3775 - val_loss: 1.3884 - val_accuracy: 0.3448\n",
      "Epoch 181/240\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 1.3279 - accuracy: 0.3750 - val_loss: 1.3936 - val_accuracy: 0.3448\n",
      "Epoch 182/240\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 1.3228 - accuracy: 0.3762 - val_loss: 1.4437 - val_accuracy: 0.3448\n",
      "Epoch 183/240\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 1.3225 - accuracy: 0.3762 - val_loss: 1.3781 - val_accuracy: 0.3448\n",
      "Epoch 184/240\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3247 - accuracy: 0.3800 - val_loss: 1.3899 - val_accuracy: 0.3448\n",
      "Epoch 185/240\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 1.3227 - accuracy: 0.3787 - val_loss: 1.4058 - val_accuracy: 0.3448\n",
      "Epoch 186/240\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 1.3231 - accuracy: 0.3787 - val_loss: 1.3946 - val_accuracy: 0.3448\n",
      "Epoch 187/240\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 1.3252 - accuracy: 0.3688 - val_loss: 1.4754 - val_accuracy: 0.3448\n",
      "Epoch 188/240\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 1.3410 - accuracy: 0.3787 - val_loss: 1.3834 - val_accuracy: 0.3448\n",
      "Epoch 189/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3200 - accuracy: 0.3775 - val_loss: 1.3904 - val_accuracy: 0.3448\n",
      "Epoch 190/240\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 1.3239 - accuracy: 0.3825 - val_loss: 1.3826 - val_accuracy: 0.3448\n",
      "Epoch 191/240\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 1.3266 - accuracy: 0.3787 - val_loss: 1.3828 - val_accuracy: 0.3448\n",
      "Epoch 192/240\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 1.3215 - accuracy: 0.3775 - val_loss: 1.3903 - val_accuracy: 0.3448\n",
      "Epoch 193/240\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 1.3268 - accuracy: 0.3800 - val_loss: 1.3937 - val_accuracy: 0.3448\n",
      "Epoch 194/240\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 1.3207 - accuracy: 0.3725 - val_loss: 1.3838 - val_accuracy: 0.3448\n",
      "Epoch 195/240\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 1.3242 - accuracy: 0.3787 - val_loss: 1.3887 - val_accuracy: 0.3448\n",
      "Epoch 196/240\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 1.3213 - accuracy: 0.3725 - val_loss: 1.3835 - val_accuracy: 0.3448\n",
      "Epoch 197/240\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 1.3233 - accuracy: 0.3800 - val_loss: 1.3790 - val_accuracy: 0.3448\n",
      "Epoch 198/240\n",
      "7/7 [==============================] - 1s 147ms/step - loss: 1.3291 - accuracy: 0.3800 - val_loss: 1.4075 - val_accuracy: 0.3448\n",
      "Epoch 199/240\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 1.3224 - accuracy: 0.3825 - val_loss: 1.4009 - val_accuracy: 0.3448\n",
      "Epoch 200/240\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.3258 - accuracy: 0.3775 - val_loss: 1.3933 - val_accuracy: 0.3448\n",
      "Epoch 201/240\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 1.3270 - accuracy: 0.3787 - val_loss: 1.3928 - val_accuracy: 0.3448\n",
      "Epoch 202/240\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 1.3230 - accuracy: 0.3750 - val_loss: 1.3801 - val_accuracy: 0.3448\n",
      "Epoch 203/240\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.3300 - accuracy: 0.3800 - val_loss: 1.3899 - val_accuracy: 0.3448\n",
      "Epoch 204/240\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 1.3260 - accuracy: 0.3750 - val_loss: 1.4203 - val_accuracy: 0.3448\n",
      "Epoch 205/240\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 1.3247 - accuracy: 0.3775 - val_loss: 1.4294 - val_accuracy: 0.3448\n",
      "Epoch 206/240\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.3249 - accuracy: 0.3787 - val_loss: 1.4680 - val_accuracy: 0.3391\n",
      "Epoch 207/240\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.3243 - accuracy: 0.3787 - val_loss: 1.4112 - val_accuracy: 0.3448\n",
      "Epoch 208/240\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 1.3245 - accuracy: 0.3825 - val_loss: 1.3863 - val_accuracy: 0.3448\n",
      "Epoch 209/240\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 1.3250 - accuracy: 0.3800 - val_loss: 1.3967 - val_accuracy: 0.3448\n",
      "Epoch 210/240\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 1.3245 - accuracy: 0.3812 - val_loss: 1.4389 - val_accuracy: 0.3448\n",
      "Epoch 211/240\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 1.3285 - accuracy: 0.3787 - val_loss: 1.3930 - val_accuracy: 0.3506\n",
      "Epoch 212/240\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.3226 - accuracy: 0.3738 - val_loss: 1.4491 - val_accuracy: 0.3391\n",
      "Epoch 213/240\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 1.3208 - accuracy: 0.3750 - val_loss: 1.3889 - val_accuracy: 0.3448\n",
      "Epoch 214/240\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.3232 - accuracy: 0.3787 - val_loss: 1.3861 - val_accuracy: 0.3448\n",
      "Epoch 215/240\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 1.3267 - accuracy: 0.3787 - val_loss: 1.4093 - val_accuracy: 0.3391\n",
      "Epoch 216/240\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.3194 - accuracy: 0.3750"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(training_X, training_y, epochs = 240, batch_size= 128, validation_data=(test_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
