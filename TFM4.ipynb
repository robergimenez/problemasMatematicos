{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import keras\n",
    "import six\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,AveragePooling1D,Flatten,concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/roberto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/roberto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/roberto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/roberto/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abro el archivo en el que se encuentra el dataset de los problemas\n",
    "with open('singleop.json', 'r') as f:\n",
    "    datastore = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo que contiene un listado de nombres\n",
    "nombres = pd.read_csv('nombres-2015.csv')\n",
    "names = pd.read_csv('yob2019.txt', header=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('problemas_adicionales2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas = []\n",
    "respuestas = []\n",
    "ecuaciones = []\n",
    "alineacion = []\n",
    "\n",
    "for item in datastore:\n",
    "    preguntas.append(item['sQuestion'])\n",
    "    respuestas.append(item['lSolutions'])\n",
    "    ecuaciones.append(item['lEquations'])\n",
    "    alineacion.append(item['lAlignments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tengo  159  sumas  162  restas,  117  multiplicaciones,  124  divisiones y otras operaciones  0\n"
     ]
    }
   ],
   "source": [
    "# Necesito convertir el dataset en un problema de clasificacion para que la red neuronal pueda identificar\n",
    "# si estoy tratando de resolver un problema de sumas, restas, multiplicaciones o divisiones.\n",
    "# Esto va a crear una lista con el tipo de operacion y que va a ser el resultado a inferir.\n",
    "operaciones = []\n",
    "sumas =0\n",
    "restas =0\n",
    "multiplicaciones =0\n",
    "divisiones = 0\n",
    "otras = 0\n",
    "#Clasifico las operaciones en 0 para sumas, 1 para restas, 2 para multiplicaciones, 3 para divisiones y 4 sino lo encuentro.\n",
    "for operacion in ecuaciones:\n",
    "    if (operacion[0].find('+')>=0):\n",
    "        operaciones.append(0)\n",
    "        sumas = sumas + 1\n",
    "    elif (operacion[0].find('-') >= 0 ):\n",
    "        operaciones.append(1)\n",
    "        restas = restas + 1\n",
    "    elif(operacion[0].find('*') >=0):\n",
    "        operaciones.append(2)\n",
    "        multiplicaciones = multiplicaciones + 1\n",
    "    elif(operacion[0].find('/')):\n",
    "        operaciones.append(3)\n",
    "        divisiones = divisiones + 1\n",
    "    else:\n",
    "        operaciones.append(4)\n",
    "        otras = otras + 1\n",
    "\n",
    "print('Tengo ', sumas, ' sumas ', restas, ' restas, ', multiplicaciones, ' multiplicaciones, ', divisiones, ' divisiones y otras operaciones ', otras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas2 = dataset2['Preguntas'].tolist()\n",
    "respuestas2 = dataset2['respuestas'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas3 = preguntas + preguntas2\n",
    "respuestas3 = operaciones + respuestas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El listado de nombres lo voy a truncar a los 15K primeros, dado que el resto son nombres muy residuales.\n",
    "nombres_ = nombres['nombre'][:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_= names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_ = nombres_.append(names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_words = list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom = nombres['nombre'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomb =  nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fiorella Luz Mailén'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomb[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El vector preguntas_sin, consiste en las preguntas a las que voy a eliminar todos los nombres propios que no\n",
    "# anaden ningun valor al conjunto de preguntas. No quiero que esos nombres se procesen y por tanto los elimino.\n",
    "def eliminar_palabras(dataset, stopw):\n",
    "    preguntas_sin = []\n",
    "    for palabras in dataset:\n",
    "        frases = [word for word in palabras.split(' ') if word not in stopw]\n",
    "        frases = \" \".join(frases)\n",
    "        preguntas_sin.append(frases)\n",
    "    return preguntas_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_sin = eliminar_palabras(preguntas3, nomb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_sin = preguntas3 + eliminar_palabras(preguntas3, nomb) + eliminar_palabras(preguntas3, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuestas3 = respuestas3 *3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cada ticket cuesta $9.00. ¿Cuanto cuestan 4 tickets? 2\n"
     ]
    }
   ],
   "source": [
    "print(preguntas_sin[130], respuestas3[130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "preguntas3, respuestas3 = shuffle(preguntas_sin,respuestas3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_w = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for i,pregunta in enumerate(preguntas_sin):\n",
    "    palabras = tokenizer.tokenize(pregunta)\n",
    "    for palabra in palabras:\n",
    "        preguntas_w.append(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_unicas = set(preguntas_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_unicas = list(palabras_unicas)\n",
    "\n",
    "vocabulario = {p:i for i, p in enumerate(p_unicas)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = gensim.models.KeyedVectors.load_word2vec_format('SBW-vectors-300-min5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for key in vocabulario.keys():\n",
    "    if key not in glove:\n",
    "        zeros = np.zeros(300)\n",
    "        if key.isdigit():\n",
    "            for i in range(0,300):\n",
    "                zeros[i] = int(key)*0.000001\n",
    "        embeddings.append({key: zeros})\n",
    "    else:\n",
    "        embeddings.append({key : glove[key][:300]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_embeddings = []\n",
    "\n",
    "for i, preguntas in enumerate(preguntas_sin):\n",
    "    palabras = tokenizer.tokenize(preguntas)\n",
    "    words = []\n",
    "    for j,palabra in enumerate(palabras):\n",
    "        for h, word in enumerate(embeddings):\n",
    "            for key in embeddings[h]:\n",
    "                if(key == palabra):\n",
    "                    words.append(embeddings[h][palabra][:300])\n",
    "    if (j < 48):\n",
    "        for j in range (j, 48):\n",
    "            words.append(p)\n",
    "    preguntas_embeddings.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el tamano del vocabulario\n",
    "vocabulario = []\n",
    "\n",
    "for pregunta in preguntas_w:\n",
    "    for palabra in pregunta:\n",
    "        vocabulario.append(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = set(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El tamano del vocabulario es necesario para poder crear la matriz de embeddings, con el numero de palabras\n",
    "# totales que tengo\n",
    "embedding_dim = 16\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preguntas_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_X = np.asarray(preguntas_embeddings[:2100])\n",
    "test_X = np.asarray(preguntas_embeddings[2100:])\n",
    "training_y = np.asarray(respuestas3[:2100])\n",
    "test_y = np.asarray(respuestas3[2100:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in training_X:\n",
    "    if(len(i) != 49):\n",
    "        print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un modelo donde el primer argumento de la capa embedding son las palabras totales que voy a procesar\n",
    "# vectorizadas en un indice.\n",
    "# El segundo argumento, es el tamano del vector embedding, que he fijado en 16.\n",
    "# El tercer argumento, es el tamano o longitud maxima, que he definido para las preguntas. Numero total de palabras\n",
    "# por pregunta.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(36, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \"\"\"\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2352\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.3622 - accuracy: 0.3329 - val_loss: 1.3507 - val_accuracy: 0.3783\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.3332 - accuracy: 0.3629 - val_loss: 1.3512 - val_accuracy: 0.3783\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3053 - accuracy: 0.3762 - val_loss: 1.3471 - val_accuracy: 0.3820\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.2666 - accuracy: 0.4033 - val_loss: 1.3468 - val_accuracy: 0.3929\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2171 - accuracy: 0.4376 - val_loss: 1.3522 - val_accuracy: 0.3771\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.1427 - accuracy: 0.4876 - val_loss: 1.3511 - val_accuracy: 0.3431\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.0791 - accuracy: 0.5390 - val_loss: 1.3866 - val_accuracy: 0.3175\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.9916 - accuracy: 0.5810 - val_loss: 1.4202 - val_accuracy: 0.3467\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.9212 - accuracy: 0.6181 - val_loss: 1.4631 - val_accuracy: 0.3139\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.8424 - accuracy: 0.6533 - val_loss: 1.5181 - val_accuracy: 0.3163\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.8133 - accuracy: 0.6548 - val_loss: 1.4965 - val_accuracy: 0.3212\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.7530 - accuracy: 0.6800 - val_loss: 1.5941 - val_accuracy: 0.3114\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.7187 - accuracy: 0.6919 - val_loss: 1.6144 - val_accuracy: 0.3127\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.6845 - accuracy: 0.7071 - val_loss: 1.6606 - val_accuracy: 0.3406\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.6688 - accuracy: 0.7110 - val_loss: 1.6553 - val_accuracy: 0.3273\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6301 - accuracy: 0.7229 - val_loss: 1.6678 - val_accuracy: 0.3248\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6078 - accuracy: 0.7224 - val_loss: 1.7600 - val_accuracy: 0.3309\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5754 - accuracy: 0.7376 - val_loss: 1.8092 - val_accuracy: 0.3333\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5681 - accuracy: 0.7367 - val_loss: 1.8205 - val_accuracy: 0.3285\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5395 - accuracy: 0.7514 - val_loss: 1.9235 - val_accuracy: 0.3187\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5540 - accuracy: 0.7371 - val_loss: 1.9261 - val_accuracy: 0.3382\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5389 - accuracy: 0.7352 - val_loss: 1.9212 - val_accuracy: 0.3151\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5244 - accuracy: 0.7467 - val_loss: 1.9921 - val_accuracy: 0.3273\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.4981 - accuracy: 0.7605 - val_loss: 2.0323 - val_accuracy: 0.3406\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5040 - accuracy: 0.7481 - val_loss: 2.0072 - val_accuracy: 0.3297\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5214 - accuracy: 0.7457 - val_loss: 2.0203 - val_accuracy: 0.3187\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5049 - accuracy: 0.7519 - val_loss: 2.0385 - val_accuracy: 0.3236\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4703 - accuracy: 0.7738 - val_loss: 2.0692 - val_accuracy: 0.3273\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4621 - accuracy: 0.7586 - val_loss: 2.1537 - val_accuracy: 0.3443\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.4739 - accuracy: 0.7562 - val_loss: 2.1168 - val_accuracy: 0.3345\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.4632 - accuracy: 0.7643 - val_loss: 2.1251 - val_accuracy: 0.3248\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4582 - accuracy: 0.7662 - val_loss: 2.2640 - val_accuracy: 0.3139\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4439 - accuracy: 0.7633 - val_loss: 2.3111 - val_accuracy: 0.3224\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4425 - accuracy: 0.7619 - val_loss: 2.2505 - val_accuracy: 0.3151\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4508 - accuracy: 0.7681 - val_loss: 2.2739 - val_accuracy: 0.3370\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4242 - accuracy: 0.7714 - val_loss: 2.4063 - val_accuracy: 0.3285\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.4367 - accuracy: 0.7562 - val_loss: 2.3915 - val_accuracy: 0.3163\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4207 - accuracy: 0.7662 - val_loss: 2.3177 - val_accuracy: 0.3224\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.4160 - accuracy: 0.7652 - val_loss: 2.4360 - val_accuracy: 0.3175\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.4166 - accuracy: 0.7652 - val_loss: 2.3263 - val_accuracy: 0.3248\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4251 - accuracy: 0.7676 - val_loss: 2.4762 - val_accuracy: 0.3200\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4017 - accuracy: 0.7743 - val_loss: 2.4424 - val_accuracy: 0.3248\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4026 - accuracy: 0.7838 - val_loss: 2.4888 - val_accuracy: 0.3321\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4130 - accuracy: 0.7624 - val_loss: 2.5335 - val_accuracy: 0.3273\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3963 - accuracy: 0.7795 - val_loss: 2.5305 - val_accuracy: 0.3394\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4049 - accuracy: 0.7805 - val_loss: 2.5302 - val_accuracy: 0.3370\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3947 - accuracy: 0.7862 - val_loss: 2.5759 - val_accuracy: 0.3139\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.4007 - accuracy: 0.7733 - val_loss: 2.5426 - val_accuracy: 0.3333\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3936 - accuracy: 0.7676 - val_loss: 2.5667 - val_accuracy: 0.3212\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3800 - accuracy: 0.7848 - val_loss: 2.6732 - val_accuracy: 0.3163\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3882 - accuracy: 0.7671 - val_loss: 2.7235 - val_accuracy: 0.3200\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3832 - accuracy: 0.7800 - val_loss: 2.5962 - val_accuracy: 0.3224\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3733 - accuracy: 0.8000 - val_loss: 2.6919 - val_accuracy: 0.3224\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3928 - accuracy: 0.7686 - val_loss: 2.6291 - val_accuracy: 0.3358\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3662 - accuracy: 0.7819 - val_loss: 2.7911 - val_accuracy: 0.3273\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3850 - accuracy: 0.7771 - val_loss: 2.6393 - val_accuracy: 0.3187\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3769 - accuracy: 0.7733 - val_loss: 2.7431 - val_accuracy: 0.3236\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3758 - accuracy: 0.7705 - val_loss: 2.6710 - val_accuracy: 0.3236\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3719 - accuracy: 0.7748 - val_loss: 2.7841 - val_accuracy: 0.3151\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3784 - accuracy: 0.7848 - val_loss: 2.7361 - val_accuracy: 0.3333\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3737 - accuracy: 0.7719 - val_loss: 2.8491 - val_accuracy: 0.3187\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3772 - accuracy: 0.7767 - val_loss: 2.7589 - val_accuracy: 0.3090\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3669 - accuracy: 0.7852 - val_loss: 2.8715 - val_accuracy: 0.3260\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3607 - accuracy: 0.7724 - val_loss: 3.0034 - val_accuracy: 0.3163\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3665 - accuracy: 0.7838 - val_loss: 2.8014 - val_accuracy: 0.3187\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3682 - accuracy: 0.7843 - val_loss: 2.9254 - val_accuracy: 0.3066\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3685 - accuracy: 0.7810 - val_loss: 2.9349 - val_accuracy: 0.3212\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3549 - accuracy: 0.7900 - val_loss: 2.9648 - val_accuracy: 0.3187\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3634 - accuracy: 0.7790 - val_loss: 2.9333 - val_accuracy: 0.3114\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3545 - accuracy: 0.7871 - val_loss: 3.0502 - val_accuracy: 0.3139\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3557 - accuracy: 0.7776 - val_loss: 3.0590 - val_accuracy: 0.3054\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3539 - accuracy: 0.7800 - val_loss: 2.9244 - val_accuracy: 0.3285\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3554 - accuracy: 0.7762 - val_loss: 3.0607 - val_accuracy: 0.3248\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3629 - accuracy: 0.7752 - val_loss: 2.9570 - val_accuracy: 0.3151\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3568 - accuracy: 0.7752 - val_loss: 2.9117 - val_accuracy: 0.3285\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3545 - accuracy: 0.7819 - val_loss: 3.0819 - val_accuracy: 0.3066\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3490 - accuracy: 0.7843 - val_loss: 3.0966 - val_accuracy: 0.3297\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3464 - accuracy: 0.7852 - val_loss: 3.0391 - val_accuracy: 0.3236\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3505 - accuracy: 0.7795 - val_loss: 3.0474 - val_accuracy: 0.3187\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3469 - accuracy: 0.7829 - val_loss: 3.0458 - val_accuracy: 0.3175\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3509 - accuracy: 0.7810 - val_loss: 3.1491 - val_accuracy: 0.3297\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3420 - accuracy: 0.7833 - val_loss: 3.1930 - val_accuracy: 0.3248\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3408 - accuracy: 0.7838 - val_loss: 3.1801 - val_accuracy: 0.3090\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3450 - accuracy: 0.7776 - val_loss: 3.2108 - val_accuracy: 0.3285\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3402 - accuracy: 0.7790 - val_loss: 3.1988 - val_accuracy: 0.3236\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3460 - accuracy: 0.7843 - val_loss: 3.2247 - val_accuracy: 0.3187\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3476 - accuracy: 0.7748 - val_loss: 3.2001 - val_accuracy: 0.3151\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3374 - accuracy: 0.7852 - val_loss: 3.3314 - val_accuracy: 0.3200\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3418 - accuracy: 0.7876 - val_loss: 3.1444 - val_accuracy: 0.3309\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3412 - accuracy: 0.7829 - val_loss: 3.2871 - val_accuracy: 0.3090\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3397 - accuracy: 0.7795 - val_loss: 3.4165 - val_accuracy: 0.3236\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3402 - accuracy: 0.7943 - val_loss: 3.2263 - val_accuracy: 0.3297\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3310 - accuracy: 0.7862 - val_loss: 3.4350 - val_accuracy: 0.3102\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3391 - accuracy: 0.7895 - val_loss: 3.4264 - val_accuracy: 0.3175\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3375 - accuracy: 0.7757 - val_loss: 3.3873 - val_accuracy: 0.3102\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3317 - accuracy: 0.7938 - val_loss: 3.4020 - val_accuracy: 0.3187\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3308 - accuracy: 0.7762 - val_loss: 3.4066 - val_accuracy: 0.3321\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3327 - accuracy: 0.8000 - val_loss: 3.4123 - val_accuracy: 0.3151\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3367 - accuracy: 0.7914 - val_loss: 3.3564 - val_accuracy: 0.3285\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3358 - accuracy: 0.7805 - val_loss: 3.5339 - val_accuracy: 0.3382\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3362 - accuracy: 0.7905 - val_loss: 3.3722 - val_accuracy: 0.3151\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3411 - accuracy: 0.7781 - val_loss: 3.4538 - val_accuracy: 0.3224\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3303 - accuracy: 0.7819 - val_loss: 3.4601 - val_accuracy: 0.3260\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3311 - accuracy: 0.7762 - val_loss: 3.5470 - val_accuracy: 0.3163\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3278 - accuracy: 0.7871 - val_loss: 3.6953 - val_accuracy: 0.3054\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3330 - accuracy: 0.7895 - val_loss: 3.4654 - val_accuracy: 0.3260\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3336 - accuracy: 0.7795 - val_loss: 3.5757 - val_accuracy: 0.3163\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3386 - accuracy: 0.7852 - val_loss: 3.4304 - val_accuracy: 0.3114\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3318 - accuracy: 0.7843 - val_loss: 3.7150 - val_accuracy: 0.3187\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3298 - accuracy: 0.7838 - val_loss: 3.5982 - val_accuracy: 0.3114\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3341 - accuracy: 0.7852 - val_loss: 3.4659 - val_accuracy: 0.3260\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3323 - accuracy: 0.7795 - val_loss: 3.5143 - val_accuracy: 0.3175\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3296 - accuracy: 0.7843 - val_loss: 3.6363 - val_accuracy: 0.3102\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3315 - accuracy: 0.7814 - val_loss: 3.7438 - val_accuracy: 0.3224\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3294 - accuracy: 0.7895 - val_loss: 3.4969 - val_accuracy: 0.3260\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3319 - accuracy: 0.7924 - val_loss: 3.6063 - val_accuracy: 0.3297\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3292 - accuracy: 0.7862 - val_loss: 3.6680 - val_accuracy: 0.3333\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3224 - accuracy: 0.7914 - val_loss: 3.7386 - val_accuracy: 0.3127\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3259 - accuracy: 0.7752 - val_loss: 3.7195 - val_accuracy: 0.3151\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3306 - accuracy: 0.7933 - val_loss: 3.6092 - val_accuracy: 0.3163\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3268 - accuracy: 0.7814 - val_loss: 3.7989 - val_accuracy: 0.3260\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3220 - accuracy: 0.7957 - val_loss: 3.7764 - val_accuracy: 0.3273\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3246 - accuracy: 0.7795 - val_loss: 3.8325 - val_accuracy: 0.3260\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3211 - accuracy: 0.7857 - val_loss: 3.8567 - val_accuracy: 0.3212\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3255 - accuracy: 0.7890 - val_loss: 3.7287 - val_accuracy: 0.3224\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3209 - accuracy: 0.7910 - val_loss: 3.9389 - val_accuracy: 0.3382\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3230 - accuracy: 0.7886 - val_loss: 3.9076 - val_accuracy: 0.3139\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3258 - accuracy: 0.7824 - val_loss: 3.7902 - val_accuracy: 0.3224\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3308 - accuracy: 0.7810 - val_loss: 3.8786 - val_accuracy: 0.3224\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3223 - accuracy: 0.7924 - val_loss: 3.9324 - val_accuracy: 0.3151\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3245 - accuracy: 0.7838 - val_loss: 3.9628 - val_accuracy: 0.3200\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3296 - accuracy: 0.7852 - val_loss: 3.8413 - val_accuracy: 0.3114\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3252 - accuracy: 0.7938 - val_loss: 3.9099 - val_accuracy: 0.3200\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3238 - accuracy: 0.7876 - val_loss: 3.8633 - val_accuracy: 0.3066\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3194 - accuracy: 0.7924 - val_loss: 4.0099 - val_accuracy: 0.3139\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3226 - accuracy: 0.7910 - val_loss: 4.0219 - val_accuracy: 0.3139\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3256 - accuracy: 0.7810 - val_loss: 3.8248 - val_accuracy: 0.3309\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3188 - accuracy: 0.7981 - val_loss: 4.0035 - val_accuracy: 0.2956\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3183 - accuracy: 0.7919 - val_loss: 3.9709 - val_accuracy: 0.3175\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3169 - accuracy: 0.7919 - val_loss: 4.0411 - val_accuracy: 0.3066\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3255 - accuracy: 0.7919 - val_loss: 4.0286 - val_accuracy: 0.3224\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3204 - accuracy: 0.7776 - val_loss: 3.9907 - val_accuracy: 0.3187\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3176 - accuracy: 0.7971 - val_loss: 4.0083 - val_accuracy: 0.3273\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3168 - accuracy: 0.7857 - val_loss: 4.0302 - val_accuracy: 0.3139\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3209 - accuracy: 0.7971 - val_loss: 4.1305 - val_accuracy: 0.3187\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3244 - accuracy: 0.7819 - val_loss: 3.8762 - val_accuracy: 0.3345\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3228 - accuracy: 0.7857 - val_loss: 4.1636 - val_accuracy: 0.3151\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3264 - accuracy: 0.7757 - val_loss: 4.1659 - val_accuracy: 0.3236\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3169 - accuracy: 0.7981 - val_loss: 4.1057 - val_accuracy: 0.3248\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3337 - accuracy: 0.7867 - val_loss: 4.1852 - val_accuracy: 0.3285\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3254 - accuracy: 0.7886 - val_loss: 3.8802 - val_accuracy: 0.3151\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3266 - accuracy: 0.7852 - val_loss: 4.2324 - val_accuracy: 0.3102\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3258 - accuracy: 0.7786 - val_loss: 3.9739 - val_accuracy: 0.3041\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3214 - accuracy: 0.7900 - val_loss: 4.1140 - val_accuracy: 0.3297\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3216 - accuracy: 0.7890 - val_loss: 4.1797 - val_accuracy: 0.3102\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3298 - accuracy: 0.7810 - val_loss: 4.0935 - val_accuracy: 0.3139\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3190 - accuracy: 0.7833 - val_loss: 4.1996 - val_accuracy: 0.3151\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3156 - accuracy: 0.7933 - val_loss: 4.1646 - val_accuracy: 0.3151\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3173 - accuracy: 0.7952 - val_loss: 4.3983 - val_accuracy: 0.3224\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3105 - accuracy: 0.8014 - val_loss: 4.3952 - val_accuracy: 0.3273\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3235 - accuracy: 0.7929 - val_loss: 4.2315 - val_accuracy: 0.3248\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3139 - accuracy: 0.7924 - val_loss: 4.4455 - val_accuracy: 0.3163\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3192 - accuracy: 0.7800 - val_loss: 4.5020 - val_accuracy: 0.3236\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3167 - accuracy: 0.7929 - val_loss: 4.2262 - val_accuracy: 0.3297\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3141 - accuracy: 0.7948 - val_loss: 4.2921 - val_accuracy: 0.3224\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3224 - accuracy: 0.7786 - val_loss: 4.1815 - val_accuracy: 0.3418\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3152 - accuracy: 0.7957 - val_loss: 4.4789 - val_accuracy: 0.3212\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3165 - accuracy: 0.7924 - val_loss: 4.4165 - val_accuracy: 0.3285\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3174 - accuracy: 0.7895 - val_loss: 4.4067 - val_accuracy: 0.3017\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3137 - accuracy: 0.7895 - val_loss: 4.5230 - val_accuracy: 0.3260\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3183 - accuracy: 0.7905 - val_loss: 4.2598 - val_accuracy: 0.3139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3208 - accuracy: 0.7838 - val_loss: 4.4105 - val_accuracy: 0.3260\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3173 - accuracy: 0.7848 - val_loss: 4.3692 - val_accuracy: 0.3187\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3202 - accuracy: 0.7886 - val_loss: 4.5421 - val_accuracy: 0.3236\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3257 - accuracy: 0.7852 - val_loss: 4.1245 - val_accuracy: 0.3248\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3158 - accuracy: 0.7910 - val_loss: 4.5214 - val_accuracy: 0.3151\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3184 - accuracy: 0.7795 - val_loss: 4.6024 - val_accuracy: 0.3114\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3120 - accuracy: 0.7981 - val_loss: 4.4530 - val_accuracy: 0.3260\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3134 - accuracy: 0.7910 - val_loss: 4.7321 - val_accuracy: 0.3273\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3141 - accuracy: 0.7910 - val_loss: 4.7377 - val_accuracy: 0.3005\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3187 - accuracy: 0.7843 - val_loss: 4.2420 - val_accuracy: 0.3370\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3155 - accuracy: 0.7857 - val_loss: 4.4965 - val_accuracy: 0.3127\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3141 - accuracy: 0.7852 - val_loss: 4.4946 - val_accuracy: 0.3309\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3146 - accuracy: 0.7981 - val_loss: 4.5990 - val_accuracy: 0.3114\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3230 - accuracy: 0.7757 - val_loss: 4.3251 - val_accuracy: 0.3248\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3163 - accuracy: 0.7924 - val_loss: 4.4212 - val_accuracy: 0.3321\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3167 - accuracy: 0.7910 - val_loss: 4.6577 - val_accuracy: 0.3127\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3139 - accuracy: 0.7905 - val_loss: 4.7590 - val_accuracy: 0.3212\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3177 - accuracy: 0.7757 - val_loss: 4.8498 - val_accuracy: 0.2968\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3169 - accuracy: 0.7938 - val_loss: 4.4638 - val_accuracy: 0.3297\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3164 - accuracy: 0.7938 - val_loss: 4.7546 - val_accuracy: 0.3127\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3156 - accuracy: 0.7810 - val_loss: 4.8536 - val_accuracy: 0.3151\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3144 - accuracy: 0.7933 - val_loss: 4.6756 - val_accuracy: 0.3078\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3130 - accuracy: 0.7857 - val_loss: 4.7291 - val_accuracy: 0.3066\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3164 - accuracy: 0.7995 - val_loss: 4.8808 - val_accuracy: 0.3066\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3163 - accuracy: 0.7929 - val_loss: 4.7908 - val_accuracy: 0.3151\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3121 - accuracy: 0.7938 - val_loss: 4.7592 - val_accuracy: 0.3297\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3125 - accuracy: 0.8000 - val_loss: 4.8659 - val_accuracy: 0.3029\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3150 - accuracy: 0.7857 - val_loss: 4.8448 - val_accuracy: 0.3224\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3109 - accuracy: 0.7933 - val_loss: 4.8983 - val_accuracy: 0.2993\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3178 - accuracy: 0.7910 - val_loss: 4.9788 - val_accuracy: 0.3285\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3142 - accuracy: 0.7843 - val_loss: 4.8144 - val_accuracy: 0.3066\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3242 - accuracy: 0.7886 - val_loss: 4.7655 - val_accuracy: 0.3212\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3119 - accuracy: 0.7967 - val_loss: 4.7856 - val_accuracy: 0.2981\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3160 - accuracy: 0.7862 - val_loss: 4.9769 - val_accuracy: 0.3041\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3160 - accuracy: 0.7838 - val_loss: 4.8616 - val_accuracy: 0.3175\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3142 - accuracy: 0.7919 - val_loss: 4.8527 - val_accuracy: 0.3066\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3198 - accuracy: 0.7952 - val_loss: 5.0498 - val_accuracy: 0.3248\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3305 - accuracy: 0.7895 - val_loss: 4.9035 - val_accuracy: 0.3066\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3184 - accuracy: 0.7805 - val_loss: 4.8654 - val_accuracy: 0.3127\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3290 - accuracy: 0.7843 - val_loss: 4.7484 - val_accuracy: 0.3090\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3181 - accuracy: 0.7776 - val_loss: 4.9089 - val_accuracy: 0.3054\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3109 - accuracy: 0.7881 - val_loss: 4.9870 - val_accuracy: 0.3102\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3107 - accuracy: 0.8010 - val_loss: 4.9563 - val_accuracy: 0.3187\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3203 - accuracy: 0.7833 - val_loss: 4.9239 - val_accuracy: 0.3066\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3167 - accuracy: 0.7895 - val_loss: 5.0452 - val_accuracy: 0.3236\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3186 - accuracy: 0.7881 - val_loss: 4.9823 - val_accuracy: 0.3090\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3126 - accuracy: 0.7905 - val_loss: 5.3412 - val_accuracy: 0.2993\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3174 - accuracy: 0.7862 - val_loss: 5.0534 - val_accuracy: 0.3090\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3190 - accuracy: 0.7905 - val_loss: 4.7530 - val_accuracy: 0.3187\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3202 - accuracy: 0.7838 - val_loss: 5.1233 - val_accuracy: 0.3066\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3104 - accuracy: 0.7933 - val_loss: 4.9921 - val_accuracy: 0.3163\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3147 - accuracy: 0.7962 - val_loss: 5.0479 - val_accuracy: 0.3224\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3071 - accuracy: 0.7895 - val_loss: 5.3455 - val_accuracy: 0.3102\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3171 - accuracy: 0.7757 - val_loss: 5.1448 - val_accuracy: 0.3041\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3132 - accuracy: 0.7900 - val_loss: 5.1146 - val_accuracy: 0.3090\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3115 - accuracy: 0.7924 - val_loss: 4.9357 - val_accuracy: 0.3139\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3090 - accuracy: 0.7905 - val_loss: 5.3948 - val_accuracy: 0.3187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3105 - accuracy: 0.7824 - val_loss: 5.2668 - val_accuracy: 0.3285\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3161 - accuracy: 0.7862 - val_loss: 5.2176 - val_accuracy: 0.3090\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3136 - accuracy: 0.8048 - val_loss: 5.1438 - val_accuracy: 0.3041\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3130 - accuracy: 0.7862 - val_loss: 5.2152 - val_accuracy: 0.3175\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3185 - accuracy: 0.7810 - val_loss: 5.3856 - val_accuracy: 0.3248\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3112 - accuracy: 0.7767 - val_loss: 5.2900 - val_accuracy: 0.3102\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3123 - accuracy: 0.7929 - val_loss: 5.3459 - val_accuracy: 0.3078\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3102 - accuracy: 0.7995 - val_loss: 5.0084 - val_accuracy: 0.3236\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3119 - accuracy: 0.7881 - val_loss: 5.1718 - val_accuracy: 0.3175\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3104 - accuracy: 0.7824 - val_loss: 5.4344 - val_accuracy: 0.3236\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3161 - accuracy: 0.7976 - val_loss: 5.1040 - val_accuracy: 0.3333\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3348 - accuracy: 0.7724 - val_loss: 4.7479 - val_accuracy: 0.3273\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3198 - accuracy: 0.7905 - val_loss: 5.4812 - val_accuracy: 0.2944\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3150 - accuracy: 0.7890 - val_loss: 5.2324 - val_accuracy: 0.3127\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3197 - accuracy: 0.7900 - val_loss: 5.0536 - val_accuracy: 0.3248\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3162 - accuracy: 0.7829 - val_loss: 5.2449 - val_accuracy: 0.3151\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3120 - accuracy: 0.7829 - val_loss: 5.4130 - val_accuracy: 0.3054\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3192 - accuracy: 0.7862 - val_loss: 5.1246 - val_accuracy: 0.3078\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3223 - accuracy: 0.7914 - val_loss: 5.1508 - val_accuracy: 0.3297\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3254 - accuracy: 0.7800 - val_loss: 5.3144 - val_accuracy: 0.2981\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3233 - accuracy: 0.7838 - val_loss: 5.0150 - val_accuracy: 0.3321\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3158 - accuracy: 0.7857 - val_loss: 5.6518 - val_accuracy: 0.3114\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3215 - accuracy: 0.7976 - val_loss: 5.2861 - val_accuracy: 0.3029\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3223 - accuracy: 0.7838 - val_loss: 5.2161 - val_accuracy: 0.3236\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3192 - accuracy: 0.7814 - val_loss: 5.1809 - val_accuracy: 0.3151\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3124 - accuracy: 0.7929 - val_loss: 5.4529 - val_accuracy: 0.3127\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3134 - accuracy: 0.7967 - val_loss: 5.3720 - val_accuracy: 0.3114\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3137 - accuracy: 0.7895 - val_loss: 5.4737 - val_accuracy: 0.3273\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3124 - accuracy: 0.7895 - val_loss: 5.7314 - val_accuracy: 0.3236\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3159 - accuracy: 0.7890 - val_loss: 5.1054 - val_accuracy: 0.3175\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3122 - accuracy: 0.7881 - val_loss: 5.0857 - val_accuracy: 0.3236\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3147 - accuracy: 0.7838 - val_loss: 5.9509 - val_accuracy: 0.2968\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3142 - accuracy: 0.7910 - val_loss: 5.3918 - val_accuracy: 0.3273\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3101 - accuracy: 0.7976 - val_loss: 5.1884 - val_accuracy: 0.3127\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3262 - accuracy: 0.7686 - val_loss: 5.2428 - val_accuracy: 0.3066\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3224 - accuracy: 0.7810 - val_loss: 5.3777 - val_accuracy: 0.3114\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3178 - accuracy: 0.7957 - val_loss: 5.5020 - val_accuracy: 0.3090\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3135 - accuracy: 0.7852 - val_loss: 5.4958 - val_accuracy: 0.3224\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3152 - accuracy: 0.7876 - val_loss: 5.4365 - val_accuracy: 0.3200\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3125 - accuracy: 0.7862 - val_loss: 5.1773 - val_accuracy: 0.3187\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3205 - accuracy: 0.7938 - val_loss: 5.3982 - val_accuracy: 0.3114\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3121 - accuracy: 0.7890 - val_loss: 5.4179 - val_accuracy: 0.3187\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3092 - accuracy: 0.7948 - val_loss: 5.4255 - val_accuracy: 0.3200\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3192 - accuracy: 0.7852 - val_loss: 5.0909 - val_accuracy: 0.3260\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3235 - accuracy: 0.7881 - val_loss: 5.3336 - val_accuracy: 0.3200\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3192 - accuracy: 0.7905 - val_loss: 5.4313 - val_accuracy: 0.3175\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3190 - accuracy: 0.7738 - val_loss: 5.5298 - val_accuracy: 0.2932\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3274 - accuracy: 0.7757 - val_loss: 5.1641 - val_accuracy: 0.3175\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3168 - accuracy: 0.7943 - val_loss: 5.3600 - val_accuracy: 0.3236\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3141 - accuracy: 0.7819 - val_loss: 5.4025 - val_accuracy: 0.3309\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3111 - accuracy: 0.7924 - val_loss: 5.5977 - val_accuracy: 0.3054\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3093 - accuracy: 0.7962 - val_loss: 5.5347 - val_accuracy: 0.3224\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3121 - accuracy: 0.7919 - val_loss: 5.6315 - val_accuracy: 0.2956\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3077 - accuracy: 0.7952 - val_loss: 5.8622 - val_accuracy: 0.3236\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3131 - accuracy: 0.7948 - val_loss: 5.8754 - val_accuracy: 0.2944\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3180 - accuracy: 0.7929 - val_loss: 5.5150 - val_accuracy: 0.3187\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3182 - accuracy: 0.7833 - val_loss: 5.6278 - val_accuracy: 0.2993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3103 - accuracy: 0.7976 - val_loss: 5.5843 - val_accuracy: 0.3200\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3090 - accuracy: 0.7962 - val_loss: 5.6604 - val_accuracy: 0.3163\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3200 - accuracy: 0.7790 - val_loss: 5.6596 - val_accuracy: 0.3309\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3187 - accuracy: 0.7795 - val_loss: 5.5346 - val_accuracy: 0.3041\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3176 - accuracy: 0.7886 - val_loss: 5.8443 - val_accuracy: 0.3309\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3077 - accuracy: 0.7900 - val_loss: 5.7608 - val_accuracy: 0.3163\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.3086 - accuracy: 0.7929 - val_loss: 5.9364 - val_accuracy: 0.3175\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3095 - accuracy: 0.7976 - val_loss: 6.0707 - val_accuracy: 0.3321\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.3119 - accuracy: 0.7929 - val_loss: 5.8223 - val_accuracy: 0.3297\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3182 - accuracy: 0.7752 - val_loss: 5.8199 - val_accuracy: 0.3370\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.3099 - accuracy: 0.7905 - val_loss: 5.9746 - val_accuracy: 0.3066\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3160 - accuracy: 0.7871 - val_loss: 5.8465 - val_accuracy: 0.3212\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3081 - accuracy: 0.7914 - val_loss: 5.8354 - val_accuracy: 0.3309\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3147 - accuracy: 0.7743 - val_loss: 6.1224 - val_accuracy: 0.3175\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.3089 - accuracy: 0.7895 - val_loss: 5.9044 - val_accuracy: 0.3248\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_X, training_y, epochs = 300, validation_data=(test_X, test_y), batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(128, dropout = 0.2, return_sequences= True, input_shape=training_X.shape)),\n",
    "    keras.layers.LSTM (64, dropout = 0.2, return_sequences = True),\n",
    "    keras.layers.LSTM (128, dropout = 0.2, return_sequences = True),\n",
    "    keras.layers.LSTM (256, dropout = 0.2, return_sequences = True),\n",
    "    keras.layers.LSTM (64, dropout = 0.2),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "opt = keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-07,\n",
    "    centered=False,\n",
    ")\n",
    "\n",
    "#opt = keras.optimizers.SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#opt = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model2.compile(loss='sparse_categorical_crossentropy',optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7213 - accuracy: 0.6614 - val_loss: 2.4714 - val_accuracy: 0.2628\n",
      "Epoch 2/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.7167 - accuracy: 0.6600 - val_loss: 2.5147 - val_accuracy: 0.2835\n",
      "Epoch 3/240\n",
      "17/17 [==============================] - 22s 1s/step - loss: 0.6866 - accuracy: 0.6614 - val_loss: 2.5142 - val_accuracy: 0.2883\n",
      "Epoch 4/240\n",
      "17/17 [==============================] - 22s 1s/step - loss: 0.7306 - accuracy: 0.6462 - val_loss: 2.2663 - val_accuracy: 0.3260\n",
      "Epoch 5/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6956 - accuracy: 0.6757 - val_loss: 2.2925 - val_accuracy: 0.3163\n",
      "Epoch 6/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.7254 - accuracy: 0.6305 - val_loss: 2.5769 - val_accuracy: 0.2701\n",
      "Epoch 7/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.6891 - accuracy: 0.6638 - val_loss: 2.3437 - val_accuracy: 0.3127\n",
      "Epoch 8/240\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.7124 - accuracy: 0.6557 - val_loss: 2.5118 - val_accuracy: 0.2810\n",
      "Epoch 9/240\n",
      "17/17 [==============================] - 26s 2s/step - loss: 0.7028 - accuracy: 0.6486 - val_loss: 2.5999 - val_accuracy: 0.2932\n",
      "Epoch 10/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7172 - accuracy: 0.6548 - val_loss: 2.3519 - val_accuracy: 0.3285\n",
      "Epoch 11/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.6928 - accuracy: 0.6590 - val_loss: 2.4428 - val_accuracy: 0.3041\n",
      "Epoch 12/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.6826 - accuracy: 0.6605 - val_loss: 2.5110 - val_accuracy: 0.2956\n",
      "Epoch 13/240\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.6897 - accuracy: 0.6567 - val_loss: 2.4853 - val_accuracy: 0.2883\n",
      "Epoch 14/240\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.6983 - accuracy: 0.6562 - val_loss: 2.4992 - val_accuracy: 0.2835\n",
      "Epoch 15/240\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.6827 - accuracy: 0.6614 - val_loss: 2.3330 - val_accuracy: 0.3127\n",
      "Epoch 16/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6648 - accuracy: 0.6714 - val_loss: 2.6537 - val_accuracy: 0.3054\n",
      "Epoch 17/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.6529 - accuracy: 0.6805 - val_loss: 2.6066 - val_accuracy: 0.3248\n",
      "Epoch 18/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.6602 - accuracy: 0.6681 - val_loss: 2.6685 - val_accuracy: 0.2847\n",
      "Epoch 19/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.6560 - accuracy: 0.6700 - val_loss: 2.5500 - val_accuracy: 0.3200\n",
      "Epoch 20/240\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.6714 - accuracy: 0.6795 - val_loss: 2.5822 - val_accuracy: 0.3236\n",
      "Epoch 21/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6834 - accuracy: 0.6710 - val_loss: 2.5408 - val_accuracy: 0.2847\n",
      "Epoch 22/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6478 - accuracy: 0.6857 - val_loss: 2.5989 - val_accuracy: 0.3151\n",
      "Epoch 23/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.6667 - accuracy: 0.6748 - val_loss: 2.4904 - val_accuracy: 0.3406\n",
      "Epoch 24/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6598 - accuracy: 0.6752 - val_loss: 2.6893 - val_accuracy: 0.2737\n",
      "Epoch 25/240\n",
      "17/17 [==============================] - 26s 2s/step - loss: 0.6734 - accuracy: 0.6710 - val_loss: 2.6541 - val_accuracy: 0.3017\n",
      "Epoch 26/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.6775 - accuracy: 0.6624 - val_loss: 2.5561 - val_accuracy: 0.3224\n",
      "Epoch 27/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6722 - accuracy: 0.6538 - val_loss: 2.8155 - val_accuracy: 0.2567\n",
      "Epoch 28/240\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.6398 - accuracy: 0.6705 - val_loss: 2.7638 - val_accuracy: 0.2871\n",
      "Epoch 29/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6362 - accuracy: 0.6833 - val_loss: 2.6273 - val_accuracy: 0.3309\n",
      "Epoch 30/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.6388 - accuracy: 0.6781 - val_loss: 2.7852 - val_accuracy: 0.3200\n",
      "Epoch 31/240\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.6369 - accuracy: 0.6714 - val_loss: 2.5451 - val_accuracy: 0.3090\n",
      "Epoch 32/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.6207 - accuracy: 0.6886 - val_loss: 2.6803 - val_accuracy: 0.3139\n",
      "Epoch 33/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6417 - accuracy: 0.6957 - val_loss: 2.6284 - val_accuracy: 0.2835\n",
      "Epoch 34/240\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.6520 - accuracy: 0.6629 - val_loss: 2.6530 - val_accuracy: 0.2920\n",
      "Epoch 35/240\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.6434 - accuracy: 0.6752 - val_loss: 2.5625 - val_accuracy: 0.3151\n",
      "Epoch 36/240\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.6315 - accuracy: 0.6943 - val_loss: 2.4556 - val_accuracy: 0.3163\n",
      "Epoch 37/240\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.6190 - accuracy: 0.6871 - val_loss: 2.8163 - val_accuracy: 0.2883\n",
      "Epoch 38/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.6398 - accuracy: 0.6810 - val_loss: 2.7168 - val_accuracy: 0.2920\n",
      "Epoch 39/240\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.6268 - accuracy: 0.6890 - val_loss: 2.6694 - val_accuracy: 0.3078\n",
      "Epoch 40/240\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.6169 - accuracy: 0.6857 - val_loss: 2.7356 - val_accuracy: 0.2981\n",
      "Epoch 41/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.6062 - accuracy: 0.6962 - val_loss: 2.8442 - val_accuracy: 0.2920\n",
      "Epoch 42/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.6328 - accuracy: 0.6776 - val_loss: 3.0571 - val_accuracy: 0.2883\n",
      "Epoch 43/240\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.6127 - accuracy: 0.6890 - val_loss: 2.7217 - val_accuracy: 0.3005\n",
      "Epoch 44/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.6200 - accuracy: 0.6962 - val_loss: 2.7011 - val_accuracy: 0.3187\n",
      "Epoch 45/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.6070 - accuracy: 0.6962 - val_loss: 2.8927 - val_accuracy: 0.3017\n",
      "Epoch 46/240\n",
      "17/17 [==============================] - 26s 2s/step - loss: 0.6167 - accuracy: 0.6919 - val_loss: 2.7591 - val_accuracy: 0.3114\n",
      "Epoch 47/240\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.5981 - accuracy: 0.6995 - val_loss: 2.8537 - val_accuracy: 0.3090\n",
      "Epoch 48/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.5862 - accuracy: 0.7029 - val_loss: 2.9298 - val_accuracy: 0.2847\n",
      "Epoch 49/240\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.5977 - accuracy: 0.6876 - val_loss: 2.7263 - val_accuracy: 0.3017\n",
      "Epoch 50/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.5836 - accuracy: 0.6995 - val_loss: 2.6578 - val_accuracy: 0.2981\n",
      "Epoch 51/240\n",
      "17/17 [==============================] - 26s 2s/step - loss: 0.5812 - accuracy: 0.7048 - val_loss: 3.0011 - val_accuracy: 0.2920\n",
      "Epoch 52/240\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.6008 - accuracy: 0.7133 - val_loss: 2.9117 - val_accuracy: 0.3066\n",
      "Epoch 53/240\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.6024 - accuracy: 0.6929 - val_loss: 2.6725 - val_accuracy: 0.3041\n",
      "Epoch 54/240\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5852 - accuracy: 0.7024 - val_loss: 2.8980 - val_accuracy: 0.2920\n",
      "Epoch 55/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.5691 - accuracy: 0.7100 - val_loss: 2.7819 - val_accuracy: 0.3163\n",
      "Epoch 56/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.5926 - accuracy: 0.7081 - val_loss: 2.8468 - val_accuracy: 0.2981\n",
      "Epoch 57/240\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.5857 - accuracy: 0.6976 - val_loss: 2.7396 - val_accuracy: 0.3102\n",
      "Epoch 58/240\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.5817 - accuracy: 0.7171 - val_loss: 2.9880 - val_accuracy: 0.3090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.5862 - accuracy: 0.6976 - val_loss: 2.9251 - val_accuracy: 0.2956\n",
      "Epoch 60/240\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.5711 - accuracy: 0.7095 - val_loss: 2.6352 - val_accuracy: 0.2908\n",
      "Epoch 61/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.6085 - accuracy: 0.6829 - val_loss: 2.8145 - val_accuracy: 0.3029\n",
      "Epoch 62/240\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.5752 - accuracy: 0.7181 - val_loss: 2.8610 - val_accuracy: 0.2713\n",
      "Epoch 63/240\n",
      "17/17 [==============================] - 26s 2s/step - loss: 0.5771 - accuracy: 0.7019 - val_loss: 2.9314 - val_accuracy: 0.2859\n",
      "Epoch 64/240\n",
      "17/17 [==============================] - 26s 2s/step - loss: 0.5703 - accuracy: 0.7014 - val_loss: 2.7369 - val_accuracy: 0.3163\n",
      "Epoch 65/240\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.5491 - accuracy: 0.7162 - val_loss: 3.1270 - val_accuracy: 0.3041\n",
      "Epoch 66/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.5748 - accuracy: 0.7024 - val_loss: 2.9195 - val_accuracy: 0.3224\n",
      "Epoch 67/240\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.5722 - accuracy: 0.7052 - val_loss: 2.9113 - val_accuracy: 0.3005\n",
      "Epoch 68/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.5645 - accuracy: 0.7095 - val_loss: 2.5768 - val_accuracy: 0.3382\n",
      "Epoch 69/240\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.5440 - accuracy: 0.7271 - val_loss: 2.9599 - val_accuracy: 0.2871\n",
      "Epoch 70/240\n",
      " 4/17 [======>.......................] - ETA: 13s - loss: 0.5587 - accuracy: 0.7168"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(training_X, training_y, epochs = 240, batch_size= 128, validation_data=(test_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
